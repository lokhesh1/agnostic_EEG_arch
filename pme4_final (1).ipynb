{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b03eea36",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f557f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from scipy.signal import firwin, filtfilt\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import warnings\n",
    "import torch\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"mne\")\n",
    "# Completely silence MNE-Python output\n",
    "mne.set_log_level('WARNING')  # or 'ERROR' for even less output\n",
    "logging.getLogger('mne').setLevel(logging.WARNING)\n",
    "#mne.set_log_level('debug')\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ebfa3e",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12af0830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eeg(path, sfreq = None):\n",
    "    raw = mne.io.read_raw_gdf(path, preload=True)\n",
    "\n",
    "    # Step 2: Get the sampling frequency\n",
    "    if not sfreq:\n",
    "        sfreq = raw.info['sfreq']  # Hz\n",
    "\n",
    "    # Step 3: Define FIR filter parameters\n",
    "    low_cutoff = 1.0   # Hz\n",
    "    high_cutoff = 30.0 # Hz\n",
    "    filter_order = 177 # Must be odd for linear-phase FIR\n",
    "\n",
    "    nyquist = 0.5 * sfreq\n",
    "\n",
    "\n",
    "    fir_coeffs = firwin(\n",
    "        numtaps=filter_order,\n",
    "        cutoff=[low_cutoff / nyquist, high_cutoff / nyquist],\n",
    "        pass_zero=False,\n",
    "        window='blackman'\n",
    "    )\n",
    "    eeg_data = raw.get_data()\n",
    "    filtered_data = filtfilt(fir_coeffs, 1.0, eeg_data, axis=1)\n",
    "\n",
    "    new_raw = mne.io.RawArray(filtered_data, raw.info.copy())\n",
    "    annotations = raw.annotations \n",
    "    new_raw.set_annotations(annotations)\n",
    "\n",
    "    return new_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4a18b3",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f25e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path, test=False, event_id= None):\n",
    "\n",
    "    raw = load_eeg(path)\n",
    "    eeg_channels = raw.ch_names[:22]\n",
    "    raw.pick(eeg_channels)\n",
    "    \n",
    "    if event_id is not None:\n",
    "        events, events_id = mne.events_from_annotations(raw, event_id=event_id)\n",
    "    else:\n",
    "        events, events_id = mne.events_from_annotations(raw)\n",
    "\n",
    "        #print(events_id)\n",
    "    #print(events_id)\n",
    "    epochs = mne.Epochs(\n",
    "        raw,\n",
    "        events=events,  \n",
    "        tmin=0,     \n",
    "        tmax=6.0,\n",
    "        event_id=events_id,\n",
    "        baseline=None,\n",
    "        preload=True\n",
    "    )\n",
    "\n",
    "    labels = epochs.events[:, 2]\n",
    "    #print(labels)\n",
    "    data = epochs.get_data()\n",
    "    \n",
    "    return {\n",
    "        'epochs': data,   \n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "#a = preprocess(\"E:/LOKI/BCI-IV/A01T.gdf\")\n",
    "# print(a['epochs'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c3a9d1",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe018fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.io as sio\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def gauss_smooth(inputs, device, smooth_kernel_std=2, smooth_kernel_size=100,  padding='same'):\n",
    "\n",
    "    #print(inputs.shape)\n",
    "    inputs = inputs.transpose(0, 2, 1)\n",
    "    # Get Gaussian kernel\n",
    "    inp = np.zeros(smooth_kernel_size, dtype=np.float32)\n",
    "    inp[smooth_kernel_size // 2] = 1\n",
    "    gaussKernel = gaussian_filter1d(inp, smooth_kernel_std)\n",
    "    validIdx = np.argwhere(gaussKernel > 0.01)\n",
    "    gaussKernel = gaussKernel[validIdx]\n",
    "    gaussKernel = np.squeeze(gaussKernel / np.sum(gaussKernel))\n",
    "\n",
    "    # Convert to tensor\n",
    "    gaussKernel = torch.tensor(gaussKernel, dtype=torch.float32, device=device)\n",
    "    gaussKernel = gaussKernel.view(1, 1, -1)  # [1, 1, kernel_size]\n",
    "\n",
    "    # Prepare convolution\n",
    "    B, T, C = inputs.shape\n",
    "    inputs = inputs.transpose(0, 2, 1)  # [B, C, T]\n",
    "    inputs = torch.tensor(inputs, dtype=torch.float32, device=device)\n",
    "    \n",
    "    gaussKernel = gaussKernel.repeat(C, 1, 1)  # [C, 1, kernel_size]\n",
    "\n",
    "    # Perform convolution\n",
    "    smoothed = F.conv1d(inputs, gaussKernel, padding=padding, groups=C)\n",
    "    return smoothed  # [B, T, C]\n",
    "\n",
    "# \n",
    "import pandas as pd\n",
    "\n",
    "class BCI4_2a_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, subjects=[1], transform=None, target_transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.subjects = subjects\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "\n",
    "        self.annotations = pd.read_csv('/teamspace/studios/shared-amethyst-w577/PME4_dataset_configs.csv')\n",
    "        self.data, self.labels = self._load_data()\n",
    "\n",
    "        self.labels = self.labels \n",
    "        \n",
    "    def _load_data(self):\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "\n",
    "        for subj in self.subjects:\n",
    "            subj_str = f\"s{subj:02d}\"\n",
    "            subj_annots = self.annotations[self.annotations['subject'] == subj]\n",
    "\n",
    "            for _, row in subj_annots.iterrows():\n",
    "                trial = row['trial']\n",
    "                label = row['emotion_num']  # numeric label\n",
    "\n",
    "                eeg_path = os.path.join(self.data_dir, subj_str, f\"t{trial:03d}\", f\"{subj_str}_t{trial:03d}_processed_eeg_1kHz.npy\")\n",
    "                if not os.path.exists(eeg_path):\n",
    "                    print(f\"Warning: {eeg_path} not found!\")\n",
    "                    continue\n",
    "\n",
    "                eeg_data = np.load(eeg_path)  # shape: (channels, timepoints)\n",
    "                # Normalize the trial\n",
    "                means = eeg_data.mean(axis=1, keepdims=True)\n",
    "                stds = eeg_data.std(axis=1, keepdims=True)\n",
    "                eeg_data = (eeg_data - means) / (stds + 1e-8)\n",
    "\n",
    "                # Append original data\n",
    "                all_data.append(eeg_data)\n",
    "                all_labels.append(label)\n",
    "\n",
    "                eeg_data = np.expand_dims(eeg_data, axis=0)\n",
    "                eeg_smooth = gauss_smooth(eeg_data, device='cpu')  # output shape: [1, channels, timepoints]\n",
    "                eeg_smooth = eeg_smooth.squeeze(0).numpy()  # back to (channels, timepoints)\n",
    "\n",
    "                all_data.append(eeg_smooth)  # append augmented data\n",
    "                all_labels.append(label)      # same label for augmented data\n",
    "\n",
    "        # Convert to arrays\n",
    "        all_data = np.stack(all_data, axis=0)  # shape: (num_samples, channels, timepoints)\n",
    "\n",
    "        # Map labels\n",
    "        label_map = {2:0, 4:1, 6:2, 8:3, 10:4, 12:5, 14:6}\n",
    "        all_labels = np.array([label_map[l] for l in all_labels])\n",
    "\n",
    "        return all_data, all_labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.labels[idx]\n",
    "        \n",
    "        x = torch.from_numpy(x).float()  # shape: (1, timepoints, channels)\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        if self.target_transform:\n",
    "            y = self.target_transform(y)\n",
    "            \n",
    "        return x, y\n",
    "\n",
    "def get_data_loaders(data_dir,all_subjects=[1], test_subject=[1,2], batch_size=32, val_split=0.2, random_state=42):\n",
    "    # Get all subjects except the test subject for training/validation\n",
    "    \n",
    "    #train_val_subjects = [s for s in all_subjects if s not in test_subject]\n",
    "    \n",
    "    # Create datasets\n",
    "    train_val_dataset = BCI4_2a_Dataset(data_dir, subjects=all_subjects)\n",
    "    test_dataset = BCI4_2a_Dataset(data_dir, subjects=test_subject)\n",
    "    single_trial_shape = test_dataset.data[0].shape\n",
    "    print(f\"Train+Val dataset size: {len(train_val_dataset)}\")\n",
    "    print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "    \n",
    "    # Split train_val into train and validation\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        range(len(train_val_dataset)),\n",
    "        test_size=val_split,\n",
    "        random_state=random_state,\n",
    "        stratify=train_val_dataset.labels\n",
    "    )\n",
    "    \n",
    "    train_dataset = torch.utils.data.Subset(train_val_dataset, train_idx)\n",
    "    val_dataset = torch.utils.data.Subset(train_val_dataset, val_idx)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print(f\"Train batches: {len(train_loader)}\")\n",
    "    print(f\"Val batches: {len(val_loader)}\")\n",
    "    print(f\"Test batches: {len(test_loader)}\")\n",
    "    print(f\"Single Trial Shape: {single_trial_shape}\")\n",
    "    return train_loader, val_loader, test_loader, single_trial_shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449a4378",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "135ecd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, num_channels, reduction_ratio=4, dropout=0.1):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(num_channels, num_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),  # Added dropout\n",
    "            nn.Linear(num_channels // reduction_ratio, num_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        channel_avg = torch.mean(x, dim=2, keepdim=True)  \n",
    "        channel_max, _ = torch.max(x, dim=2, keepdim=True) \n",
    "        combined = channel_avg + channel_max  \n",
    "        combined = combined.squeeze(2)\n",
    "        attention = self.mlp(combined)\n",
    "        attention = torch.sigmoid(attention).unsqueeze(2)\n",
    "        attended_x = x * attention\n",
    "        return attended_x, attention.squeeze(2)  # Return proper attention scores\n",
    "\n",
    "\n",
    "class LearnableSTFT(nn.Module):\n",
    "    def __init__(self, window_size, hop_size, learnable_window=True, dropout=0.05):\n",
    "        super(LearnableSTFT, self).__init__()\n",
    "        \n",
    "        self.window_size = window_size\n",
    "        self.hop_size = hop_size\n",
    "        self.dft_size = window_size\n",
    "        self.learnable_window = learnable_window\n",
    "        \n",
    "        # Initialize with Hamming window\n",
    "        initial_window = 0.54 - 0.46 * torch.cos(\n",
    "            2 * math.pi * torch.arange(window_size, dtype=torch.float32) / (window_size - 1)\n",
    "        )\n",
    "        \n",
    "        if learnable_window:\n",
    "            self.window = nn.Parameter(initial_window)\n",
    "        else:\n",
    "            # Fixed window reduces overfitting\n",
    "            self.register_buffer('window', initial_window)\n",
    "        \n",
    "        # Batch normalization after STFT\n",
    "        self.batch_norm = nn.BatchNorm2d(1)\n",
    "        self.dropout = nn.Dropout2d(dropout)\n",
    "        \n",
    "        dft_matrix = self._create_dft_matrix(self.dft_size, self.window_size)\n",
    "        self.register_buffer('dft_matrix', dft_matrix)\n",
    "\n",
    "    def _create_dft_matrix(self, dft_size, window_size):\n",
    "        k = torch.arange(dft_size).unsqueeze(1)\n",
    "        n = torch.arange(window_size)\n",
    "        angle = -2 * math.pi * k * n / dft_size\n",
    "        dft_matrix = torch.complex(torch.cos(angle), torch.sin(angle))\n",
    "        return dft_matrix\n",
    "\n",
    "    def forward(self, signal):\n",
    "        if signal.dim() == 1:\n",
    "            signal = signal.unsqueeze(0).unsqueeze(0)\n",
    "        elif signal.dim() == 2:\n",
    "            signal = signal.unsqueeze(1)\n",
    "            \n",
    "        batch_size, num_channels, num_samples = signal.shape\n",
    "        signal_reshaped = signal.reshape(batch_size * num_channels, num_samples)\n",
    "        \n",
    "        frames = signal_reshaped.unfold(dimension=1, size=self.window_size, step=self.hop_size)\n",
    "        num_frames_unfolded = frames.shape[1]\n",
    "        expected_num_frames = int(math.ceil((num_samples - self.window_size) / self.hop_size)) + 1\n",
    "        \n",
    "        if num_frames_unfolded < expected_num_frames:\n",
    "            padding_amount = (expected_num_frames - 1) * self.hop_size + self.window_size - num_samples\n",
    "            padded_signal = torch.nn.functional.pad(signal_reshaped, (0, padding_amount))\n",
    "            frames = padded_signal.unfold(1, self.window_size, self.hop_size)\n",
    "        \n",
    "        windowed_frames = frames * self.window\n",
    "        BC, F, W = windowed_frames.shape\n",
    "        windowed_frames_reshaped = windowed_frames.reshape(BC * F, W)\n",
    "        \n",
    "        windowed_frames_complex = windowed_frames_reshaped.to(self.dft_matrix.dtype)\n",
    "        stft_result_reshaped = self.dft_matrix @ windowed_frames_complex.T\n",
    "        stft_result = stft_result_reshaped.T.reshape(batch_size, num_channels, F, self.dft_size)\n",
    "        \n",
    "        # Apply magnitude and normalization\n",
    "        stft_magnitude = torch.abs(stft_result)\n",
    "        \n",
    "        # Reshape for batch norm: (B*C, 1, F, freq_bins)\n",
    "        stft_normalized = stft_magnitude.reshape(batch_size * num_channels, 1, F, self.dft_size)\n",
    "        stft_normalized = self.batch_norm(stft_normalized)\n",
    "        stft_normalized = self.dropout(stft_normalized)\n",
    "        stft_normalized = stft_normalized.reshape(batch_size, num_channels, F, self.dft_size)\n",
    "        \n",
    "        return stft_normalized\n",
    "\n",
    "\n",
    "class Attention4D(nn.Module):\n",
    "    def __init__(self, in_channels, time_frames, freq_bins, d_model=128, n_heads=4, \n",
    "                 d_ff=256, dropout=0.2, num_layers=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.time_frames = time_frames\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        in_features = in_channels * freq_bins\n",
    "        \n",
    "        # Project input to d_model with layer norm\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(in_features, d_model),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # Learnable positional encoding with smaller init\n",
    "        self.positional_encoding = nn.Parameter(\n",
    "            torch.randn(1, time_frames, d_model) * 0.02\n",
    "        )\n",
    "        \n",
    "        # Stack multiple transformer layers for better representation\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            TransformerBlock(d_model, n_heads, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.final_norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Reshape: (B, C, T, F) -> (B, T, C*F)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        x = x.reshape(batch_size, self.time_frames, -1)\n",
    "        \n",
    "        # Project and add positional encoding\n",
    "        x = self.projection(x)\n",
    "        x = x + self.positional_encoding\n",
    "        \n",
    "        # Store attention weights from all layers\n",
    "        all_attention_weights = []\n",
    "        \n",
    "        # Pass through transformer layers\n",
    "        for layer in self.transformer_layers:\n",
    "            x, attn_weights = layer(x)\n",
    "            all_attention_weights.append(attn_weights)\n",
    "        \n",
    "        x = self.final_norm(x)\n",
    "        \n",
    "        return x, all_attention_weights\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=d_model, \n",
    "            num_heads=n_heads, \n",
    "            dropout=dropout, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.GELU(),  # GELU often works better than ReLU\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Pre-norm architecture (more stable)\n",
    "        x_norm = self.layernorm1(x)\n",
    "        attn_output, attn_weights = self.attention(x_norm, x_norm, x_norm, \n",
    "                                                    need_weights=True, \n",
    "                                                    average_attn_weights=True)\n",
    "        x = x + self.dropout1(attn_output)\n",
    "        \n",
    "        x_norm = self.layernorm2(x)\n",
    "        ff_output = self.feed_forward(x_norm)\n",
    "        x = x + self.dropout2(ff_output)\n",
    "        \n",
    "        return x, attn_weights\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_features, num_classes, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # Add intermediate layer for better capacity\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features // 2),\n",
    "            nn.LayerNorm(in_features // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_features // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # (B, d_model, T)\n",
    "        x = self.pooling(x).squeeze(2)  # (B, d_model)\n",
    "        output = self.classifier(x)  # (B, num_classes)\n",
    "        return output\n",
    "\n",
    "\n",
    "class EEGClassifier(nn.Module):\n",
    "    def __init__(self, num_samples, num_classes=4, window_percent=0.25, \n",
    "                 overlap_percent=0.10, d_model=128, n_heads=8, \n",
    "                 transformer_layers=1, dropout=0.2, learnable_window=True):\n",
    "\n",
    "        super(EEGClassifier, self).__init__()\n",
    "        \n",
    "        window_size = int(num_samples * window_percent)\n",
    "        hop_size = int(num_samples * overlap_percent)\n",
    "        \n",
    "        self.window_size = max(window_size, 30)\n",
    "        self.hop_size = max(hop_size, 10)\n",
    "        \n",
    "        self.channel_attn = ChannelAttention(num_channels=8, dropout=dropout)\n",
    "        \n",
    "        self.learnable_stft = LearnableSTFT(\n",
    "            window_size=self.window_size,\n",
    "            hop_size=self.hop_size,\n",
    "            learnable_window=learnable_window,\n",
    "            dropout=dropout * 0.5\n",
    "        )\n",
    "        \n",
    "        time_frames = int(math.ceil((num_samples - self.window_size) / self.hop_size)) + 1\n",
    "        \n",
    "        self.attention_module = Attention4D(\n",
    "            in_channels=8,\n",
    "            time_frames=time_frames,\n",
    "            freq_bins=self.window_size,\n",
    "            d_model=d_model,\n",
    "            n_heads=n_heads,\n",
    "            num_layers=transformer_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.classifier = Classifier(\n",
    "            in_features=d_model, \n",
    "            num_classes=num_classes,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, x, return_attention=False):\n",
    "\n",
    "        # Channel attention\n",
    "        x, channel_attn_scores = self.channel_attn(x)\n",
    "        \n",
    "        # STFT\n",
    "        x = self.learnable_stft(x)\n",
    "        \n",
    "        # Transformer attention\n",
    "        x, transformer_attn_weights = self.attention_module(x)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(x)\n",
    "        \n",
    "        if return_attention:\n",
    "            attention_dict = {\n",
    "                'channel_attention': channel_attn_scores,  # (B, 22)\n",
    "                'transformer_attention': transformer_attn_weights,  # List of (B, T, T) for each layer\n",
    "            }\n",
    "            return logits, attention_dict\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "class AttentionRegularizedLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, alpha=0.01, beta=0.01):\n",
    "        super().__init__()\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.alpha = alpha  # Channel attention regularization weight\n",
    "        self.beta = beta    # Transformer attention regularization weight\n",
    "        \n",
    "    def forward(self, logits, targets, attention_dict):\n",
    "        # Classification loss\n",
    "        ce = self.ce_loss(logits, targets)\n",
    "        \n",
    "        # Channel attention regularization (encourage diversity)\n",
    "        \n",
    "        # Transformer attention regularization (discourage extreme peakiness)\n",
    "        transformer_attn = attention_dict['transformer_attention'][-1]  # Use last layer (B, T, T)\n",
    "        # Variance is always non-negative (variance >= 0)\n",
    "        attn_variance = torch.var(transformer_attn, dim=-1).mean()\n",
    "        \n",
    "        # Calculate total loss: CE + (alpha * negative_entropy) + (beta * variance)\n",
    "        # Since alpha * negative_entropy is negative, it reduces the loss.\n",
    "        total_loss = ce + self.beta * attn_variance\n",
    "        \n",
    "        # *** CRITICAL FIX: Ensure Total Loss is Non-Negative ***\n",
    "        # If CE is near zero, the negative channel_reg term can cause total_loss < 0.\n",
    "        # Clipping maintains optimization goal while ensuring mathematical stability.\n",
    "        total_loss = torch.max(total_loss, torch.tensor(0.0, device=total_loss.device))\n",
    "        \n",
    "        return total_loss, {\n",
    "            'ce_loss': ce.item(),\n",
    "            'attn_variance': attn_variance.item()\n",
    "        }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f850fe",
   "metadata": {},
   "source": [
    "# test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "484720f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     # Model initialization\n",
    "#     model = EEGClassifier(\n",
    "#         num_samples=1000,\n",
    "#         num_classes=4,\n",
    "#         d_model=64,  # Reduced from 128\n",
    "#         n_heads=4,   # Reduced from 8\n",
    "#         transformer_layers=2,\n",
    "#         dropout=0.3,\n",
    "#         learnable_window=False  # Start with fixed window\n",
    "#     )\n",
    "    \n",
    "#     # Loss function\n",
    "#     criterion = AttentionRegularizedLoss(num_classes=4, alpha=0.01, beta=0.01)\n",
    "    \n",
    "#     # Dummy data\n",
    "#     x = torch.randn(4, 22, 1000)  # (batch, channels, time)\n",
    "#     y = torch.randint(0, 4, (4,))\n",
    "    \n",
    "#     # Forward pass with attention\n",
    "#     logits, attention_dict = model(x, return_attention=True)\n",
    "    \n",
    "#     # Calculate loss\n",
    "#     loss, loss_dict = criterion(logits, y, attention_dict)\n",
    "    \n",
    "#     print(f\"Logits shape: {logits.shape}\")\n",
    "#     print(f\"Channel attention shape: {attention_dict['channel_attention'].shape}\")\n",
    "#     print(f\"Num transformer layers: {len(attention_dict['transformer_attention'])}\")\n",
    "#     print(f\"Transformer attention shape: {attention_dict['transformer_attention'][0].shape}\")\n",
    "#     print(f\"Total loss: {loss.item():.4f}\")\n",
    "#     print(f\"Loss components: {loss_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313f023b",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c483a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 10:46:15.696764: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-29 10:46:15.744081: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-29 10:46:15.744125: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-29 10:46:15.744155: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-29 10:46:15.753844: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-29 10:46:17.032348: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import json\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "class EEGTrainer:\n",
    "    def __init__(self, model, train_loader, val_loader, test_loader=None, config=None):\n",
    "\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        \n",
    "        # Set device\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "        # Default configuration\n",
    "        self.config = {\n",
    "            'lr': 1e-3,\n",
    "            'weight_decay': 1e-4,\n",
    "            'patience': 10,\n",
    "            'min_lr': 1e-6,\n",
    "            'epochs': 100,\n",
    "            'save_dir': 'experiments',\n",
    "            'experiment_name': f'exp_{time.strftime(\"%Y%m%d-%H%M%S\")}',\n",
    "            'save_attention_maps': True,\n",
    "            'attention_map_freq': 5\n",
    "        }\n",
    "        \n",
    "        # Update with user config if provided\n",
    "        if config:\n",
    "            self.config.update(config)\n",
    "            \n",
    "        # Create experiment directory\n",
    "        self.exp_dir = os.path.join(self.config['save_dir'], self.config['experiment_name'])\n",
    "        os.makedirs(self.exp_dir, exist_ok=True)\n",
    "        \n",
    "        # Initialize components\n",
    "        self._init_components()\n",
    "        \n",
    "        # Save config\n",
    "        self._save_config()\n",
    "        \n",
    "    def _init_components(self):\n",
    "        \"\"\"Initialize training components\"\"\"\n",
    "        # Loss function (CrossEntropy + KLDiv for attention regularization)\n",
    "        self.criterion = AttentionRegularizedLoss(num_classes=4, alpha=0.01, beta=0.01)#nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=self.config['lr'],\n",
    "            weight_decay=self.config['weight_decay']\n",
    "        )\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        self.scheduler = ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='max',\n",
    "            factor=0.5,\n",
    "            patience=self.config['patience']//2,\n",
    "            min_lr=self.config['min_lr'],\n",
    "            #verbose=True\n",
    "        )\n",
    "        \n",
    "        self.best_val_acc = 0.0\n",
    "        self.early_stop_counter = 0\n",
    "        \n",
    "        # Tensorboard writer\n",
    "        self.writer = SummaryWriter(log_dir=self.exp_dir)\n",
    "        \n",
    "        # Attention maps directory\n",
    "        if self.config['save_attention_maps']:\n",
    "            self.attention_dir = os.path.join(self.exp_dir, 'attention_maps')\n",
    "            os.makedirs(self.attention_dir, exist_ok=True)\n",
    "    \n",
    "    def _save_config(self):\n",
    "        config_path = os.path.join(self.exp_dir, 'config.json')\n",
    "        with open(config_path, 'w') as f:\n",
    "            json.dump(self.config, f, indent=4)\n",
    "    \n",
    "    def _compute_metrics(self, outputs, labels):\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        accuracy = correct / labels.size(0)\n",
    "        return accuracy\n",
    "    \n",
    "    def _log_metrics(self, phase, metrics, epoch):\n",
    "        loss = metrics['loss']\n",
    "        acc = metrics['accuracy']\n",
    "        pre = metrics['precision']\n",
    "        rec = metrics['recall']\n",
    "        f1 = metrics['f1']\n",
    "        \n",
    "        # Console logging\n",
    "        print(f\"{phase.capitalize()} - Epoch: {epoch+1} | \"\n",
    "              f\"Loss: {loss:.4f} | Acc: {acc:.2%} | Precision: {pre:.2%} | recall: {rec:.2%} | f1: {f1:.2%}\")\n",
    "        \n",
    "        # Tensorboard logging\n",
    "        self.writer.add_scalar(f'Loss/{phase}', loss, epoch)\n",
    "        self.writer.add_scalar(f'Accuracy/{phase}', acc, epoch)\n",
    "        \n",
    "        \n",
    "        # Log learning rate\n",
    "        if phase == 'train':\n",
    "            lr = self.optimizer.param_groups[0]['lr']\n",
    "            self.writer.add_scalar('LR', lr, epoch)\n",
    "    \n",
    "    def _save_checkpoint(self, epoch, is_best=False):\n",
    "        \"\"\"Save model checkpoint\"\"\"\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'state_dict': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "            'scheduler': self.scheduler.state_dict(),\n",
    "            'best_val_acc': self.best_val_acc\n",
    "        }\n",
    "        \n",
    "        # Save regular checkpoint\n",
    "        checkpoint_path = os.path.join(self.exp_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "        torch.save(state, checkpoint_path)\n",
    "        \n",
    "        # Save best model\n",
    "        if is_best:\n",
    "            best_path = os.path.join(self.exp_dir, 'best_model.pth')\n",
    "            torch.save(state, best_path)\n",
    "    \n",
    "\n",
    "    \n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Store all predictions and labels for epoch-wise metrics\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for inputs, labels in self.train_loader:\n",
    "            inputs = inputs.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "\n",
    "            # Zero gradients\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs, attention_dict = self.model(inputs, return_attention=True)\n",
    "            loss ,_ = self.criterion(outputs, labels,attention_dict)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # ----- accumulate loss -----\n",
    "            batch_size = inputs.size(0)\n",
    "            running_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "            # ----- accumulate preds + labels for metrics -----\n",
    "            preds = torch.argmax(outputs, dim=1)          # [B]\n",
    "            all_preds.append(preds.detach().cpu())\n",
    "            all_labels.append(labels.detach().cpu())\n",
    "\n",
    "        # ---- end of epoch: stack everything and compute metrics ----\n",
    "        all_preds = torch.cat(all_preds).numpy()\n",
    "        all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "        epoch_loss = running_loss / total_samples\n",
    "\n",
    "        # accuracy\n",
    "        epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "        # precision, recall, f1\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_labels,\n",
    "            all_preds,\n",
    "            average='weighted',      # change to 'macro' / 'binary' if needed\n",
    "            zero_division=0          # avoid NaN if a class is missing in preds\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'loss': epoch_loss,\n",
    "            'accuracy': epoch_acc,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "        }\n",
    "\n",
    "\n",
    "    \n",
    "    def validate_epoch(self, epoch):\n",
    "        \"\"\"Validate for one epoch\"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.val_loader:\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "     \n",
    "                # Forward pass\n",
    "                #outputs = self.model(inputs)\n",
    "                outputs, attention_dict = self.model(inputs, return_attention=True)\n",
    "                loss, _ = self.criterion(outputs, labels, attention_dict)\n",
    "                #loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                batch_size = inputs.size(0)\n",
    "                running_loss += loss.item() * batch_size\n",
    "                total_samples += batch_size\n",
    "\n",
    "                # ----- accumulate preds + labels for metrics -----\n",
    "                preds = torch.argmax(outputs, dim=1)          # [B]\n",
    "                all_preds.append(preds.detach().cpu())\n",
    "                all_labels.append(labels.detach().cpu())\n",
    "\n",
    "            # ---- end of epoch: stack everything and compute metrics ----\n",
    "            all_preds = torch.cat(all_preds).numpy()\n",
    "            all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "            epoch_loss = running_loss / total_samples\n",
    "\n",
    "            # accuracy\n",
    "            epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "            # precision, recall, f1\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                all_labels,\n",
    "                all_preds,\n",
    "                average='weighted',      # change to 'macro' / 'binary' if needed\n",
    "                zero_division=0          # avoid NaN if a class is missing in preds\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                'loss': epoch_loss,\n",
    "                'accuracy': epoch_acc,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1,\n",
    "            }\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Main training loop\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(self.config['epochs']):\n",
    "            # Train and validate\n",
    "            train_metrics = self.train_epoch(epoch)\n",
    "            val_metrics = self.validate_epoch(epoch)\n",
    "            \n",
    "            # Log metrics\n",
    "            self._log_metrics('train', train_metrics, epoch)\n",
    "            self._log_metrics('val', val_metrics, epoch)\n",
    "            \n",
    "            # Save attention maps periodically\n",
    "            \n",
    "            # Step scheduler\n",
    "            self.scheduler.step(val_metrics['accuracy'])\n",
    "            \n",
    "            # Check for best model\n",
    "            if val_metrics['accuracy'] > self.best_val_acc:\n",
    "                self.best_val_acc = val_metrics['accuracy']\n",
    "                self._save_checkpoint(epoch, is_best=True)\n",
    "                self.early_stop_counter = 0\n",
    "            else:\n",
    "                self.early_stop_counter += 1\n",
    "            \n",
    "            # Save checkpoint periodically\n",
    "            if epoch % 10 == 0:\n",
    "                self._save_checkpoint(epoch)\n",
    "            \n",
    "            # Early stopping\n",
    "            # if self.early_stop_counter >= self.config['patience']:\n",
    "            #     print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            #     break\n",
    "        \n",
    "        # Training complete\n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"Training completed in {training_time//60:.0f}m {training_time%60:.0f}s\")\n",
    "        print(f\"Best validation accuracy: {self.best_val_acc:.2%}\")\n",
    "        \n",
    "        # Test if test loader provided\n",
    "        if self.test_loader:\n",
    "            test_acc = self.test()\n",
    "            print(f\"Test accuracy: {test_acc:.2%}\")\n",
    "        \n",
    "        # Close tensorboard writer\n",
    "        self.writer.close()\n",
    "        \n",
    "        return self.best_val_acc\n",
    "    \n",
    "    def test(self):\n",
    "        \"\"\"Evaluate on test set\"\"\"\n",
    "        self.model.eval()\n",
    "        running_acc = 0.0\n",
    "        total_samples = 0\n",
    "        \n",
    "        # Load best model\n",
    "        best_path = os.path.join(self.exp_dir, 'best_model.pth')\n",
    "        if os.path.exists(best_path):\n",
    "            checkpoint = torch.load(best_path)\n",
    "            self.model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n",
    "        \n",
    "        all_preds=[]\n",
    "        all_labels=[]\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.test_loader:\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                batch_size = inputs.size(0)\n",
    "                total_samples += batch_size\n",
    "\n",
    "                # ----- accumulate preds + labels for metrics -----\n",
    "                preds = torch.argmax(outputs, dim=1)          # [B]\n",
    "                all_preds.append(preds.detach().cpu())\n",
    "                all_labels.append(labels.detach().cpu())\n",
    "\n",
    "            # ---- end of epoch: stack everything and compute metrics ----\n",
    "            all_preds = torch.cat(all_preds).numpy()\n",
    "            all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "            epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "            # precision, recall, f1\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                all_labels,\n",
    "                all_preds,\n",
    "                average='weighted',      # change to 'macro' / 'binary' if needed\n",
    "                zero_division=0          # avoid NaN if a class is missing in preds\n",
    "            )\n",
    "        \n",
    "        test_acc = epoch_acc\n",
    "        self.writer.add_scalar('Accuracy/test', test_acc)\n",
    "        print(\"acc: \",test_acc)\n",
    "        print(\"precision:\", precision)\n",
    "        print(\"recall:\", recall)\n",
    "        print(\"F1 :\", f1)\n",
    "        return epoch_acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef686541",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf259697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train+Val dataset size: 7658\n",
      "Test dataset size: 1398\n",
      "Train batches: 192\n",
      "Val batches: 48\n",
      "Test batches: 44\n",
      "Single Trial Shape: (8, 5000)\n",
      "Train - Epoch: 1 | Loss: 1.9614 | Acc: 14.32% | Precision: 14.21% | recall: 14.32% | f1: 14.18%\n",
      "Val - Epoch: 1 | Loss: 1.9487 | Acc: 15.86% | Precision: 16.68% | recall: 15.86% | f1: 10.03%\n",
      "Train - Epoch: 2 | Loss: 1.9556 | Acc: 13.86% | Precision: 13.78% | recall: 13.86% | f1: 13.64%\n",
      "Val - Epoch: 2 | Loss: 1.9465 | Acc: 14.30% | Precision: 2.04% | recall: 14.30% | f1: 3.58%\n",
      "Train - Epoch: 3 | Loss: 1.9500 | Acc: 14.48% | Precision: 14.15% | recall: 14.48% | f1: 13.67%\n",
      "Val - Epoch: 3 | Loss: 1.9455 | Acc: 15.21% | Precision: 7.39% | recall: 15.21% | f1: 7.75%\n",
      "Train - Epoch: 4 | Loss: 1.9485 | Acc: 15.03% | Precision: 14.92% | recall: 15.03% | f1: 14.71%\n",
      "Val - Epoch: 4 | Loss: 1.9438 | Acc: 15.01% | Precision: 16.96% | recall: 15.01% | f1: 6.08%\n",
      "Train - Epoch: 5 | Loss: 1.9448 | Acc: 16.18% | Precision: 15.83% | recall: 16.18% | f1: 15.58%\n",
      "Val - Epoch: 5 | Loss: 1.9404 | Acc: 15.93% | Precision: 11.08% | recall: 15.93% | f1: 8.37%\n",
      "Train - Epoch: 6 | Loss: 1.9389 | Acc: 16.16% | Precision: 16.49% | recall: 16.16% | f1: 15.28%\n",
      "Val - Epoch: 6 | Loss: 1.9302 | Acc: 15.60% | Precision: 12.31% | recall: 15.60% | f1: 11.18%\n",
      "Train - Epoch: 7 | Loss: 1.9369 | Acc: 16.06% | Precision: 16.50% | recall: 16.06% | f1: 14.95%\n",
      "Val - Epoch: 7 | Loss: 1.9226 | Acc: 16.84% | Precision: 16.01% | recall: 16.84% | f1: 12.47%\n",
      "Train - Epoch: 8 | Loss: 1.9303 | Acc: 18.10% | Precision: 19.45% | recall: 18.10% | f1: 16.45%\n",
      "Val - Epoch: 8 | Loss: 1.9203 | Acc: 17.56% | Precision: 22.77% | recall: 17.56% | f1: 14.27%\n",
      "Train - Epoch: 9 | Loss: 1.9300 | Acc: 17.60% | Precision: 17.88% | recall: 17.60% | f1: 16.54%\n",
      "Val - Epoch: 9 | Loss: 1.9216 | Acc: 16.45% | Precision: 21.55% | recall: 16.45% | f1: 11.61%\n",
      "Train - Epoch: 10 | Loss: 1.9194 | Acc: 17.81% | Precision: 18.02% | recall: 17.81% | f1: 17.42%\n",
      "Val - Epoch: 10 | Loss: 1.9208 | Acc: 17.43% | Precision: 15.07% | recall: 17.43% | f1: 10.74%\n",
      "Train - Epoch: 11 | Loss: 1.9151 | Acc: 18.58% | Precision: 18.65% | recall: 18.58% | f1: 17.83%\n",
      "Val - Epoch: 11 | Loss: 1.9055 | Acc: 19.19% | Precision: 17.55% | recall: 19.19% | f1: 15.56%\n",
      "Train - Epoch: 12 | Loss: 1.9107 | Acc: 19.05% | Precision: 19.12% | recall: 19.05% | f1: 18.36%\n",
      "Val - Epoch: 12 | Loss: 1.9053 | Acc: 18.28% | Precision: 30.82% | recall: 18.28% | f1: 12.90%\n",
      "Train - Epoch: 13 | Loss: 1.9019 | Acc: 20.26% | Precision: 20.36% | recall: 20.26% | f1: 18.95%\n",
      "Val - Epoch: 13 | Loss: 1.9162 | Acc: 16.32% | Precision: 28.93% | recall: 16.32% | f1: 11.65%\n",
      "Train - Epoch: 14 | Loss: 1.9002 | Acc: 19.02% | Precision: 18.95% | recall: 19.02% | f1: 18.43%\n",
      "Val - Epoch: 14 | Loss: 1.8885 | Acc: 19.71% | Precision: 22.44% | recall: 19.71% | f1: 17.49%\n",
      "Train - Epoch: 15 | Loss: 1.8871 | Acc: 20.54% | Precision: 20.29% | recall: 20.54% | f1: 19.97%\n",
      "Val - Epoch: 15 | Loss: 1.8864 | Acc: 20.10% | Precision: 33.79% | recall: 20.10% | f1: 14.75%\n",
      "Train - Epoch: 16 | Loss: 1.8765 | Acc: 21.07% | Precision: 21.09% | recall: 21.07% | f1: 20.53%\n",
      "Val - Epoch: 16 | Loss: 1.8865 | Acc: 20.10% | Precision: 25.04% | recall: 20.10% | f1: 17.68%\n",
      "Train - Epoch: 17 | Loss: 1.8613 | Acc: 22.46% | Precision: 21.88% | recall: 22.46% | f1: 21.57%\n",
      "Val - Epoch: 17 | Loss: 1.8806 | Acc: 19.45% | Precision: 21.24% | recall: 19.45% | f1: 17.96%\n",
      "Train - Epoch: 18 | Loss: 1.8366 | Acc: 24.58% | Precision: 24.75% | recall: 24.58% | f1: 24.10%\n",
      "Val - Epoch: 18 | Loss: 1.8518 | Acc: 21.28% | Precision: 21.63% | recall: 21.28% | f1: 20.33%\n",
      "Train - Epoch: 19 | Loss: 1.8167 | Acc: 25.64% | Precision: 25.63% | recall: 25.64% | f1: 24.70%\n",
      "Val - Epoch: 19 | Loss: 1.8371 | Acc: 22.98% | Precision: 26.21% | recall: 22.98% | f1: 22.01%\n",
      "Train - Epoch: 20 | Loss: 1.7814 | Acc: 28.58% | Precision: 28.63% | recall: 28.58% | f1: 28.02%\n",
      "Val - Epoch: 20 | Loss: 1.8357 | Acc: 23.63% | Precision: 26.94% | recall: 23.63% | f1: 21.28%\n",
      "Train - Epoch: 21 | Loss: 1.7298 | Acc: 31.42% | Precision: 31.41% | recall: 31.42% | f1: 30.65%\n",
      "Val - Epoch: 21 | Loss: 1.8513 | Acc: 25.78% | Precision: 30.87% | recall: 25.78% | f1: 23.45%\n",
      "Train - Epoch: 22 | Loss: 1.6801 | Acc: 34.23% | Precision: 34.36% | recall: 34.23% | f1: 33.91%\n",
      "Val - Epoch: 22 | Loss: 1.7903 | Acc: 27.74% | Precision: 35.76% | recall: 27.74% | f1: 25.12%\n",
      "Train - Epoch: 23 | Loss: 1.6181 | Acc: 37.61% | Precision: 37.51% | recall: 37.61% | f1: 37.01%\n",
      "Val - Epoch: 23 | Loss: 1.7493 | Acc: 32.31% | Precision: 32.90% | recall: 32.31% | f1: 30.07%\n",
      "Train - Epoch: 24 | Loss: 1.5518 | Acc: 41.25% | Precision: 41.13% | recall: 41.25% | f1: 40.70%\n",
      "Val - Epoch: 24 | Loss: 1.7148 | Acc: 33.16% | Precision: 36.41% | recall: 33.16% | f1: 32.67%\n",
      "Train - Epoch: 25 | Loss: 1.4768 | Acc: 44.45% | Precision: 44.61% | recall: 44.45% | f1: 44.14%\n",
      "Val - Epoch: 25 | Loss: 1.6818 | Acc: 35.64% | Precision: 38.44% | recall: 35.64% | f1: 34.23%\n",
      "Train - Epoch: 26 | Loss: 1.3896 | Acc: 47.94% | Precision: 47.96% | recall: 47.94% | f1: 47.65%\n",
      "Val - Epoch: 26 | Loss: 1.6274 | Acc: 40.67% | Precision: 42.09% | recall: 40.67% | f1: 40.49%\n",
      "Train - Epoch: 27 | Loss: 1.3064 | Acc: 52.56% | Precision: 52.65% | recall: 52.56% | f1: 52.37%\n",
      "Val - Epoch: 27 | Loss: 1.6288 | Acc: 41.06% | Precision: 42.74% | recall: 41.06% | f1: 39.93%\n",
      "Train - Epoch: 28 | Loss: 1.2262 | Acc: 55.66% | Precision: 55.43% | recall: 55.66% | f1: 55.31%\n",
      "Val - Epoch: 28 | Loss: 1.6174 | Acc: 41.19% | Precision: 43.55% | recall: 41.19% | f1: 40.40%\n",
      "Train - Epoch: 29 | Loss: 1.1273 | Acc: 59.89% | Precision: 59.74% | recall: 59.89% | f1: 59.67%\n",
      "Val - Epoch: 29 | Loss: 1.4701 | Acc: 47.78% | Precision: 49.47% | recall: 47.78% | f1: 47.58%\n",
      "Train - Epoch: 30 | Loss: 1.0816 | Acc: 61.90% | Precision: 61.86% | recall: 61.90% | f1: 61.79%\n",
      "Val - Epoch: 30 | Loss: 1.4668 | Acc: 49.80% | Precision: 50.31% | recall: 49.80% | f1: 49.23%\n",
      "Train - Epoch: 31 | Loss: 1.0076 | Acc: 64.94% | Precision: 64.83% | recall: 64.94% | f1: 64.81%\n",
      "Val - Epoch: 31 | Loss: 1.4428 | Acc: 51.11% | Precision: 55.11% | recall: 51.11% | f1: 50.08%\n",
      "Train - Epoch: 32 | Loss: 0.9216 | Acc: 68.84% | Precision: 68.79% | recall: 68.84% | f1: 68.76%\n",
      "Val - Epoch: 32 | Loss: 1.3883 | Acc: 53.98% | Precision: 57.55% | recall: 53.98% | f1: 53.44%\n",
      "Train - Epoch: 33 | Loss: 0.8922 | Acc: 69.25% | Precision: 69.25% | recall: 69.25% | f1: 69.20%\n",
      "Val - Epoch: 33 | Loss: 1.2771 | Acc: 57.64% | Precision: 58.93% | recall: 57.64% | f1: 57.52%\n",
      "Train - Epoch: 34 | Loss: 0.7846 | Acc: 74.11% | Precision: 74.08% | recall: 74.11% | f1: 74.06%\n",
      "Val - Epoch: 34 | Loss: 1.2589 | Acc: 59.66% | Precision: 61.30% | recall: 59.66% | f1: 58.90%\n",
      "Train - Epoch: 35 | Loss: 0.7471 | Acc: 74.52% | Precision: 74.45% | recall: 74.52% | f1: 74.46%\n",
      "Val - Epoch: 35 | Loss: 1.1972 | Acc: 63.45% | Precision: 64.77% | recall: 63.45% | f1: 63.63%\n",
      "Train - Epoch: 36 | Loss: 0.7061 | Acc: 76.49% | Precision: 76.48% | recall: 76.49% | f1: 76.45%\n",
      "Val - Epoch: 36 | Loss: 1.1491 | Acc: 64.23% | Precision: 64.93% | recall: 64.23% | f1: 64.17%\n",
      "Train - Epoch: 37 | Loss: 0.6459 | Acc: 78.62% | Precision: 78.56% | recall: 78.62% | f1: 78.58%\n",
      "Val - Epoch: 37 | Loss: 1.1618 | Acc: 65.08% | Precision: 67.25% | recall: 65.08% | f1: 65.28%\n",
      "Train - Epoch: 38 | Loss: 0.5974 | Acc: 80.08% | Precision: 80.07% | recall: 80.08% | f1: 80.07%\n",
      "Val - Epoch: 38 | Loss: 1.0981 | Acc: 67.89% | Precision: 69.54% | recall: 67.89% | f1: 67.67%\n",
      "Train - Epoch: 39 | Loss: 0.5859 | Acc: 81.23% | Precision: 81.22% | recall: 81.23% | f1: 81.21%\n",
      "Val - Epoch: 39 | Loss: 1.0288 | Acc: 70.69% | Precision: 71.07% | recall: 70.69% | f1: 70.52%\n",
      "Train - Epoch: 40 | Loss: 0.5488 | Acc: 82.21% | Precision: 82.20% | recall: 82.21% | f1: 82.18%\n",
      "Val - Epoch: 40 | Loss: 1.0753 | Acc: 70.17% | Precision: 71.54% | recall: 70.17% | f1: 70.32%\n",
      "Train - Epoch: 41 | Loss: 0.4885 | Acc: 83.90% | Precision: 83.90% | recall: 83.90% | f1: 83.90%\n",
      "Val - Epoch: 41 | Loss: 1.0451 | Acc: 72.19% | Precision: 72.66% | recall: 72.19% | f1: 72.23%\n",
      "Train - Epoch: 42 | Loss: 0.4676 | Acc: 84.98% | Precision: 85.01% | recall: 84.98% | f1: 84.99%\n",
      "Val - Epoch: 42 | Loss: 1.0073 | Acc: 72.78% | Precision: 74.17% | recall: 72.78% | f1: 72.89%\n",
      "Train - Epoch: 43 | Loss: 0.4443 | Acc: 85.62% | Precision: 85.62% | recall: 85.62% | f1: 85.61%\n",
      "Val - Epoch: 43 | Loss: 0.9327 | Acc: 75.20% | Precision: 75.55% | recall: 75.20% | f1: 75.22%\n",
      "Train - Epoch: 44 | Loss: 0.4173 | Acc: 86.75% | Precision: 86.74% | recall: 86.75% | f1: 86.74%\n",
      "Val - Epoch: 44 | Loss: 0.9532 | Acc: 75.78% | Precision: 76.93% | recall: 75.78% | f1: 75.94%\n",
      "Train - Epoch: 45 | Loss: 0.4123 | Acc: 86.53% | Precision: 86.53% | recall: 86.53% | f1: 86.53%\n",
      "Val - Epoch: 45 | Loss: 0.9392 | Acc: 76.63% | Precision: 76.85% | recall: 76.63% | f1: 76.61%\n",
      "Train - Epoch: 46 | Loss: 0.3825 | Acc: 87.64% | Precision: 87.64% | recall: 87.64% | f1: 87.64%\n",
      "Val - Epoch: 46 | Loss: 0.8745 | Acc: 78.92% | Precision: 80.12% | recall: 78.92% | f1: 79.08%\n",
      "Train - Epoch: 47 | Loss: 0.3700 | Acc: 88.26% | Precision: 88.26% | recall: 88.26% | f1: 88.26%\n",
      "Val - Epoch: 47 | Loss: 0.8784 | Acc: 78.33% | Precision: 78.96% | recall: 78.33% | f1: 78.42%\n",
      "Train - Epoch: 48 | Loss: 0.3350 | Acc: 89.57% | Precision: 89.59% | recall: 89.57% | f1: 89.57%\n",
      "Val - Epoch: 48 | Loss: 0.8328 | Acc: 79.57% | Precision: 79.78% | recall: 79.57% | f1: 79.54%\n",
      "Train - Epoch: 49 | Loss: 0.3274 | Acc: 89.39% | Precision: 89.40% | recall: 89.39% | f1: 89.39%\n",
      "Val - Epoch: 49 | Loss: 0.8820 | Acc: 79.50% | Precision: 80.27% | recall: 79.50% | f1: 79.56%\n",
      "Train - Epoch: 50 | Loss: 0.3153 | Acc: 90.19% | Precision: 90.21% | recall: 90.19% | f1: 90.19%\n",
      "Val - Epoch: 50 | Loss: 0.8316 | Acc: 80.09% | Precision: 80.48% | recall: 80.09% | f1: 80.13%\n",
      "Train - Epoch: 51 | Loss: 0.2982 | Acc: 90.32% | Precision: 90.32% | recall: 90.32% | f1: 90.32%\n",
      "Val - Epoch: 51 | Loss: 0.8733 | Acc: 79.70% | Precision: 80.34% | recall: 79.70% | f1: 79.71%\n",
      "Train - Epoch: 52 | Loss: 0.2962 | Acc: 90.91% | Precision: 90.91% | recall: 90.91% | f1: 90.91%\n",
      "Val - Epoch: 52 | Loss: 0.8541 | Acc: 80.09% | Precision: 80.89% | recall: 80.09% | f1: 80.12%\n",
      "Train - Epoch: 53 | Loss: 0.2708 | Acc: 91.19% | Precision: 91.21% | recall: 91.19% | f1: 91.19%\n",
      "Val - Epoch: 53 | Loss: 0.8543 | Acc: 80.94% | Precision: 81.21% | recall: 80.94% | f1: 80.95%\n",
      "Train - Epoch: 54 | Loss: 0.2399 | Acc: 92.65% | Precision: 92.66% | recall: 92.65% | f1: 92.65%\n",
      "Val - Epoch: 54 | Loss: 0.8640 | Acc: 80.74% | Precision: 81.31% | recall: 80.74% | f1: 80.76%\n",
      "Train - Epoch: 55 | Loss: 0.2480 | Acc: 92.13% | Precision: 92.13% | recall: 92.13% | f1: 92.13%\n",
      "Val - Epoch: 55 | Loss: 0.8979 | Acc: 80.16% | Precision: 81.29% | recall: 80.16% | f1: 80.30%\n",
      "Train - Epoch: 56 | Loss: 0.2805 | Acc: 91.32% | Precision: 91.32% | recall: 91.32% | f1: 91.31%\n",
      "Val - Epoch: 56 | Loss: 0.8659 | Acc: 81.72% | Precision: 82.15% | recall: 81.72% | f1: 81.77%\n",
      "Train - Epoch: 57 | Loss: 0.2371 | Acc: 92.47% | Precision: 92.48% | recall: 92.47% | f1: 92.47%\n",
      "Val - Epoch: 57 | Loss: 0.8124 | Acc: 81.92% | Precision: 82.22% | recall: 81.92% | f1: 81.90%\n",
      "Train - Epoch: 58 | Loss: 0.2317 | Acc: 92.57% | Precision: 92.58% | recall: 92.57% | f1: 92.57%\n",
      "Val - Epoch: 58 | Loss: 0.8652 | Acc: 81.92% | Precision: 82.44% | recall: 81.92% | f1: 82.04%\n",
      "Train - Epoch: 59 | Loss: 0.2469 | Acc: 92.23% | Precision: 92.23% | recall: 92.23% | f1: 92.23%\n",
      "Val - Epoch: 59 | Loss: 0.8559 | Acc: 82.18% | Precision: 82.83% | recall: 82.18% | f1: 82.26%\n",
      "Train - Epoch: 60 | Loss: 0.2315 | Acc: 92.85% | Precision: 92.86% | recall: 92.85% | f1: 92.85%\n",
      "Val - Epoch: 60 | Loss: 0.8168 | Acc: 83.55% | Precision: 83.85% | recall: 83.55% | f1: 83.60%\n",
      "Train - Epoch: 61 | Loss: 0.2171 | Acc: 93.31% | Precision: 93.31% | recall: 93.31% | f1: 93.31%\n",
      "Val - Epoch: 61 | Loss: 0.8332 | Acc: 82.44% | Precision: 82.92% | recall: 82.44% | f1: 82.45%\n",
      "Train - Epoch: 62 | Loss: 0.2041 | Acc: 93.31% | Precision: 93.32% | recall: 93.31% | f1: 93.31%\n",
      "Val - Epoch: 62 | Loss: 0.8206 | Acc: 83.16% | Precision: 83.47% | recall: 83.16% | f1: 83.19%\n",
      "Train - Epoch: 63 | Loss: 0.1978 | Acc: 93.63% | Precision: 93.64% | recall: 93.63% | f1: 93.64%\n",
      "Val - Epoch: 63 | Loss: 0.9235 | Acc: 82.11% | Precision: 83.37% | recall: 82.11% | f1: 82.20%\n",
      "Train - Epoch: 64 | Loss: 0.2159 | Acc: 92.82% | Precision: 92.82% | recall: 92.82% | f1: 92.82%\n",
      "Val - Epoch: 64 | Loss: 0.8453 | Acc: 82.18% | Precision: 82.74% | recall: 82.18% | f1: 82.25%\n",
      "Train - Epoch: 65 | Loss: 0.2032 | Acc: 93.55% | Precision: 93.55% | recall: 93.55% | f1: 93.55%\n",
      "Val - Epoch: 65 | Loss: 0.8607 | Acc: 82.70% | Precision: 83.22% | recall: 82.70% | f1: 82.78%\n",
      "Train - Epoch: 66 | Loss: 0.1896 | Acc: 94.17% | Precision: 94.18% | recall: 94.17% | f1: 94.17%\n",
      "Val - Epoch: 66 | Loss: 0.8627 | Acc: 83.49% | Precision: 83.65% | recall: 83.49% | f1: 83.50%\n",
      "Train - Epoch: 67 | Loss: 0.1855 | Acc: 94.27% | Precision: 94.27% | recall: 94.27% | f1: 94.27%\n",
      "Val - Epoch: 67 | Loss: 0.8924 | Acc: 82.64% | Precision: 83.16% | recall: 82.64% | f1: 82.73%\n",
      "Train - Epoch: 68 | Loss: 0.1933 | Acc: 93.94% | Precision: 93.95% | recall: 93.94% | f1: 93.94%\n",
      "Val - Epoch: 68 | Loss: 0.8599 | Acc: 82.77% | Precision: 83.60% | recall: 82.77% | f1: 82.85%\n",
      "Train - Epoch: 69 | Loss: 0.1430 | Acc: 95.63% | Precision: 95.63% | recall: 95.63% | f1: 95.63%\n",
      "Val - Epoch: 69 | Loss: 0.8730 | Acc: 82.83% | Precision: 82.98% | recall: 82.83% | f1: 82.85%\n",
      "Train - Epoch: 70 | Loss: 0.1219 | Acc: 96.41% | Precision: 96.41% | recall: 96.41% | f1: 96.41%\n",
      "Val - Epoch: 70 | Loss: 0.8847 | Acc: 83.68% | Precision: 83.86% | recall: 83.68% | f1: 83.67%\n",
      "Train - Epoch: 71 | Loss: 0.1103 | Acc: 96.44% | Precision: 96.44% | recall: 96.44% | f1: 96.44%\n",
      "Val - Epoch: 71 | Loss: 0.8648 | Acc: 83.22% | Precision: 83.95% | recall: 83.22% | f1: 83.34%\n",
      "Train - Epoch: 72 | Loss: 0.1106 | Acc: 96.54% | Precision: 96.54% | recall: 96.54% | f1: 96.54%\n",
      "Val - Epoch: 72 | Loss: 0.8629 | Acc: 83.22% | Precision: 83.57% | recall: 83.22% | f1: 83.25%\n",
      "Train - Epoch: 73 | Loss: 0.1117 | Acc: 96.77% | Precision: 96.77% | recall: 96.77% | f1: 96.77%\n",
      "Val - Epoch: 73 | Loss: 0.8672 | Acc: 83.09% | Precision: 83.15% | recall: 83.09% | f1: 83.08%\n",
      "Train - Epoch: 74 | Loss: 0.1148 | Acc: 96.54% | Precision: 96.54% | recall: 96.54% | f1: 96.54%\n",
      "Val - Epoch: 74 | Loss: 0.8389 | Acc: 83.42% | Precision: 83.69% | recall: 83.42% | f1: 83.44%\n",
      "Train - Epoch: 75 | Loss: 0.1154 | Acc: 96.56% | Precision: 96.56% | recall: 96.56% | f1: 96.56%\n",
      "Val - Epoch: 75 | Loss: 0.8448 | Acc: 83.29% | Precision: 83.37% | recall: 83.29% | f1: 83.28%\n",
      "Train - Epoch: 76 | Loss: 0.1074 | Acc: 96.91% | Precision: 96.92% | recall: 96.91% | f1: 96.91%\n",
      "Val - Epoch: 76 | Loss: 0.8993 | Acc: 83.42% | Precision: 83.81% | recall: 83.42% | f1: 83.47%\n",
      "Train - Epoch: 77 | Loss: 0.1001 | Acc: 97.13% | Precision: 97.13% | recall: 97.13% | f1: 97.13%\n",
      "Val - Epoch: 77 | Loss: 0.8808 | Acc: 83.49% | Precision: 83.56% | recall: 83.49% | f1: 83.47%\n",
      "Train - Epoch: 78 | Loss: 0.1081 | Acc: 96.65% | Precision: 96.65% | recall: 96.65% | f1: 96.65%\n",
      "Val - Epoch: 78 | Loss: 0.8772 | Acc: 83.29% | Precision: 83.58% | recall: 83.29% | f1: 83.29%\n",
      "Train - Epoch: 79 | Loss: 0.0907 | Acc: 97.24% | Precision: 97.24% | recall: 97.24% | f1: 97.24%\n",
      "Val - Epoch: 79 | Loss: 0.8785 | Acc: 83.16% | Precision: 83.27% | recall: 83.16% | f1: 83.13%\n",
      "Train - Epoch: 80 | Loss: 0.0701 | Acc: 97.93% | Precision: 97.93% | recall: 97.93% | f1: 97.93%\n",
      "Val - Epoch: 80 | Loss: 0.8721 | Acc: 84.07% | Precision: 84.17% | recall: 84.07% | f1: 84.07%\n",
      "Train - Epoch: 81 | Loss: 0.0727 | Acc: 97.75% | Precision: 97.75% | recall: 97.75% | f1: 97.75%\n",
      "Val - Epoch: 81 | Loss: 0.8721 | Acc: 83.62% | Precision: 83.68% | recall: 83.62% | f1: 83.62%\n",
      "Train - Epoch: 82 | Loss: 0.0720 | Acc: 97.93% | Precision: 97.93% | recall: 97.93% | f1: 97.93%\n",
      "Val - Epoch: 82 | Loss: 0.8851 | Acc: 83.94% | Precision: 84.18% | recall: 83.94% | f1: 83.93%\n",
      "Train - Epoch: 83 | Loss: 0.0633 | Acc: 98.17% | Precision: 98.17% | recall: 98.17% | f1: 98.17%\n",
      "Val - Epoch: 83 | Loss: 0.8953 | Acc: 83.62% | Precision: 83.73% | recall: 83.62% | f1: 83.60%\n",
      "Train - Epoch: 84 | Loss: 0.0629 | Acc: 98.11% | Precision: 98.11% | recall: 98.11% | f1: 98.11%\n",
      "Val - Epoch: 84 | Loss: 0.8906 | Acc: 83.75% | Precision: 83.79% | recall: 83.75% | f1: 83.73%\n",
      "Train - Epoch: 85 | Loss: 0.0682 | Acc: 98.04% | Precision: 98.04% | recall: 98.04% | f1: 98.04%\n",
      "Val - Epoch: 85 | Loss: 0.8897 | Acc: 83.49% | Precision: 83.56% | recall: 83.49% | f1: 83.48%\n",
      "Train - Epoch: 86 | Loss: 0.0622 | Acc: 98.19% | Precision: 98.19% | recall: 98.19% | f1: 98.19%\n",
      "Val - Epoch: 86 | Loss: 0.8909 | Acc: 83.55% | Precision: 83.68% | recall: 83.55% | f1: 83.54%\n",
      "Train - Epoch: 87 | Loss: 0.0711 | Acc: 97.93% | Precision: 97.93% | recall: 97.93% | f1: 97.93%\n",
      "Val - Epoch: 87 | Loss: 0.8956 | Acc: 84.14% | Precision: 84.30% | recall: 84.14% | f1: 84.12%\n",
      "Train - Epoch: 88 | Loss: 0.0625 | Acc: 98.01% | Precision: 98.01% | recall: 98.01% | f1: 98.01%\n",
      "Val - Epoch: 88 | Loss: 0.8977 | Acc: 83.75% | Precision: 83.78% | recall: 83.75% | f1: 83.73%\n",
      "Train - Epoch: 89 | Loss: 0.0664 | Acc: 98.19% | Precision: 98.19% | recall: 98.19% | f1: 98.19%\n",
      "Val - Epoch: 89 | Loss: 0.8724 | Acc: 83.94% | Precision: 83.96% | recall: 83.94% | f1: 83.92%\n",
      "Train - Epoch: 90 | Loss: 0.0727 | Acc: 97.71% | Precision: 97.72% | recall: 97.71% | f1: 97.71%\n",
      "Val - Epoch: 90 | Loss: 0.8692 | Acc: 83.88% | Precision: 84.17% | recall: 83.88% | f1: 83.93%\n",
      "Train - Epoch: 91 | Loss: 0.0699 | Acc: 97.85% | Precision: 97.85% | recall: 97.85% | f1: 97.85%\n",
      "Val - Epoch: 91 | Loss: 0.8581 | Acc: 84.01% | Precision: 84.12% | recall: 84.01% | f1: 83.98%\n",
      "Train - Epoch: 92 | Loss: 0.0609 | Acc: 98.07% | Precision: 98.08% | recall: 98.07% | f1: 98.07%\n",
      "Val - Epoch: 92 | Loss: 0.8847 | Acc: 83.55% | Precision: 83.59% | recall: 83.55% | f1: 83.54%\n",
      "Train - Epoch: 93 | Loss: 0.0675 | Acc: 97.88% | Precision: 97.88% | recall: 97.88% | f1: 97.88%\n",
      "Val - Epoch: 93 | Loss: 0.9089 | Acc: 84.20% | Precision: 84.35% | recall: 84.20% | f1: 84.18%\n",
      "Train - Epoch: 94 | Loss: 0.0675 | Acc: 97.88% | Precision: 97.88% | recall: 97.88% | f1: 97.88%\n",
      "Val - Epoch: 94 | Loss: 0.9175 | Acc: 83.68% | Precision: 83.80% | recall: 83.68% | f1: 83.66%\n",
      "Train - Epoch: 95 | Loss: 0.0628 | Acc: 98.06% | Precision: 98.06% | recall: 98.06% | f1: 98.06%\n",
      "Val - Epoch: 95 | Loss: 0.9010 | Acc: 83.81% | Precision: 84.11% | recall: 83.81% | f1: 83.84%\n",
      "Train - Epoch: 96 | Loss: 0.0658 | Acc: 98.19% | Precision: 98.19% | recall: 98.19% | f1: 98.19%\n",
      "Val - Epoch: 96 | Loss: 0.9219 | Acc: 83.49% | Precision: 84.16% | recall: 83.49% | f1: 83.55%\n",
      "Train - Epoch: 97 | Loss: 0.0564 | Acc: 98.22% | Precision: 98.22% | recall: 98.22% | f1: 98.22%\n",
      "Val - Epoch: 97 | Loss: 0.9303 | Acc: 83.81% | Precision: 83.93% | recall: 83.81% | f1: 83.79%\n",
      "Train - Epoch: 98 | Loss: 0.0641 | Acc: 98.16% | Precision: 98.16% | recall: 98.16% | f1: 98.16%\n",
      "Val - Epoch: 98 | Loss: 0.9091 | Acc: 83.62% | Precision: 83.78% | recall: 83.62% | f1: 83.60%\n",
      "Train - Epoch: 99 | Loss: 0.0582 | Acc: 98.22% | Precision: 98.22% | recall: 98.22% | f1: 98.22%\n",
      "Val - Epoch: 99 | Loss: 0.9517 | Acc: 83.55% | Precision: 83.79% | recall: 83.55% | f1: 83.54%\n",
      "Train - Epoch: 100 | Loss: 0.0583 | Acc: 98.20% | Precision: 98.21% | recall: 98.20% | f1: 98.20%\n",
      "Val - Epoch: 100 | Loss: 0.9113 | Acc: 83.22% | Precision: 83.49% | recall: 83.22% | f1: 83.22%\n",
      "Training completed in 9m 27s\n",
      "Best validation accuracy: 84.20%\n",
      "Loaded best model from epoch 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_281713/1727585784.py:307: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(best_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.969241773962804\n",
      "precision: 0.9693417285448676\n",
      "recall: 0.969241773962804\n",
      "F1 : 0.9692434215433547\n",
      "Test accuracy: 96.92%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example configuration\n",
    "    config = {\n",
    "        'lr': 3e-4,\n",
    "        'weight_decay': 1e-5,\n",
    "        'patience': 15,\n",
    "        'epochs': 100,\n",
    "        'experiment_name': 'eeg_attention_experiment',\n",
    "        'save_attention_maps': True\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_loader, val_loader, test_loader, trail_shape = get_data_loaders(data_dir=\"/teamspace/studios/shared-amethyst-w577/data2\", all_subjects = [1,2,3,4,5,6,7,8,9,10,11])\n",
    "    model = EEGClassifier(num_samples = trail_shape[-1], num_classes=7)\n",
    "    # Create trainer\n",
    "    trainer = EEGTrainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    # Start training\n",
    "    best_val_acc = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1488ba3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
