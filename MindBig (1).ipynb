{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b03eea36",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f557f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.signal import firwin, filtfilt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import warnings\n",
    "import torch\n",
    "import random\n",
    "from scipy.io import loadmat\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"mne\")\n",
    "# Completely silence MNE-Python output\n",
    "mne.set_log_level('WARNING')  # or 'ERROR' for even less output\n",
    "logging.getLogger('mne').setLevel(logging.WARNING)\n",
    "#mne.set_log_level('debug')\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fbae4a",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "055eea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(file_path, clas):\n",
    "\n",
    "    try:\n",
    "        raw = mne.io.read_raw_edf(file_path, preload=True)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR during file loading: {e}\")\n",
    "        return\n",
    "\n",
    "    epochs = mne.make_fixed_length_epochs(\n",
    "        raw, \n",
    "        duration=10.0, \n",
    "        overlap=1.0, \n",
    "    )\n",
    "\n",
    "    epochs.load_data() \n",
    "    label = epochs.get_data().shape[0]\n",
    "    labels=None\n",
    "    if clas == 'H':\n",
    "        labels = [0]*label\n",
    "    else:\n",
    "        labels = [1] * label\n",
    "\n",
    "    return {\"epochs\":epochs, \"labels\":labels}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c3a9d1",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe018fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.io as sio\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def gauss_smooth(inputs, device, smooth_kernel_std=2, smooth_kernel_size=100,  padding='same'):\n",
    "\n",
    "    #print(inputs.shape)\n",
    "    inputs = inputs.transpose(0, 2, 1)\n",
    "    # Get Gaussian kernel\n",
    "    inp = np.zeros(smooth_kernel_size, dtype=np.float32)\n",
    "    inp[smooth_kernel_size // 2] = 1\n",
    "    gaussKernel = gaussian_filter1d(inp, smooth_kernel_std)\n",
    "    validIdx = np.argwhere(gaussKernel > 0.01)\n",
    "    gaussKernel = gaussKernel[validIdx]\n",
    "    gaussKernel = np.squeeze(gaussKernel / np.sum(gaussKernel))\n",
    "\n",
    "    # Convert to tensor\n",
    "    gaussKernel = torch.tensor(gaussKernel, dtype=torch.float32, device=device)\n",
    "    gaussKernel = gaussKernel.view(1, 1, -1)  # [1, 1, kernel_size]\n",
    "\n",
    "    # Prepare convolution\n",
    "    B, T, C = inputs.shape\n",
    "    inputs = inputs.transpose(0, 2, 1)  # [B, C, T]\n",
    "    inputs = torch.tensor(inputs, dtype=torch.float32, device=device)\n",
    "    \n",
    "    gaussKernel = gaussKernel.repeat(C, 1, 1)  # [C, 1, kernel_size]\n",
    "\n",
    "    # Perform convolution\n",
    "    smoothed = F.conv1d(inputs, gaussKernel, padding=padding, groups=C)\n",
    "    return smoothed.detach().cpu().numpy()  # [B, T, C]\n",
    "\n",
    "from scipy.signal import filtfilt, butter\n",
    "\n",
    "def bandpass(data, low=1, high=40, fs=256, order=4):\n",
    "    nyq = fs / 2\n",
    "    b, a = butter(order, [low/nyq, high/nyq], btype='band')\n",
    "    \n",
    "    # Apply on axis=2 (time axis)\n",
    "    return filtfilt(b, a, data, axis=2)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "class BCI4_2a_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, transform=None, target_transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.data, self.labels = self._load_data()\n",
    "\n",
    "        self.labels = self.labels \n",
    "        # In your dataset __init__:\n",
    "        print(f\"Class distribution: {np.bincount(self.labels)}\")\n",
    "        print(f\"Class ratio: {np.bincount(self.labels)[1] / len(self.labels):.2%}\")\n",
    "\n",
    "\n",
    "    def _load_data(self):\n",
    "\n",
    "        df = pd.read_csv(self.data_dir, header=None)\n",
    "        df = df[df.iloc[:, 2] != -1]\n",
    "        labels = df.iloc[:, 2].values\n",
    "        all_data = []\n",
    "\n",
    "        for i, row in df.iterrows():\n",
    "            data = row.iloc[788:].astype(float).values.reshape(64, 400)\n",
    "            all_data.append(data)\n",
    "            exp_data = np.expand_dims(data, axis=0)\n",
    "            aug1 = gauss_smooth(exp_data, device='cpu', smooth_kernel_std=0.7, smooth_kernel_size=20)\n",
    "            aug2 = gauss_smooth(exp_data, device='cpu', smooth_kernel_std=2.0, smooth_kernel_size=50)\n",
    "            aug3 = gauss_smooth(exp_data, device='cpu', smooth_kernel_std=2, smooth_kernel_size=50)\n",
    "            all_data.append(np.squeeze(aug1, axis=0))\n",
    "            all_data.append(np.squeeze(aug2, axis=0))\n",
    "            all_data.append(np.squeeze(aug3, axis=0))\n",
    "        \n",
    "        # Convert list â†’ NumPy array\n",
    "        all_data = np.stack(all_data)\n",
    " \n",
    "        labels = np.repeat(labels, 4)\n",
    "\n",
    "        return all_data, labels\n",
    "    \n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.labels[idx]\n",
    "        \n",
    "        x = torch.from_numpy(x).float()  # shape: (1, timepoints, channels)\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        if self.target_transform:\n",
    "            y = self.target_transform(y)\n",
    "            \n",
    "        return x, y\n",
    "\n",
    "def get_data_loaders(data_dir, batch_size=32, test_split= 0.2, val_split=0.2, random_state=42):\n",
    "    # Get all subjects except the test subject for training/validation\n",
    "    \n",
    "    #train_val_subjects = [s for s in all_subjects if s not in test_subject]\n",
    "    \n",
    "    # Create datasets\n",
    "    train_val_dataset = BCI4_2a_Dataset(data_dir)\n",
    "    single_trial_shape = train_val_dataset.data[0].shape\n",
    "    # labels = np.array(train_val_dataset.labels)\n",
    "    # class_weights = compute_class_weight(class_weight='balanced',\n",
    "    #                                  classes=np.unique(labels),\n",
    "    #                                  y=labels)\n",
    "\n",
    "    # class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "    print(f\"Train+Val dataset size: {len(train_val_dataset)}\")\n",
    "    \n",
    "    train_idx, val_idx = train_test_split(\n",
    "        range(len(train_val_dataset)),\n",
    "        test_size=test_split,          # e.g., 0.2\n",
    "        random_state=random_state,\n",
    "        stratify=train_val_dataset.labels\n",
    "    )\n",
    "  \n",
    "\n",
    "    \n",
    "    train_dataset = torch.utils.data.Subset(train_val_dataset, train_idx)\n",
    "    val_dataset = torch.utils.data.Subset(train_val_dataset, val_idx)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print(f\"Train batches: {len(train_loader)}\")\n",
    "    print(f\"Val batches: {len(val_loader)}\")\n",
    "    print(f\"Single Trial Shape: {single_trial_shape}\")\n",
    "    return train_loader, val_loader, single_trial_shape,None# class_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449a4378",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "135ecd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, num_channels, reduction_ratio=4, dropout=0.1):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(num_channels, num_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),  # Added dropout\n",
    "            nn.Linear(num_channels // reduction_ratio, num_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        channel_avg = torch.mean(x, dim=2, keepdim=True)  \n",
    "        channel_max, _ = torch.max(x, dim=2, keepdim=True) \n",
    "        combined = channel_avg + channel_max  \n",
    "        combined = combined.squeeze(2)\n",
    "        attention = self.mlp(combined)\n",
    "        attention = torch.sigmoid(attention).unsqueeze(2)\n",
    "        attended_x = x * attention\n",
    "        return attended_x, attention.squeeze(2)  # Return proper attention scores\n",
    "\n",
    "\n",
    "class LearnableSTFT(nn.Module):\n",
    "    def __init__(self, window_size, hop_size, learnable_window=True, dropout=0.05):\n",
    "        super(LearnableSTFT, self).__init__()\n",
    "        \n",
    "        self.window_size = window_size\n",
    "        self.hop_size = hop_size\n",
    "        self.dft_size = window_size\n",
    "        self.learnable_window = learnable_window\n",
    "        \n",
    "        # Initialize with Hamming window\n",
    "        initial_window = 0.54 - 0.46 * torch.cos(\n",
    "            2 * math.pi * torch.arange(window_size, dtype=torch.float32) / (window_size - 1)\n",
    "        )\n",
    "        \n",
    "        if learnable_window:\n",
    "            self.window = nn.Parameter(initial_window)\n",
    "        else:\n",
    "            # Fixed window reduces overfitting\n",
    "            self.register_buffer('window', initial_window)\n",
    "        \n",
    "        # Batch normalization after STFT\n",
    "        self.batch_norm = nn.BatchNorm2d(1)\n",
    "        self.dropout = nn.Dropout2d(dropout)\n",
    "        \n",
    "        dft_matrix = self._create_dft_matrix(self.dft_size, self.window_size)\n",
    "        self.register_buffer('dft_matrix', dft_matrix)\n",
    "\n",
    "    def _create_dft_matrix(self, dft_size, window_size):\n",
    "        k = torch.arange(dft_size).unsqueeze(1)\n",
    "        n = torch.arange(window_size)\n",
    "        angle = -2 * math.pi * k * n / dft_size\n",
    "        dft_matrix = torch.complex(torch.cos(angle), torch.sin(angle))\n",
    "        return dft_matrix\n",
    "\n",
    "    def forward(self, signal):\n",
    "        if signal.dim() == 1:\n",
    "            signal = signal.unsqueeze(0).unsqueeze(0)\n",
    "        elif signal.dim() == 2:\n",
    "            signal = signal.unsqueeze(1)\n",
    "            \n",
    "        batch_size, num_channels, num_samples = signal.shape\n",
    "        signal_reshaped = signal.reshape(batch_size * num_channels, num_samples)\n",
    "        \n",
    "        frames = signal_reshaped.unfold(dimension=1, size=self.window_size, step=self.hop_size)\n",
    "        num_frames_unfolded = frames.shape[1]\n",
    "        expected_num_frames = int(math.ceil((num_samples - self.window_size) / self.hop_size)) + 1\n",
    "        \n",
    "        if num_frames_unfolded < expected_num_frames:\n",
    "            padding_amount = (expected_num_frames - 1) * self.hop_size + self.window_size - num_samples\n",
    "            padded_signal = torch.nn.functional.pad(signal_reshaped, (0, padding_amount))\n",
    "            frames = padded_signal.unfold(1, self.window_size, self.hop_size)\n",
    "        \n",
    "        windowed_frames = frames * self.window\n",
    "        BC, F, W = windowed_frames.shape\n",
    "        windowed_frames_reshaped = windowed_frames.reshape(BC * F, W)\n",
    "        \n",
    "        windowed_frames_complex = windowed_frames_reshaped.to(self.dft_matrix.dtype)\n",
    "        stft_result_reshaped = self.dft_matrix @ windowed_frames_complex.T\n",
    "        stft_result = stft_result_reshaped.T.reshape(batch_size, num_channels, F, self.dft_size)\n",
    "        \n",
    "        # Apply magnitude and normalization\n",
    "        stft_magnitude = torch.abs(stft_result)\n",
    "        \n",
    "        # Reshape for batch norm: (B*C, 1, F, freq_bins)\n",
    "        stft_normalized = stft_magnitude.reshape(batch_size * num_channels, 1, F, self.dft_size)\n",
    "        stft_normalized = self.batch_norm(stft_normalized)\n",
    "        stft_normalized = self.dropout(stft_normalized)\n",
    "        stft_normalized = stft_normalized.reshape(batch_size, num_channels, F, self.dft_size)\n",
    "        \n",
    "        return stft_normalized\n",
    "\n",
    "\n",
    "class Attention4D(nn.Module):\n",
    "    def __init__(self, in_channels, time_frames, freq_bins, d_model=128, n_heads=4, \n",
    "                 d_ff=256, dropout=0.2, num_layers=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.time_frames = time_frames\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        in_features = in_channels * freq_bins\n",
    "        \n",
    "        # Project input to d_model with layer norm\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(in_features, d_model),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # Learnable positional encoding with smaller init\n",
    "        self.positional_encoding = nn.Parameter(\n",
    "            torch.randn(1, time_frames, d_model) * 0.02\n",
    "        )\n",
    "        \n",
    "        # Stack multiple transformer layers for better representation\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            TransformerBlock(d_model, n_heads, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.final_norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Reshape: (B, C, T, F) -> (B, T, C*F)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        x = x.reshape(batch_size, self.time_frames, -1)\n",
    "        \n",
    "        # Project and add positional encoding\n",
    "        x = self.projection(x)\n",
    "        x = x + self.positional_encoding\n",
    "        \n",
    "        # Store attention weights from all layers\n",
    "        all_attention_weights = []\n",
    "        \n",
    "        # Pass through transformer layers\n",
    "        for layer in self.transformer_layers:\n",
    "            x, attn_weights = layer(x)\n",
    "            all_attention_weights.append(attn_weights)\n",
    "        \n",
    "        x = self.final_norm(x)\n",
    "        \n",
    "        return x, all_attention_weights\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=d_model, \n",
    "            num_heads=n_heads, \n",
    "            dropout=dropout, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.GELU(),  # GELU often works better than ReLU\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Pre-norm architecture (more stable)\n",
    "        x_norm = self.layernorm1(x)\n",
    "        attn_output, attn_weights = self.attention(x_norm, x_norm, x_norm, \n",
    "                                                    need_weights=True, \n",
    "                                                    average_attn_weights=True)\n",
    "        x = x + self.dropout1(attn_output)\n",
    "        \n",
    "        x_norm = self.layernorm2(x)\n",
    "        ff_output = self.feed_forward(x_norm)\n",
    "        x = x + self.dropout2(ff_output)\n",
    "        \n",
    "        return x, attn_weights\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_features, num_classes, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # Add intermediate layer for better capacity\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features // 2),\n",
    "            nn.LayerNorm(in_features // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_features // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # (B, d_model, T)\n",
    "        x = self.pooling(x).squeeze(2)  # (B, d_model)\n",
    "        output = self.classifier(x)  # (B, num_classes)\n",
    "        return output\n",
    "\n",
    "\n",
    "class EEGClassifier(nn.Module):\n",
    "    def __init__(self, num_samples, num_classes=4, window_percent=0.25, \n",
    "                 overlap_percent=0.10, d_model=128, n_heads=8, \n",
    "                 transformer_layers=1, dropout=0.2, learnable_window=True):\n",
    "\n",
    "        super(EEGClassifier, self).__init__()\n",
    "        \n",
    "        window_size = int(num_samples * window_percent)\n",
    "        hop_size = int(num_samples * overlap_percent)\n",
    "        \n",
    "        self.window_size = max(window_size, 40)\n",
    "        self.hop_size = max(hop_size, 20)\n",
    "        \n",
    "        self.channel_attn = ChannelAttention(num_channels=64, dropout=dropout)\n",
    "        \n",
    "        self.learnable_stft = LearnableSTFT(\n",
    "            window_size=self.window_size,\n",
    "            hop_size=self.hop_size,\n",
    "            learnable_window=learnable_window,\n",
    "            dropout=dropout * 0.5\n",
    "        )\n",
    "        \n",
    "        time_frames = int(math.ceil((num_samples - self.window_size) / self.hop_size)) + 1\n",
    "        \n",
    "        self.attention_module = Attention4D(\n",
    "            in_channels=64,\n",
    "            time_frames=time_frames,\n",
    "            freq_bins=self.window_size,\n",
    "            d_model=d_model,\n",
    "            n_heads=n_heads,\n",
    "            num_layers=transformer_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.classifier = Classifier(\n",
    "            in_features=d_model, \n",
    "            num_classes=num_classes,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, x, return_attention=False):\n",
    "\n",
    "        # Channel attention\n",
    "        x, channel_attn_scores = self.channel_attn(x)\n",
    "        \n",
    "        # STFT\n",
    "        x = self.learnable_stft(x)\n",
    "        \n",
    "        # Transformer attention\n",
    "        x, transformer_attn_weights = self.attention_module(x)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(x)\n",
    "        \n",
    "        if return_attention:\n",
    "            attention_dict = {\n",
    "                'channel_attention': channel_attn_scores,  # (B, 22)\n",
    "                'transformer_attention': transformer_attn_weights,  # List of (B, T, T) for each layer\n",
    "            }\n",
    "            return logits, attention_dict\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "class AttentionRegularizedLoss(nn.Module):\n",
    "    def __init__(self, num_classes, alpha=0.01, beta=0.01):\n",
    "        super().__init__()\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.alpha = alpha  # Channel attention regularization weight\n",
    "        self.beta = beta    # Transformer attention regularization weight\n",
    "        \n",
    "    def forward(self, logits, targets, attention_dict):\n",
    "        ce = self.ce_loss(logits, targets)\n",
    "        channel_attn = attention_dict['channel_attention']  # (B, C)\n",
    "        channel_attn_norm = channel_attn + 1e-8\n",
    "        channel_attn_norm = channel_attn_norm / channel_attn_norm.sum(dim=1, keepdim=True)\n",
    "        channel_entropy = -(channel_attn_norm * torch.log(channel_attn_norm)).sum(dim=1).mean()\n",
    "        channel_reg = -self.alpha * channel_entropy  # Negative because we want to maximize entropy\n",
    "        transformer_attn = attention_dict['transformer_attention'][-1]  # (B, T, T)\n",
    "        attn_norm = transformer_attn + 1e-8\n",
    "        attn_norm = attn_norm / attn_norm.sum(dim=-1, keepdim=True)\n",
    "        attn_entropy = -(attn_norm * torch.log(attn_norm)).sum(dim=-1).mean()\n",
    "        transformer_reg = -self.beta * attn_entropy  # Maximize entropy\n",
    "\n",
    "        total_loss = ce + channel_reg + transformer_reg\n",
    "        \n",
    "        return total_loss, {\n",
    "            'ce_loss': ce.item(),\n",
    "            'channel_reg': channel_reg.item(),\n",
    "            'transformer_reg': transformer_reg.item(),\n",
    "            'total_loss': total_loss.item()\n",
    "        }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f850fe",
   "metadata": {},
   "source": [
    "# test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "484720f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     # Model initialization\n",
    "#     model = EEGClassifier(\n",
    "#         num_samples=1000,\n",
    "#         num_classes=4,\n",
    "#         d_model=64,  # Reduced from 128\n",
    "#         n_heads=4,   # Reduced from 8\n",
    "#         transformer_layers=2,\n",
    "#         dropout=0.3,\n",
    "#         learnable_window=False  # Start with fixed window\n",
    "#     )\n",
    "    \n",
    "#     # Loss function\n",
    "#     criterion = AttentionRegularizedLoss(num_classes=4, alpha=0.01, beta=0.01)\n",
    "    \n",
    "#     # Dummy data\n",
    "#     x = torch.randn(4, 22, 1000)  # (batch, channels, time)\n",
    "#     y = torch.randint(0, 4, (4,))\n",
    "    \n",
    "#     # Forward pass with attention\n",
    "#     logits, attention_dict = model(x, return_attention=True)\n",
    "    \n",
    "#     # Calculate loss\n",
    "#     loss, loss_dict = criterion(logits, y, attention_dict)\n",
    "    \n",
    "#     print(f\"Logits shape: {logits.shape}\")\n",
    "#     print(f\"Channel attention shape: {attention_dict['channel_attention'].shape}\")\n",
    "#     print(f\"Num transformer layers: {len(attention_dict['transformer_attention'])}\")\n",
    "#     print(f\"Transformer attention shape: {attention_dict['transformer_attention'][0].shape}\")\n",
    "#     print(f\"Total loss: {loss.item():.4f}\")\n",
    "#     print(f\"Loss components: {loss_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313f023b",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c483a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 04:03:46.354581: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-30 04:03:46.403197: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-30 04:03:46.403237: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-30 04:03:46.403276: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-30 04:03:46.412470: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 04:03:47.664456: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import json\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "class EEGTrainer:\n",
    "    def __init__(self, model, train_loader, val_loader ,class_weights=None,test_loader=None, config=None):\n",
    "\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        \n",
    "        # Set device\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.class_weights = class_weights\n",
    "        # Default configuration\n",
    "        self.config = {\n",
    "            'lr': 1e-3,\n",
    "            'weight_decay': 1e-4,\n",
    "            'patience': 10,\n",
    "            'min_lr': 1e-6,\n",
    "            'epochs': 100,\n",
    "            'save_dir': 'experiments',\n",
    "            'experiment_name': f'exp_{time.strftime(\"%Y%m%d-%H%M%S\")}',\n",
    "            'save_attention_maps': True,\n",
    "            'attention_map_freq': 5\n",
    "        }\n",
    "        \n",
    "        # Update with user config if provided\n",
    "        if config:\n",
    "            self.config.update(config)\n",
    "            \n",
    "        # Create experiment directory\n",
    "        self.exp_dir = os.path.join(self.config['save_dir'], self.config['experiment_name'])\n",
    "        os.makedirs(self.exp_dir, exist_ok=True)\n",
    "        \n",
    "        # Initialize components\n",
    "        self._init_components()\n",
    "        \n",
    "        # Save config\n",
    "        self._save_config()\n",
    "        \n",
    "    def _init_components(self):\n",
    "        \"\"\"Initialize training components\"\"\"\n",
    "        # Loss function (CrossEntropy + KLDiv for attention regularization)\n",
    "        #self.criterion = nn.CrossEntropyLoss()#weight=self.class_weights)\n",
    "        self.criterion = AttentionRegularizedLoss(num_classes=10)\n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=self.config['lr'],\n",
    "            weight_decay=self.config['weight_decay']\n",
    "        )\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        self.scheduler = ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='max',\n",
    "            factor=0.5,\n",
    "            patience=self.config['patience']//2,\n",
    "            min_lr=self.config['min_lr'],\n",
    "            #verbose=True\n",
    "        )\n",
    "        \n",
    "        self.best_val_acc = 0.0\n",
    "        self.early_stop_counter = 0\n",
    "        \n",
    "        # Tensorboard writer\n",
    "        self.writer = SummaryWriter(log_dir=self.exp_dir)\n",
    "        \n",
    "        # Attention maps directory\n",
    "        if self.config['save_attention_maps']:\n",
    "            self.attention_dir = os.path.join(self.exp_dir, 'attention_maps')\n",
    "            os.makedirs(self.attention_dir, exist_ok=True)\n",
    "    \n",
    "    def _save_config(self):\n",
    "        config_path = os.path.join(self.exp_dir, 'config.json')\n",
    "        with open(config_path, 'w') as f:\n",
    "            json.dump(self.config, f, indent=4)\n",
    "    \n",
    "    def _compute_metrics(self, outputs, labels):\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        accuracy = correct / labels.size(0)\n",
    "        return accuracy\n",
    "    \n",
    "    def _log_metrics(self, phase, metrics, epoch):\n",
    "        loss = metrics['loss']\n",
    "        acc = metrics['accuracy']\n",
    "        pre = metrics['precision']\n",
    "        rec = metrics['recall']\n",
    "        f1 = metrics['f1']\n",
    "        \n",
    "        # Console logging\n",
    "        print(f\"{phase.capitalize()} - Epoch: {epoch+1} | \"\n",
    "              f\"Loss: {loss:.4f} | Acc: {acc:.2%} | Precision: {pre:.2%} | recall: {rec:.2%} | f1: {f1:.2%}\")\n",
    "        \n",
    "        # Tensorboard logging\n",
    "        self.writer.add_scalar(f'Loss/{phase}', loss, epoch)\n",
    "        self.writer.add_scalar(f'Accuracy/{phase}', acc, epoch)\n",
    "        \n",
    "        \n",
    "        # Log learning rate\n",
    "        if phase == 'train':\n",
    "            lr = self.optimizer.param_groups[0]['lr']\n",
    "            self.writer.add_scalar('LR', lr, epoch)\n",
    "    \n",
    "    def _save_checkpoint(self, epoch, is_best=False):\n",
    "        \"\"\"Save model checkpoint\"\"\"\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'state_dict': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "            'scheduler': self.scheduler.state_dict(),\n",
    "            'best_val_acc': self.best_val_acc\n",
    "        }\n",
    "        \n",
    "        # Save regular checkpoint\n",
    "        checkpoint_path = os.path.join(self.exp_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "        torch.save(state, checkpoint_path)\n",
    "        \n",
    "        # Save best model\n",
    "        if is_best:\n",
    "            best_path = os.path.join(self.exp_dir, 'best_model.pth')\n",
    "            torch.save(state, best_path)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Store all predictions and labels for epoch-wise metrics\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for inputs, labels in self.train_loader:\n",
    "            inputs = inputs.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "\n",
    "            # Zero gradients\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs, attention_dict = self.model(inputs, return_attention=True)\n",
    "            loss ,_ = self.criterion(outputs, labels,attention_dict)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # ----- accumulate loss -----\n",
    "            batch_size = inputs.size(0)\n",
    "            running_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "            # ----- accumulate preds + labels for metrics -----\n",
    "            preds = torch.argmax(outputs, dim=1)          # [B]\n",
    "            all_preds.append(preds.detach().cpu())\n",
    "            all_labels.append(labels.detach().cpu())\n",
    "\n",
    "        # ---- end of epoch: stack everything and compute metrics ----\n",
    "        all_preds = torch.cat(all_preds).numpy()\n",
    "        all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "        epoch_loss = running_loss / total_samples\n",
    "\n",
    "        # accuracy\n",
    "        epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "        # precision, recall, f1\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_labels,\n",
    "            all_preds,\n",
    "            average='weighted',      # change to 'macro' / 'binary' if needed\n",
    "            zero_division=0          # avoid NaN if a class is missing in preds\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'loss': epoch_loss,\n",
    "            'accuracy': epoch_acc,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "        }\n",
    "\n",
    "\n",
    "    \n",
    "    def validate_epoch(self, epoch):\n",
    "        \"\"\"Validate for one epoch\"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.val_loader:\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "     \n",
    "                # Forward pass\n",
    "                #outputs = self.model(inputs)\n",
    "                outputs, attention_dict = self.model(inputs, return_attention=True)\n",
    "                loss, _ = self.criterion(outputs, labels, attention_dict)\n",
    "                #loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                batch_size = inputs.size(0)\n",
    "                running_loss += loss.item() * batch_size\n",
    "                total_samples += batch_size\n",
    "\n",
    "                # ----- accumulate preds + labels for metrics -----\n",
    "                preds = torch.argmax(outputs, dim=1)          # [B]\n",
    "                all_preds.append(preds.detach().cpu())\n",
    "                all_labels.append(labels.detach().cpu())\n",
    "\n",
    "            # ---- end of epoch: stack everything and compute metrics ----\n",
    "            all_preds = torch.cat(all_preds).numpy()\n",
    "            all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "            epoch_loss = running_loss / total_samples\n",
    "\n",
    "            # accuracy\n",
    "            epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "            # precision, recall, f1\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                all_labels,\n",
    "                all_preds,\n",
    "                average='weighted',      # change to 'macro' / 'binary' if needed\n",
    "                zero_division=0          # avoid NaN if a class is missing in preds\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                'loss': epoch_loss,\n",
    "                'accuracy': epoch_acc,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1,\n",
    "            }\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Main training loop\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(self.config['epochs']):\n",
    "            # Train and validate\n",
    "            train_metrics = self.train_epoch(epoch)\n",
    "            val_metrics = self.validate_epoch(epoch)\n",
    "            \n",
    "            # Log metrics\n",
    "            self._log_metrics('train', train_metrics, epoch)\n",
    "            self._log_metrics('val', val_metrics, epoch)\n",
    "            \n",
    "            # Save attention maps periodically\n",
    "            \n",
    "            # Step scheduler\n",
    "            self.scheduler.step(val_metrics['accuracy'])\n",
    "            \n",
    "            # Check for best model\n",
    "            if val_metrics['accuracy'] > self.best_val_acc:\n",
    "                self.best_val_acc = val_metrics['accuracy']\n",
    "                self._save_checkpoint(epoch, is_best=True)\n",
    "                self.early_stop_counter = 0\n",
    "            else:\n",
    "                self.early_stop_counter += 1\n",
    "            \n",
    "            # Save checkpoint periodically\n",
    "            if epoch % 10 == 0:\n",
    "                self._save_checkpoint(epoch)\n",
    "            \n",
    "            # Early stopping\n",
    "            # if self.early_stop_counter >= self.config['patience']:\n",
    "            #     print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            #     break\n",
    "        \n",
    "        # Training complete\n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"Training completed in {training_time//60:.0f}m {training_time%60:.0f}s\")\n",
    "        print(f\"Best validation accuracy: {self.best_val_acc:.2%}\")\n",
    "        \n",
    "        # Test if test loader provided\n",
    "        if self.test_loader:\n",
    "            test_acc = self.test()\n",
    "            print(f\"Test accuracy: {test_acc:.2%}\")\n",
    "        \n",
    "        # Close tensorboard writer\n",
    "        self.writer.close()\n",
    "        \n",
    "        return self.best_val_acc\n",
    "    \n",
    "    def test(self):\n",
    "        \"\"\"Evaluate on test set\"\"\"\n",
    "        self.model.eval()\n",
    "        running_acc = 0.0\n",
    "        total_samples = 0\n",
    "        \n",
    "        # Load best model\n",
    "        best_path = os.path.join(self.exp_dir, 'best_model.pth')\n",
    "        if os.path.exists(best_path):\n",
    "            checkpoint = torch.load(best_path)\n",
    "            self.model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n",
    "        \n",
    "        all_preds=[]\n",
    "        all_labels=[]\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.test_loader:\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                batch_size = inputs.size(0)\n",
    "                total_samples += batch_size\n",
    "\n",
    "                # ----- accumulate preds + labels for metrics -----\n",
    "                preds = torch.argmax(outputs, dim=1)          # [B]\n",
    "                all_preds.append(preds.detach().cpu())\n",
    "                all_labels.append(labels.detach().cpu())\n",
    "\n",
    "            # ---- end of epoch: stack everything and compute metrics ----\n",
    "            all_preds = torch.cat(all_preds).numpy()\n",
    "            all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "            epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "            # precision, recall, f1\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                all_labels,\n",
    "                all_preds,\n",
    "                average='binary',      # change to 'macro' / 'binary' if needed\n",
    "                zero_division=0          # avoid NaN if a class is missing in preds\n",
    "            )\n",
    "        \n",
    "        test_acc = epoch_acc\n",
    "        self.writer.add_scalar('Accuracy/test', test_acc)\n",
    "        print(\"acc: \",test_acc)\n",
    "        print(\"precision:\", precision)\n",
    "        print(\"recall:\", recall)\n",
    "        print(\"F1 :\", f1)\n",
    "        return epoch_acc\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef686541",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf259697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: [456 556 460 444 484 416 428 552 408 460]\n",
      "Class ratio: 11.92%\n",
      "Train+Val dataset size: 4664\n",
      "Train batches: 117\n",
      "Val batches: 30\n",
      "Single Trial Shape: (64, 400)\n",
      "Train - Epoch: 1 | Loss: 2.2656 | Acc: 11.07% | Precision: 10.20% | recall: 11.07% | f1: 9.56%\n",
      "Val - Epoch: 1 | Loss: 2.2392 | Acc: 11.90% | Precision: 7.35% | recall: 11.90% | f1: 2.72%\n",
      "Train - Epoch: 2 | Loss: 2.2500 | Acc: 12.62% | Precision: 10.50% | recall: 12.62% | f1: 10.16%\n",
      "Val - Epoch: 2 | Loss: 2.2351 | Acc: 12.65% | Precision: 4.35% | recall: 12.65% | f1: 6.02%\n",
      "Train - Epoch: 3 | Loss: 2.2448 | Acc: 12.57% | Precision: 12.09% | recall: 12.57% | f1: 9.91%\n",
      "Val - Epoch: 3 | Loss: 2.2318 | Acc: 14.15% | Precision: 3.57% | recall: 14.15% | f1: 5.06%\n",
      "Train - Epoch: 4 | Loss: 2.2429 | Acc: 11.63% | Precision: 11.04% | recall: 11.63% | f1: 8.91%\n",
      "Val - Epoch: 4 | Loss: 2.2347 | Acc: 11.79% | Precision: 1.39% | recall: 11.79% | f1: 2.49%\n",
      "Train - Epoch: 5 | Loss: 2.2389 | Acc: 12.36% | Precision: 11.09% | recall: 12.36% | f1: 9.10%\n",
      "Val - Epoch: 5 | Loss: 2.2228 | Acc: 13.72% | Precision: 12.79% | recall: 13.72% | f1: 5.44%\n",
      "Train - Epoch: 6 | Loss: 2.2280 | Acc: 13.37% | Precision: 13.48% | recall: 13.37% | f1: 11.09%\n",
      "Val - Epoch: 6 | Loss: 2.2177 | Acc: 13.50% | Precision: 9.67% | recall: 13.50% | f1: 5.03%\n",
      "Train - Epoch: 7 | Loss: 2.2208 | Acc: 14.74% | Precision: 16.32% | recall: 14.74% | f1: 12.29%\n",
      "Val - Epoch: 7 | Loss: 2.2142 | Acc: 14.15% | Precision: 12.23% | recall: 14.15% | f1: 9.27%\n",
      "Train - Epoch: 8 | Loss: 2.2183 | Acc: 13.43% | Precision: 14.33% | recall: 13.43% | f1: 12.18%\n",
      "Val - Epoch: 8 | Loss: 2.2055 | Acc: 15.54% | Precision: 11.78% | recall: 15.54% | f1: 11.19%\n",
      "Train - Epoch: 9 | Loss: 2.2094 | Acc: 14.79% | Precision: 14.38% | recall: 14.79% | f1: 13.45%\n",
      "Val - Epoch: 9 | Loss: 2.2003 | Acc: 17.04% | Precision: 20.02% | recall: 17.04% | f1: 11.39%\n",
      "Train - Epoch: 10 | Loss: 2.2024 | Acc: 13.45% | Precision: 13.52% | recall: 13.45% | f1: 11.98%\n",
      "Val - Epoch: 10 | Loss: 2.1894 | Acc: 15.33% | Precision: 19.80% | recall: 15.33% | f1: 11.11%\n",
      "Train - Epoch: 11 | Loss: 2.1975 | Acc: 15.30% | Precision: 15.40% | recall: 15.30% | f1: 14.45%\n",
      "Val - Epoch: 11 | Loss: 2.1856 | Acc: 18.11% | Precision: 21.30% | recall: 18.11% | f1: 13.57%\n",
      "Train - Epoch: 12 | Loss: 2.1794 | Acc: 17.39% | Precision: 18.08% | recall: 17.39% | f1: 16.65%\n",
      "Val - Epoch: 12 | Loss: 2.1625 | Acc: 19.08% | Precision: 27.19% | recall: 19.08% | f1: 16.02%\n",
      "Train - Epoch: 13 | Loss: 2.1649 | Acc: 17.26% | Precision: 17.04% | recall: 17.26% | f1: 16.45%\n",
      "Val - Epoch: 13 | Loss: 2.1632 | Acc: 17.04% | Precision: 19.19% | recall: 17.04% | f1: 14.17%\n",
      "Train - Epoch: 14 | Loss: 2.1610 | Acc: 18.41% | Precision: 19.03% | recall: 18.41% | f1: 17.86%\n",
      "Val - Epoch: 14 | Loss: 2.1429 | Acc: 18.65% | Precision: 27.10% | recall: 18.65% | f1: 14.52%\n",
      "Train - Epoch: 15 | Loss: 2.1438 | Acc: 20.40% | Precision: 20.62% | recall: 20.40% | f1: 19.69%\n",
      "Val - Epoch: 15 | Loss: 2.1261 | Acc: 18.54% | Precision: 20.91% | recall: 18.54% | f1: 13.74%\n",
      "Train - Epoch: 16 | Loss: 2.1168 | Acc: 21.31% | Precision: 21.41% | recall: 21.31% | f1: 20.54%\n",
      "Val - Epoch: 16 | Loss: 2.1279 | Acc: 21.22% | Precision: 30.37% | recall: 21.22% | f1: 16.65%\n",
      "Train - Epoch: 17 | Loss: 2.1248 | Acc: 20.85% | Precision: 20.63% | recall: 20.85% | f1: 20.27%\n",
      "Val - Epoch: 17 | Loss: 2.1178 | Acc: 21.33% | Precision: 21.45% | recall: 21.33% | f1: 18.88%\n",
      "Train - Epoch: 18 | Loss: 2.0980 | Acc: 21.95% | Precision: 21.87% | recall: 21.95% | f1: 21.43%\n",
      "Val - Epoch: 18 | Loss: 2.0608 | Acc: 24.22% | Precision: 29.40% | recall: 24.22% | f1: 21.40%\n",
      "Train - Epoch: 19 | Loss: 2.0768 | Acc: 23.45% | Precision: 23.97% | recall: 23.45% | f1: 22.85%\n",
      "Val - Epoch: 19 | Loss: 2.0644 | Acc: 25.29% | Precision: 25.15% | recall: 25.29% | f1: 23.69%\n",
      "Train - Epoch: 20 | Loss: 2.0614 | Acc: 24.15% | Precision: 24.25% | recall: 24.15% | f1: 23.65%\n",
      "Val - Epoch: 20 | Loss: 2.0347 | Acc: 25.94% | Precision: 32.97% | recall: 25.94% | f1: 24.24%\n",
      "Train - Epoch: 21 | Loss: 2.0329 | Acc: 26.05% | Precision: 26.15% | recall: 26.05% | f1: 25.76%\n",
      "Val - Epoch: 21 | Loss: 2.0349 | Acc: 27.87% | Precision: 34.79% | recall: 27.87% | f1: 25.37%\n",
      "Train - Epoch: 22 | Loss: 2.0215 | Acc: 26.45% | Precision: 26.69% | recall: 26.45% | f1: 25.93%\n",
      "Val - Epoch: 22 | Loss: 2.0213 | Acc: 29.15% | Precision: 35.72% | recall: 29.15% | f1: 26.95%\n",
      "Train - Epoch: 23 | Loss: 1.9982 | Acc: 27.74% | Precision: 28.15% | recall: 27.74% | f1: 27.49%\n",
      "Val - Epoch: 23 | Loss: 1.9724 | Acc: 30.44% | Precision: 36.18% | recall: 30.44% | f1: 29.61%\n",
      "Train - Epoch: 24 | Loss: 1.9825 | Acc: 29.03% | Precision: 29.22% | recall: 29.03% | f1: 28.49%\n",
      "Val - Epoch: 24 | Loss: 1.9516 | Acc: 31.19% | Precision: 33.21% | recall: 31.19% | f1: 31.04%\n",
      "Train - Epoch: 25 | Loss: 1.9605 | Acc: 29.91% | Precision: 30.01% | recall: 29.91% | f1: 29.60%\n",
      "Val - Epoch: 25 | Loss: 1.9339 | Acc: 29.80% | Precision: 35.17% | recall: 29.80% | f1: 28.44%\n",
      "Train - Epoch: 26 | Loss: 1.9332 | Acc: 32.73% | Precision: 33.01% | recall: 32.73% | f1: 32.50%\n",
      "Val - Epoch: 26 | Loss: 1.9098 | Acc: 36.12% | Precision: 37.01% | recall: 36.12% | f1: 35.19%\n",
      "Train - Epoch: 27 | Loss: 1.9234 | Acc: 32.19% | Precision: 32.73% | recall: 32.19% | f1: 31.92%\n",
      "Val - Epoch: 27 | Loss: 1.9221 | Acc: 30.44% | Precision: 37.68% | recall: 30.44% | f1: 27.44%\n",
      "Train - Epoch: 28 | Loss: 1.9076 | Acc: 33.80% | Precision: 34.12% | recall: 33.80% | f1: 33.53%\n",
      "Val - Epoch: 28 | Loss: 1.8738 | Acc: 36.76% | Precision: 40.51% | recall: 36.76% | f1: 35.46%\n",
      "Train - Epoch: 29 | Loss: 1.8831 | Acc: 34.28% | Precision: 34.45% | recall: 34.28% | f1: 33.82%\n",
      "Val - Epoch: 29 | Loss: 1.8975 | Acc: 35.26% | Precision: 40.86% | recall: 35.26% | f1: 33.83%\n",
      "Train - Epoch: 30 | Loss: 1.8563 | Acc: 36.61% | Precision: 37.21% | recall: 36.61% | f1: 36.33%\n",
      "Val - Epoch: 30 | Loss: 1.8624 | Acc: 38.91% | Precision: 44.44% | recall: 38.91% | f1: 37.55%\n",
      "Train - Epoch: 31 | Loss: 1.8238 | Acc: 38.25% | Precision: 38.76% | recall: 38.25% | f1: 37.93%\n",
      "Val - Epoch: 31 | Loss: 1.8665 | Acc: 34.30% | Precision: 44.48% | recall: 34.30% | f1: 32.68%\n",
      "Train - Epoch: 32 | Loss: 1.8017 | Acc: 38.89% | Precision: 39.01% | recall: 38.89% | f1: 38.64%\n",
      "Val - Epoch: 32 | Loss: 1.8387 | Acc: 37.62% | Precision: 45.18% | recall: 37.62% | f1: 35.63%\n",
      "Train - Epoch: 33 | Loss: 1.7826 | Acc: 40.55% | Precision: 41.15% | recall: 40.55% | f1: 40.33%\n",
      "Val - Epoch: 33 | Loss: 1.8151 | Acc: 38.80% | Precision: 49.72% | recall: 38.80% | f1: 36.00%\n",
      "Train - Epoch: 34 | Loss: 1.7736 | Acc: 40.23% | Precision: 40.46% | recall: 40.23% | f1: 40.00%\n",
      "Val - Epoch: 34 | Loss: 1.7417 | Acc: 43.30% | Precision: 47.45% | recall: 43.30% | f1: 42.93%\n",
      "Train - Epoch: 35 | Loss: 1.7426 | Acc: 41.30% | Precision: 41.44% | recall: 41.30% | f1: 41.01%\n",
      "Val - Epoch: 35 | Loss: 1.7685 | Acc: 36.01% | Precision: 44.13% | recall: 36.01% | f1: 34.49%\n",
      "Train - Epoch: 36 | Loss: 1.7196 | Acc: 42.67% | Precision: 42.85% | recall: 42.67% | f1: 42.51%\n",
      "Val - Epoch: 36 | Loss: 1.7928 | Acc: 38.26% | Precision: 50.17% | recall: 38.26% | f1: 35.76%\n",
      "Train - Epoch: 37 | Loss: 1.7093 | Acc: 42.78% | Precision: 43.09% | recall: 42.78% | f1: 42.54%\n",
      "Val - Epoch: 37 | Loss: 1.7088 | Acc: 41.59% | Precision: 47.67% | recall: 41.59% | f1: 40.70%\n",
      "Train - Epoch: 38 | Loss: 1.6704 | Acc: 46.13% | Precision: 46.50% | recall: 46.13% | f1: 45.72%\n",
      "Val - Epoch: 38 | Loss: 1.6879 | Acc: 46.41% | Precision: 50.92% | recall: 46.41% | f1: 45.93%\n",
      "Train - Epoch: 39 | Loss: 1.6581 | Acc: 45.67% | Precision: 46.10% | recall: 45.67% | f1: 45.52%\n",
      "Val - Epoch: 39 | Loss: 1.6903 | Acc: 46.41% | Precision: 50.88% | recall: 46.41% | f1: 45.79%\n",
      "Train - Epoch: 40 | Loss: 1.6290 | Acc: 47.82% | Precision: 47.90% | recall: 47.82% | f1: 47.70%\n",
      "Val - Epoch: 40 | Loss: 1.6696 | Acc: 46.41% | Precision: 52.90% | recall: 46.41% | f1: 45.30%\n",
      "Train - Epoch: 41 | Loss: 1.6106 | Acc: 47.84% | Precision: 48.10% | recall: 47.84% | f1: 47.65%\n",
      "Val - Epoch: 41 | Loss: 1.6705 | Acc: 44.27% | Precision: 50.97% | recall: 44.27% | f1: 42.66%\n",
      "Train - Epoch: 42 | Loss: 1.6054 | Acc: 48.73% | Precision: 49.00% | recall: 48.73% | f1: 48.55%\n",
      "Val - Epoch: 42 | Loss: 1.6865 | Acc: 42.66% | Precision: 53.02% | recall: 42.66% | f1: 41.98%\n",
      "Train - Epoch: 43 | Loss: 1.5784 | Acc: 49.53% | Precision: 49.62% | recall: 49.53% | f1: 49.40%\n",
      "Val - Epoch: 43 | Loss: 1.5671 | Acc: 52.09% | Precision: 55.01% | recall: 52.09% | f1: 50.94%\n",
      "Train - Epoch: 44 | Loss: 1.5581 | Acc: 50.52% | Precision: 50.74% | recall: 50.52% | f1: 50.39%\n",
      "Val - Epoch: 44 | Loss: 1.5973 | Acc: 45.98% | Precision: 52.47% | recall: 45.98% | f1: 44.80%\n",
      "Train - Epoch: 45 | Loss: 1.5294 | Acc: 51.94% | Precision: 52.27% | recall: 51.94% | f1: 51.77%\n",
      "Val - Epoch: 45 | Loss: 1.5464 | Acc: 53.91% | Precision: 57.85% | recall: 53.91% | f1: 53.42%\n",
      "Train - Epoch: 46 | Loss: 1.5089 | Acc: 52.64% | Precision: 52.79% | recall: 52.64% | f1: 52.50%\n",
      "Val - Epoch: 46 | Loss: 1.5085 | Acc: 53.38% | Precision: 54.91% | recall: 53.38% | f1: 52.76%\n",
      "Train - Epoch: 47 | Loss: 1.5147 | Acc: 51.76% | Precision: 52.01% | recall: 51.76% | f1: 51.65%\n",
      "Val - Epoch: 47 | Loss: 1.5694 | Acc: 47.48% | Precision: 57.10% | recall: 47.48% | f1: 48.12%\n",
      "Train - Epoch: 48 | Loss: 1.4903 | Acc: 53.47% | Precision: 53.56% | recall: 53.47% | f1: 53.36%\n",
      "Val - Epoch: 48 | Loss: 1.4845 | Acc: 53.48% | Precision: 56.06% | recall: 53.48% | f1: 52.48%\n",
      "Train - Epoch: 49 | Loss: 1.4604 | Acc: 54.17% | Precision: 54.30% | recall: 54.17% | f1: 54.06%\n",
      "Val - Epoch: 49 | Loss: 1.5446 | Acc: 50.59% | Precision: 58.75% | recall: 50.59% | f1: 49.76%\n",
      "Train - Epoch: 50 | Loss: 1.4301 | Acc: 55.32% | Precision: 55.34% | recall: 55.32% | f1: 55.23%\n",
      "Val - Epoch: 50 | Loss: 1.4378 | Acc: 57.34% | Precision: 61.10% | recall: 57.34% | f1: 56.85%\n",
      "Train - Epoch: 51 | Loss: 1.4103 | Acc: 56.74% | Precision: 56.97% | recall: 56.74% | f1: 56.67%\n",
      "Val - Epoch: 51 | Loss: 1.5368 | Acc: 47.16% | Precision: 57.24% | recall: 47.16% | f1: 46.11%\n",
      "Train - Epoch: 52 | Loss: 1.3943 | Acc: 56.02% | Precision: 56.19% | recall: 56.02% | f1: 55.92%\n",
      "Val - Epoch: 52 | Loss: 1.4142 | Acc: 54.88% | Precision: 58.67% | recall: 54.88% | f1: 54.64%\n",
      "Train - Epoch: 53 | Loss: 1.3843 | Acc: 57.30% | Precision: 57.40% | recall: 57.30% | f1: 57.19%\n",
      "Val - Epoch: 53 | Loss: 1.4021 | Acc: 56.91% | Precision: 60.38% | recall: 56.91% | f1: 55.52%\n",
      "Train - Epoch: 54 | Loss: 1.3586 | Acc: 57.44% | Precision: 57.54% | recall: 57.44% | f1: 57.38%\n",
      "Val - Epoch: 54 | Loss: 1.3609 | Acc: 59.27% | Precision: 61.29% | recall: 59.27% | f1: 58.72%\n",
      "Train - Epoch: 55 | Loss: 1.3291 | Acc: 59.53% | Precision: 59.60% | recall: 59.53% | f1: 59.48%\n",
      "Val - Epoch: 55 | Loss: 1.3795 | Acc: 58.41% | Precision: 61.98% | recall: 58.41% | f1: 57.41%\n",
      "Train - Epoch: 56 | Loss: 1.3165 | Acc: 59.74% | Precision: 59.78% | recall: 59.74% | f1: 59.69%\n",
      "Val - Epoch: 56 | Loss: 1.3509 | Acc: 58.84% | Precision: 61.96% | recall: 58.84% | f1: 57.57%\n",
      "Train - Epoch: 57 | Loss: 1.2877 | Acc: 61.86% | Precision: 61.95% | recall: 61.86% | f1: 61.82%\n",
      "Val - Epoch: 57 | Loss: 1.3008 | Acc: 61.84% | Precision: 63.97% | recall: 61.84% | f1: 60.96%\n",
      "Train - Epoch: 58 | Loss: 1.2721 | Acc: 61.54% | Precision: 61.69% | recall: 61.54% | f1: 61.45%\n",
      "Val - Epoch: 58 | Loss: 1.2890 | Acc: 60.02% | Precision: 64.06% | recall: 60.02% | f1: 59.85%\n",
      "Train - Epoch: 59 | Loss: 1.2626 | Acc: 61.83% | Precision: 61.94% | recall: 61.83% | f1: 61.80%\n",
      "Val - Epoch: 59 | Loss: 1.2334 | Acc: 64.84% | Precision: 66.21% | recall: 64.84% | f1: 64.63%\n",
      "Train - Epoch: 60 | Loss: 1.2359 | Acc: 63.55% | Precision: 63.78% | recall: 63.55% | f1: 63.54%\n",
      "Val - Epoch: 60 | Loss: 1.2434 | Acc: 63.24% | Precision: 65.96% | recall: 63.24% | f1: 63.10%\n",
      "Train - Epoch: 61 | Loss: 1.2312 | Acc: 63.52% | Precision: 63.51% | recall: 63.52% | f1: 63.40%\n",
      "Val - Epoch: 61 | Loss: 1.2794 | Acc: 60.24% | Precision: 66.53% | recall: 60.24% | f1: 60.34%\n",
      "Train - Epoch: 62 | Loss: 1.2138 | Acc: 63.23% | Precision: 63.34% | recall: 63.23% | f1: 63.17%\n",
      "Val - Epoch: 62 | Loss: 1.3076 | Acc: 59.91% | Precision: 66.06% | recall: 59.91% | f1: 58.83%\n",
      "Train - Epoch: 63 | Loss: 1.1697 | Acc: 64.92% | Precision: 64.98% | recall: 64.92% | f1: 64.86%\n",
      "Val - Epoch: 63 | Loss: 1.1537 | Acc: 67.10% | Precision: 68.79% | recall: 67.10% | f1: 66.81%\n",
      "Train - Epoch: 64 | Loss: 1.1605 | Acc: 65.88% | Precision: 65.99% | recall: 65.88% | f1: 65.81%\n",
      "Val - Epoch: 64 | Loss: 1.1417 | Acc: 65.81% | Precision: 69.21% | recall: 65.81% | f1: 65.84%\n",
      "Train - Epoch: 65 | Loss: 1.1591 | Acc: 66.18% | Precision: 66.31% | recall: 66.18% | f1: 66.15%\n",
      "Val - Epoch: 65 | Loss: 1.2280 | Acc: 62.92% | Precision: 66.50% | recall: 62.92% | f1: 61.01%\n",
      "Train - Epoch: 66 | Loss: 1.1179 | Acc: 67.14% | Precision: 67.22% | recall: 67.14% | f1: 67.13%\n",
      "Val - Epoch: 66 | Loss: 1.0896 | Acc: 69.99% | Precision: 72.54% | recall: 69.99% | f1: 70.07%\n",
      "Train - Epoch: 67 | Loss: 1.0961 | Acc: 68.53% | Precision: 68.59% | recall: 68.53% | f1: 68.48%\n",
      "Val - Epoch: 67 | Loss: 1.0555 | Acc: 70.63% | Precision: 72.24% | recall: 70.63% | f1: 70.67%\n",
      "Train - Epoch: 68 | Loss: 1.0839 | Acc: 68.08% | Precision: 68.19% | recall: 68.08% | f1: 68.05%\n",
      "Val - Epoch: 68 | Loss: 1.1392 | Acc: 65.92% | Precision: 70.90% | recall: 65.92% | f1: 66.02%\n",
      "Train - Epoch: 69 | Loss: 1.0509 | Acc: 70.03% | Precision: 70.13% | recall: 70.03% | f1: 70.01%\n",
      "Val - Epoch: 69 | Loss: 1.0442 | Acc: 71.38% | Precision: 74.42% | recall: 71.38% | f1: 71.29%\n",
      "Train - Epoch: 70 | Loss: 1.0507 | Acc: 68.45% | Precision: 68.53% | recall: 68.45% | f1: 68.41%\n",
      "Val - Epoch: 70 | Loss: 1.0411 | Acc: 70.10% | Precision: 72.91% | recall: 70.10% | f1: 70.19%\n",
      "Train - Epoch: 71 | Loss: 1.0291 | Acc: 70.54% | Precision: 70.54% | recall: 70.54% | f1: 70.49%\n",
      "Val - Epoch: 71 | Loss: 1.0953 | Acc: 67.85% | Precision: 73.10% | recall: 67.85% | f1: 66.59%\n",
      "Train - Epoch: 72 | Loss: 0.9800 | Acc: 73.28% | Precision: 73.32% | recall: 73.28% | f1: 73.27%\n",
      "Val - Epoch: 72 | Loss: 0.9604 | Acc: 74.38% | Precision: 76.23% | recall: 74.38% | f1: 73.70%\n",
      "Train - Epoch: 73 | Loss: 0.9735 | Acc: 72.55% | Precision: 72.61% | recall: 72.55% | f1: 72.52%\n",
      "Val - Epoch: 73 | Loss: 0.9489 | Acc: 73.85% | Precision: 75.37% | recall: 73.85% | f1: 73.43%\n",
      "Train - Epoch: 74 | Loss: 0.9583 | Acc: 72.26% | Precision: 72.28% | recall: 72.26% | f1: 72.23%\n",
      "Val - Epoch: 74 | Loss: 0.9778 | Acc: 73.95% | Precision: 77.06% | recall: 73.95% | f1: 73.96%\n",
      "Train - Epoch: 75 | Loss: 0.9293 | Acc: 73.84% | Precision: 73.85% | recall: 73.84% | f1: 73.80%\n",
      "Val - Epoch: 75 | Loss: 0.9397 | Acc: 72.35% | Precision: 77.56% | recall: 72.35% | f1: 72.48%\n",
      "Train - Epoch: 76 | Loss: 0.9179 | Acc: 73.92% | Precision: 73.99% | recall: 73.92% | f1: 73.92%\n",
      "Val - Epoch: 76 | Loss: 0.8368 | Acc: 79.10% | Precision: 80.10% | recall: 79.10% | f1: 78.80%\n",
      "Train - Epoch: 77 | Loss: 0.8775 | Acc: 75.53% | Precision: 75.59% | recall: 75.53% | f1: 75.53%\n",
      "Val - Epoch: 77 | Loss: 0.8327 | Acc: 77.17% | Precision: 78.23% | recall: 77.17% | f1: 76.81%\n",
      "Train - Epoch: 78 | Loss: 0.8669 | Acc: 76.12% | Precision: 76.13% | recall: 76.12% | f1: 76.08%\n",
      "Val - Epoch: 78 | Loss: 0.8199 | Acc: 79.53% | Precision: 81.73% | recall: 79.53% | f1: 79.57%\n",
      "Train - Epoch: 79 | Loss: 0.8417 | Acc: 76.57% | Precision: 76.58% | recall: 76.57% | f1: 76.53%\n",
      "Val - Epoch: 79 | Loss: 0.8215 | Acc: 78.56% | Precision: 80.64% | recall: 78.56% | f1: 78.60%\n",
      "Train - Epoch: 80 | Loss: 0.8359 | Acc: 75.98% | Precision: 76.00% | recall: 75.98% | f1: 75.97%\n",
      "Val - Epoch: 80 | Loss: 0.7982 | Acc: 76.63% | Precision: 80.62% | recall: 76.63% | f1: 77.06%\n",
      "Train - Epoch: 81 | Loss: 0.8007 | Acc: 77.54% | Precision: 77.58% | recall: 77.54% | f1: 77.52%\n",
      "Val - Epoch: 81 | Loss: 0.8270 | Acc: 76.31% | Precision: 80.32% | recall: 76.31% | f1: 76.26%\n",
      "Train - Epoch: 82 | Loss: 0.7922 | Acc: 77.19% | Precision: 77.22% | recall: 77.19% | f1: 77.15%\n",
      "Val - Epoch: 82 | Loss: 0.7284 | Acc: 80.81% | Precision: 82.96% | recall: 80.81% | f1: 80.95%\n",
      "Train - Epoch: 83 | Loss: 0.7604 | Acc: 79.07% | Precision: 79.09% | recall: 79.07% | f1: 79.01%\n",
      "Val - Epoch: 83 | Loss: 0.6854 | Acc: 82.96% | Precision: 84.24% | recall: 82.96% | f1: 82.98%\n",
      "Train - Epoch: 84 | Loss: 0.7309 | Acc: 80.78% | Precision: 80.82% | recall: 80.78% | f1: 80.77%\n",
      "Val - Epoch: 84 | Loss: 0.6288 | Acc: 83.39% | Precision: 83.92% | recall: 83.39% | f1: 83.36%\n",
      "Train - Epoch: 85 | Loss: 0.7267 | Acc: 80.51% | Precision: 80.50% | recall: 80.51% | f1: 80.45%\n",
      "Val - Epoch: 85 | Loss: 0.6741 | Acc: 83.49% | Precision: 85.11% | recall: 83.49% | f1: 83.37%\n",
      "Train - Epoch: 86 | Loss: 0.6960 | Acc: 81.80% | Precision: 81.82% | recall: 81.80% | f1: 81.79%\n",
      "Val - Epoch: 86 | Loss: 0.6148 | Acc: 83.71% | Precision: 86.05% | recall: 83.71% | f1: 84.07%\n",
      "Train - Epoch: 87 | Loss: 0.6902 | Acc: 81.37% | Precision: 81.37% | recall: 81.37% | f1: 81.35%\n",
      "Val - Epoch: 87 | Loss: 0.5848 | Acc: 84.46% | Precision: 85.38% | recall: 84.46% | f1: 84.33%\n",
      "Train - Epoch: 88 | Loss: 0.6410 | Acc: 83.46% | Precision: 83.49% | recall: 83.46% | f1: 83.46%\n",
      "Val - Epoch: 88 | Loss: 0.5297 | Acc: 87.78% | Precision: 88.28% | recall: 87.78% | f1: 87.76%\n",
      "Train - Epoch: 89 | Loss: 0.6289 | Acc: 83.49% | Precision: 83.50% | recall: 83.49% | f1: 83.47%\n",
      "Val - Epoch: 89 | Loss: 0.5291 | Acc: 87.03% | Precision: 87.74% | recall: 87.03% | f1: 87.10%\n",
      "Train - Epoch: 90 | Loss: 0.6076 | Acc: 84.37% | Precision: 84.38% | recall: 84.37% | f1: 84.35%\n",
      "Val - Epoch: 90 | Loss: 0.5037 | Acc: 88.42% | Precision: 89.06% | recall: 88.42% | f1: 88.37%\n",
      "Train - Epoch: 91 | Loss: 0.6155 | Acc: 83.89% | Precision: 83.88% | recall: 83.89% | f1: 83.86%\n",
      "Val - Epoch: 91 | Loss: 0.4954 | Acc: 88.42% | Precision: 89.13% | recall: 88.42% | f1: 88.26%\n",
      "Train - Epoch: 92 | Loss: 0.5843 | Acc: 84.59% | Precision: 84.60% | recall: 84.59% | f1: 84.57%\n",
      "Val - Epoch: 92 | Loss: 0.4181 | Acc: 90.68% | Precision: 90.86% | recall: 90.68% | f1: 90.59%\n",
      "Train - Epoch: 93 | Loss: 0.5583 | Acc: 85.74% | Precision: 85.76% | recall: 85.74% | f1: 85.74%\n",
      "Val - Epoch: 93 | Loss: 0.4564 | Acc: 89.50% | Precision: 90.42% | recall: 89.50% | f1: 89.62%\n",
      "Train - Epoch: 94 | Loss: 0.5583 | Acc: 85.29% | Precision: 85.31% | recall: 85.29% | f1: 85.28%\n",
      "Val - Epoch: 94 | Loss: 0.4646 | Acc: 87.14% | Precision: 88.79% | recall: 87.14% | f1: 87.29%\n",
      "Train - Epoch: 95 | Loss: 0.5392 | Acc: 85.55% | Precision: 85.54% | recall: 85.55% | f1: 85.53%\n",
      "Val - Epoch: 95 | Loss: 0.4288 | Acc: 88.96% | Precision: 89.74% | recall: 88.96% | f1: 88.99%\n",
      "Train - Epoch: 96 | Loss: 0.5243 | Acc: 86.73% | Precision: 86.74% | recall: 86.73% | f1: 86.72%\n",
      "Val - Epoch: 96 | Loss: 0.3916 | Acc: 90.68% | Precision: 91.59% | recall: 90.68% | f1: 90.67%\n",
      "Train - Epoch: 97 | Loss: 0.4864 | Acc: 86.95% | Precision: 86.96% | recall: 86.95% | f1: 86.93%\n",
      "Val - Epoch: 97 | Loss: 0.3647 | Acc: 91.00% | Precision: 91.29% | recall: 91.00% | f1: 91.01%\n",
      "Train - Epoch: 98 | Loss: 0.4697 | Acc: 87.91% | Precision: 87.93% | recall: 87.91% | f1: 87.89%\n",
      "Val - Epoch: 98 | Loss: 0.3438 | Acc: 91.00% | Precision: 91.65% | recall: 91.00% | f1: 90.99%\n",
      "Train - Epoch: 99 | Loss: 0.4406 | Acc: 89.04% | Precision: 89.05% | recall: 89.04% | f1: 89.03%\n",
      "Val - Epoch: 99 | Loss: 0.3300 | Acc: 91.75% | Precision: 92.20% | recall: 91.75% | f1: 91.72%\n",
      "Train - Epoch: 100 | Loss: 0.4479 | Acc: 88.74% | Precision: 88.74% | recall: 88.74% | f1: 88.73%\n",
      "Val - Epoch: 100 | Loss: 0.3421 | Acc: 91.64% | Precision: 92.37% | recall: 91.64% | f1: 91.69%\n",
      "Train - Epoch: 101 | Loss: 0.4312 | Acc: 89.41% | Precision: 89.41% | recall: 89.41% | f1: 89.40%\n",
      "Val - Epoch: 101 | Loss: 0.2818 | Acc: 93.89% | Precision: 94.29% | recall: 93.89% | f1: 93.94%\n",
      "Train - Epoch: 102 | Loss: 0.4120 | Acc: 89.25% | Precision: 89.27% | recall: 89.25% | f1: 89.24%\n",
      "Val - Epoch: 102 | Loss: 0.2639 | Acc: 93.46% | Precision: 94.04% | recall: 93.46% | f1: 93.54%\n",
      "Train - Epoch: 103 | Loss: 0.3950 | Acc: 89.84% | Precision: 89.85% | recall: 89.84% | f1: 89.84%\n",
      "Val - Epoch: 103 | Loss: 0.2233 | Acc: 94.75% | Precision: 94.87% | recall: 94.75% | f1: 94.74%\n",
      "Train - Epoch: 104 | Loss: 0.3716 | Acc: 90.57% | Precision: 90.57% | recall: 90.57% | f1: 90.56%\n",
      "Val - Epoch: 104 | Loss: 0.2076 | Acc: 95.07% | Precision: 95.21% | recall: 95.07% | f1: 95.09%\n",
      "Train - Epoch: 105 | Loss: 0.3698 | Acc: 90.11% | Precision: 90.15% | recall: 90.11% | f1: 90.12%\n",
      "Val - Epoch: 105 | Loss: 0.2277 | Acc: 93.89% | Precision: 94.42% | recall: 93.89% | f1: 93.93%\n",
      "Train - Epoch: 106 | Loss: 0.3444 | Acc: 91.37% | Precision: 91.38% | recall: 91.37% | f1: 91.37%\n",
      "Val - Epoch: 106 | Loss: 0.2199 | Acc: 95.07% | Precision: 95.36% | recall: 95.07% | f1: 95.09%\n",
      "Train - Epoch: 107 | Loss: 0.3320 | Acc: 90.89% | Precision: 90.91% | recall: 90.89% | f1: 90.89%\n",
      "Val - Epoch: 107 | Loss: 0.1841 | Acc: 96.14% | Precision: 96.35% | recall: 96.14% | f1: 96.18%\n",
      "Train - Epoch: 108 | Loss: 0.3037 | Acc: 92.76% | Precision: 92.78% | recall: 92.76% | f1: 92.76%\n",
      "Val - Epoch: 108 | Loss: 0.1904 | Acc: 95.18% | Precision: 95.55% | recall: 95.18% | f1: 95.13%\n",
      "Train - Epoch: 109 | Loss: 0.3196 | Acc: 92.17% | Precision: 92.19% | recall: 92.17% | f1: 92.17%\n",
      "Val - Epoch: 109 | Loss: 0.1334 | Acc: 96.68% | Precision: 96.81% | recall: 96.68% | f1: 96.68%\n",
      "Train - Epoch: 110 | Loss: 0.3062 | Acc: 92.31% | Precision: 92.31% | recall: 92.31% | f1: 92.30%\n",
      "Val - Epoch: 110 | Loss: 0.1368 | Acc: 96.46% | Precision: 96.58% | recall: 96.46% | f1: 96.47%\n",
      "Training completed in 2m 55s\n",
      "Best validation accuracy: 96.68%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example configuration\n",
    "    config = {\n",
    "        'lr': 3e-5,\n",
    "        'weight_decay': 1e-5,\n",
    "        'patience': 15,\n",
    "        'epochs': 110,\n",
    "        'experiment_name': 'eeg_attention_experiment',\n",
    "        'save_attention_maps': True\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_loader, val_loader, trail_shape, class_weights = get_data_loaders(data_dir=\"/teamspace/studios/this_studio/mnist_data/MindBigData64_Mnist2022-EEGv0.016.txt\")\n",
    "    model = EEGClassifier(num_samples = trail_shape[-1], num_classes=10)\n",
    "    # Create trainer\n",
    "    trainer = EEGTrainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        class_weights = class_weights,\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    # Start training\n",
    "    best_val_acc = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca4ca2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# file_path = \"/teamspace/studios/this_studio/mnist_s/MindBigData64_Mnist2022-EEGv0.016.txt\"\n",
    "# df = pd.read_csv(file_path, header=None)\n",
    "# df = df[df.iloc[:, 2] != -1]\n",
    "\n",
    "# df.columns = ['id', 'event', 'device', 'channel', 'code', 'size', 'data']\n",
    "# df['data'] = df['data'].apply(lambda x: np.array(x.split(','), dtype=float))\n",
    "# num_groups = len(df) // 14\n",
    "# grouped = np.zeros((num_groups - 8, 14, 244), dtype=np.float32)\n",
    "# group_idx = 0\n",
    "# temp = None\n",
    "# temp1=[]\n",
    "# labels = []\n",
    "# ind = 0\n",
    "# for row, num in zip(df['data'], df['code']):\n",
    "\n",
    "#     if num != -1:\n",
    "#         if len(row) >= 244:\n",
    "#             temp = df['data'].iloc[ind:ind+14]\n",
    "#             ind+=14\n",
    "#         else:\n",
    "#             continue\n",
    "        \n",
    "#         if not temp.empty:\n",
    "#             if all(len(i)>=244 for i in temp):\n",
    "#                 for row in temp:\n",
    "#                     temp1.append(row[:244])\n",
    "#             else:\n",
    "#                 continue\n",
    "#         else:\n",
    "#             continue\n",
    "\n",
    "\n",
    "#         if len(temp1) == 14:\n",
    "#             grouped[group_idx] = np.stack(temp1)\n",
    "#             labels.append(num)\n",
    "#             temp1=[]\n",
    "#             temp = None\n",
    "#             group_idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4255d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# labels = df.iloc[:, 2].values\n",
    "# all_data = []\n",
    "\n",
    "# for i, row in df.iterrows():\n",
    "#     data = row.iloc[788:].astype(float).values.reshape(64, 400)\n",
    "#     all_data.append(data)\n",
    "\n",
    "# # Convert list â†’ NumPy array\n",
    "# all_data = np.stack(all_data)\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
