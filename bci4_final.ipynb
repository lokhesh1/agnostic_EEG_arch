{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b03eea36",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f557f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from scipy.signal import firwin, filtfilt\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import warnings\n",
    "import torch\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"mne\")\n",
    "# Completely silence MNE-Python output\n",
    "mne.set_log_level('WARNING')  # or 'ERROR' for even less output\n",
    "logging.getLogger('mne').setLevel(logging.WARNING)\n",
    "#mne.set_log_level('debug')\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ebfa3e",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12af0830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eeg(path, sfreq = None):\n",
    "    raw = mne.io.read_raw_gdf(path, preload=True)\n",
    "\n",
    "    # Step 2: Get the sampling frequency\n",
    "    if not sfreq:\n",
    "        sfreq = raw.info['sfreq']  # Hz\n",
    "\n",
    "    # Step 3: Define FIR filter parameters\n",
    "    low_cutoff = 1.0   # Hz\n",
    "    high_cutoff = 30.0 # Hz\n",
    "    filter_order = 177 # Must be odd for linear-phase FIR\n",
    "\n",
    "    nyquist = 0.5 * sfreq\n",
    "\n",
    "\n",
    "    fir_coeffs = firwin(\n",
    "        numtaps=filter_order,\n",
    "        cutoff=[low_cutoff / nyquist, high_cutoff / nyquist],\n",
    "        pass_zero=False,\n",
    "        window='blackman'\n",
    "    )\n",
    "    eeg_data = raw.get_data()\n",
    "    filtered_data = filtfilt(fir_coeffs, 1.0, eeg_data, axis=1)\n",
    "\n",
    "    new_raw = mne.io.RawArray(filtered_data, raw.info.copy())\n",
    "    annotations = raw.annotations \n",
    "    new_raw.set_annotations(annotations)\n",
    "\n",
    "    return new_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4a18b3",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f25e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path, test=False, event_id= None):\n",
    "\n",
    "    raw = load_eeg(path)\n",
    "    eeg_channels = raw.ch_names[:22]\n",
    "    raw.pick(eeg_channels)\n",
    "    \n",
    "    if event_id is not None:\n",
    "        events, events_id = mne.events_from_annotations(raw, event_id=event_id)\n",
    "    else:\n",
    "        events, events_id = mne.events_from_annotations(raw)\n",
    "\n",
    "        #print(events_id)\n",
    "    #print(events_id)\n",
    "    epochs = mne.Epochs(\n",
    "        raw,\n",
    "        events=events,  \n",
    "        tmin=0,     \n",
    "        tmax=6.0,\n",
    "        event_id=events_id,\n",
    "        baseline=None,\n",
    "        preload=True\n",
    "    )\n",
    "\n",
    "    labels = epochs.events[:, 2]\n",
    "    #print(labels)\n",
    "    data = epochs.get_data()\n",
    "    \n",
    "    return {\n",
    "        'epochs': data,   \n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "#a = preprocess(\"E:/LOKI/BCI-IV/A01T.gdf\")\n",
    "# print(a['epochs'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c3a9d1",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe018fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.io as sio\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def gauss_smooth(inputs, device, smooth_kernel_std=2, smooth_kernel_size=100,  padding='same'):\n",
    "\n",
    "    #print(inputs.shape)\n",
    "    inputs = inputs.transpose(0, 2, 1)\n",
    "    # Get Gaussian kernel\n",
    "    inp = np.zeros(smooth_kernel_size, dtype=np.float32)\n",
    "    inp[smooth_kernel_size // 2] = 1\n",
    "    gaussKernel = gaussian_filter1d(inp, smooth_kernel_std)\n",
    "    validIdx = np.argwhere(gaussKernel > 0.01)\n",
    "    gaussKernel = gaussKernel[validIdx]\n",
    "    gaussKernel = np.squeeze(gaussKernel / np.sum(gaussKernel))\n",
    "\n",
    "    # Convert to tensor\n",
    "    gaussKernel = torch.tensor(gaussKernel, dtype=torch.float32, device=device)\n",
    "    gaussKernel = gaussKernel.view(1, 1, -1)  # [1, 1, kernel_size]\n",
    "\n",
    "    # Prepare convolution\n",
    "    B, T, C = inputs.shape\n",
    "    inputs = inputs.transpose(0, 2, 1)  # [B, C, T]\n",
    "    inputs = torch.tensor(inputs, dtype=torch.float32, device=device)\n",
    "    \n",
    "    gaussKernel = gaussKernel.repeat(C, 1, 1)  # [C, 1, kernel_size]\n",
    "\n",
    "    # Perform convolution\n",
    "    smoothed = F.conv1d(inputs, gaussKernel, padding=padding, groups=C)\n",
    "    return smoothed  # [B, T, C]\n",
    "\n",
    "# \n",
    "import pandas as pd\n",
    "\n",
    "class BCI4_2a_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, subjects=[1], transform=None, target_transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.subjects = subjects\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.data, self.labels = self._load_data()\n",
    "        \n",
    "        self.labels = self.labels \n",
    "        \n",
    "    def _load_data(self):\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "        \n",
    "        for subject in self.subjects:\n",
    "\n",
    "            filename = f'A{subject:02d}T.gdf'\n",
    "            filepath = os.path.join(self.data_dir, filename)\n",
    "            data_ = preprocess(filepath, event_id = {'769': 0,'770': 1,'771': 2,'772': 3})\n",
    "            \n",
    "            data = data_['epochs']\n",
    "            labels = data_['labels']\n",
    "            #data = np.transpose(data, (0, 2, 1))\n",
    "            aug_data = gauss_smooth(data, 'cpu')\n",
    "            all_data.append(data)\n",
    "            all_data.append(aug_data)\n",
    "            all_labels.append(labels)\n",
    "            all_labels.append(labels)\n",
    "            \n",
    "        all_data = np.concatenate(all_data, axis=0)\n",
    "        all_labels = np.concatenate(all_labels, axis=0)\n",
    "        #print(all_labels.shape)\n",
    "        def normalize_eeg(batch_data):\n",
    "            # Calculate mean and std along the time axis (axis=2)\n",
    "            means = batch_data.mean(axis=2, keepdims=True)\n",
    "            stds = batch_data.std(axis=2, keepdims=True)\n",
    "\n",
    "            return (batch_data - means) / (stds + 1e-8)\n",
    "\n",
    "        #all_data_n = normalize_eeg(all_data)\n",
    "\n",
    "        return all_data, all_labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.labels[idx]\n",
    "        \n",
    "        x = torch.from_numpy(x).float()  # shape: (1, timepoints, channels)\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        if self.target_transform:\n",
    "            y = self.target_transform(y)\n",
    "            \n",
    "        return x, y\n",
    "\n",
    "def get_data_loaders(data_dir,all_subjects=[1], test_subject=[1,2], batch_size=32, val_split=0.2, random_state=42):\n",
    "    # Get all subjects except the test subject for training/validation\n",
    "    \n",
    "    #train_val_subjects = [s for s in all_subjects if s not in test_subject]\n",
    "    \n",
    "    # Create datasets\n",
    "    train_val_dataset = BCI4_2a_Dataset(data_dir, subjects=all_subjects)\n",
    "    test_dataset = BCI4_2a_Dataset(data_dir, subjects=test_subject)\n",
    "    single_trial_shape = test_dataset.data[0].shape\n",
    "    print(f\"Train+Val dataset size: {len(train_val_dataset)}\")\n",
    "    print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "    \n",
    "    # Split train_val into train and validation\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        range(len(train_val_dataset)),\n",
    "        test_size=val_split,\n",
    "        random_state=random_state,\n",
    "        stratify=train_val_dataset.labels\n",
    "    )\n",
    "    \n",
    "    train_dataset = torch.utils.data.Subset(train_val_dataset, train_idx)\n",
    "    val_dataset = torch.utils.data.Subset(train_val_dataset, val_idx)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print(f\"Train batches: {len(train_loader)}\")\n",
    "    print(f\"Val batches: {len(val_loader)}\")\n",
    "    print(f\"Test batches: {len(test_loader)}\")\n",
    "    print(f\"Single Trial Shape: {single_trial_shape}\")\n",
    "    return train_loader, val_loader, test_loader, single_trial_shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449a4378",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "135ecd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, num_channels, reduction_ratio=4, dropout=0.1):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(num_channels, num_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),  # Added dropout\n",
    "            nn.Linear(num_channels // reduction_ratio, num_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        channel_avg = torch.mean(x, dim=2, keepdim=True)  \n",
    "        channel_max, _ = torch.max(x, dim=2, keepdim=True) \n",
    "        combined = channel_avg + channel_max  \n",
    "        combined = combined.squeeze(2)\n",
    "        attention = self.mlp(combined)\n",
    "        attention = torch.sigmoid(attention).unsqueeze(2)\n",
    "        attended_x = x * attention\n",
    "        return attended_x, attention.squeeze(2)  # Return proper attention scores\n",
    "\n",
    "\n",
    "class LearnableSTFT(nn.Module):\n",
    "    def __init__(self, window_size, hop_size, learnable_window=True, dropout=0.05):\n",
    "        super(LearnableSTFT, self).__init__()\n",
    "        \n",
    "        self.window_size = window_size\n",
    "        self.hop_size = hop_size\n",
    "        self.dft_size = window_size\n",
    "        self.learnable_window = learnable_window\n",
    "        \n",
    "        # Initialize with Hamming window\n",
    "        initial_window = 0.54 - 0.46 * torch.cos(\n",
    "            2 * math.pi * torch.arange(window_size, dtype=torch.float32) / (window_size - 1)\n",
    "        )\n",
    "        \n",
    "        if learnable_window:\n",
    "            self.window = nn.Parameter(initial_window)\n",
    "        else:\n",
    "            # Fixed window reduces overfitting\n",
    "            self.register_buffer('window', initial_window)\n",
    "        \n",
    "        # Batch normalization after STFT\n",
    "        self.batch_norm = nn.BatchNorm2d(1)\n",
    "        self.dropout = nn.Dropout2d(dropout)\n",
    "        \n",
    "        dft_matrix = self._create_dft_matrix(self.dft_size, self.window_size)\n",
    "        self.register_buffer('dft_matrix', dft_matrix)\n",
    "\n",
    "    def _create_dft_matrix(self, dft_size, window_size):\n",
    "        k = torch.arange(dft_size).unsqueeze(1)\n",
    "        n = torch.arange(window_size)\n",
    "        angle = -2 * math.pi * k * n / dft_size\n",
    "        dft_matrix = torch.complex(torch.cos(angle), torch.sin(angle))\n",
    "        return dft_matrix\n",
    "\n",
    "    def forward(self, signal):\n",
    "        if signal.dim() == 1:\n",
    "            signal = signal.unsqueeze(0).unsqueeze(0)\n",
    "        elif signal.dim() == 2:\n",
    "            signal = signal.unsqueeze(1)\n",
    "            \n",
    "        batch_size, num_channels, num_samples = signal.shape\n",
    "        signal_reshaped = signal.reshape(batch_size * num_channels, num_samples)\n",
    "        \n",
    "        frames = signal_reshaped.unfold(dimension=1, size=self.window_size, step=self.hop_size)\n",
    "        num_frames_unfolded = frames.shape[1]\n",
    "        expected_num_frames = int(math.ceil((num_samples - self.window_size) / self.hop_size)) + 1\n",
    "        \n",
    "        if num_frames_unfolded < expected_num_frames:\n",
    "            padding_amount = (expected_num_frames - 1) * self.hop_size + self.window_size - num_samples\n",
    "            padded_signal = torch.nn.functional.pad(signal_reshaped, (0, padding_amount))\n",
    "            frames = padded_signal.unfold(1, self.window_size, self.hop_size)\n",
    "        \n",
    "        windowed_frames = frames * self.window\n",
    "        BC, F, W = windowed_frames.shape\n",
    "        windowed_frames_reshaped = windowed_frames.reshape(BC * F, W)\n",
    "        \n",
    "        windowed_frames_complex = windowed_frames_reshaped.to(self.dft_matrix.dtype)\n",
    "        stft_result_reshaped = self.dft_matrix @ windowed_frames_complex.T\n",
    "        stft_result = stft_result_reshaped.T.reshape(batch_size, num_channels, F, self.dft_size)\n",
    "        \n",
    "        # Apply magnitude and normalization\n",
    "        stft_magnitude = torch.abs(stft_result)\n",
    "        \n",
    "        # Reshape for batch norm: (B*C, 1, F, freq_bins)\n",
    "        stft_normalized = stft_magnitude.reshape(batch_size * num_channels, 1, F, self.dft_size)\n",
    "        stft_normalized = self.batch_norm(stft_normalized)\n",
    "        stft_normalized = self.dropout(stft_normalized)\n",
    "        stft_normalized = stft_normalized.reshape(batch_size, num_channels, F, self.dft_size)\n",
    "        \n",
    "        return stft_normalized\n",
    "\n",
    "\n",
    "class Attention4D(nn.Module):\n",
    "    def __init__(self, in_channels, time_frames, freq_bins, d_model=128, n_heads=4, \n",
    "                 d_ff=256, dropout=0.2, num_layers=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.time_frames = time_frames\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        in_features = in_channels * freq_bins\n",
    "        \n",
    "        # Project input to d_model with layer norm\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(in_features, d_model),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # Learnable positional encoding with smaller init\n",
    "        self.positional_encoding = nn.Parameter(\n",
    "            torch.randn(1, time_frames, d_model) * 0.02\n",
    "        )\n",
    "        \n",
    "        # Stack multiple transformer layers for better representation\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            TransformerBlock(d_model, n_heads, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.final_norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Reshape: (B, C, T, F) -> (B, T, C*F)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        x = x.reshape(batch_size, self.time_frames, -1)\n",
    "        \n",
    "        # Project and add positional encoding\n",
    "        x = self.projection(x)\n",
    "        x = x + self.positional_encoding\n",
    "        \n",
    "        # Store attention weights from all layers\n",
    "        all_attention_weights = []\n",
    "        \n",
    "        # Pass through transformer layers\n",
    "        for layer in self.transformer_layers:\n",
    "            x, attn_weights = layer(x)\n",
    "            all_attention_weights.append(attn_weights)\n",
    "        \n",
    "        x = self.final_norm(x)\n",
    "        \n",
    "        return x, all_attention_weights\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=d_model, \n",
    "            num_heads=n_heads, \n",
    "            dropout=dropout, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.GELU(),  # GELU often works better than ReLU\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Pre-norm architecture (more stable)\n",
    "        x_norm = self.layernorm1(x)\n",
    "        attn_output, attn_weights = self.attention(x_norm, x_norm, x_norm, \n",
    "                                                    need_weights=True, \n",
    "                                                    average_attn_weights=True)\n",
    "        x = x + self.dropout1(attn_output)\n",
    "        \n",
    "        x_norm = self.layernorm2(x)\n",
    "        ff_output = self.feed_forward(x_norm)\n",
    "        x = x + self.dropout2(ff_output)\n",
    "        \n",
    "        return x, attn_weights\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_features, num_classes, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # Add intermediate layer for better capacity\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features // 2),\n",
    "            nn.LayerNorm(in_features // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_features // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # (B, d_model, T)\n",
    "        x = self.pooling(x).squeeze(2)  # (B, d_model)\n",
    "        output = self.classifier(x)  # (B, num_classes)\n",
    "        return output\n",
    "\n",
    "\n",
    "class EEGClassifier(nn.Module):\n",
    "    def __init__(self, num_samples, num_classes=4, window_percent=0.25, \n",
    "                 overlap_percent=0.10, d_model=128, n_heads=8, \n",
    "                 transformer_layers=1, dropout=0.2, learnable_window=True):\n",
    "\n",
    "        super(EEGClassifier, self).__init__()\n",
    "        \n",
    "        window_size = int(num_samples * window_percent)\n",
    "        hop_size = int(num_samples * overlap_percent)\n",
    "        \n",
    "        self.window_size = max(window_size, 30)\n",
    "        self.hop_size = max(hop_size, 10)\n",
    "        \n",
    "        self.channel_attn = ChannelAttention(num_channels=22, dropout=dropout)\n",
    "        \n",
    "        self.learnable_stft = LearnableSTFT(\n",
    "            window_size=self.window_size,\n",
    "            hop_size=self.hop_size,\n",
    "            learnable_window=learnable_window,\n",
    "            dropout=dropout * 0.5\n",
    "        )\n",
    "        \n",
    "        time_frames = int(math.ceil((num_samples - self.window_size) / self.hop_size)) + 1\n",
    "        \n",
    "        self.attention_module = Attention4D(\n",
    "            in_channels=22,\n",
    "            time_frames=time_frames,\n",
    "            freq_bins=self.window_size,\n",
    "            d_model=d_model,\n",
    "            n_heads=n_heads,\n",
    "            num_layers=transformer_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.classifier = Classifier(\n",
    "            in_features=d_model, \n",
    "            num_classes=num_classes,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, x, return_attention=False):\n",
    "\n",
    "        # Channel attention\n",
    "        x, channel_attn_scores = self.channel_attn(x)\n",
    "        \n",
    "        # STFT\n",
    "        x = self.learnable_stft(x)\n",
    "        \n",
    "        # Transformer attention\n",
    "        x, transformer_attn_weights = self.attention_module(x)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(x)\n",
    "        \n",
    "        if return_attention:\n",
    "            attention_dict = {\n",
    "                'channel_attention': channel_attn_scores,  # (B, 22)\n",
    "                'transformer_attention': transformer_attn_weights,  # List of (B, T, T) for each layer\n",
    "            }\n",
    "            return logits, attention_dict\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "class AttentionRegularizedLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, alpha=0.01, beta=0.01):\n",
    "        super().__init__()\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.alpha = alpha  # Channel attention regularization weight\n",
    "        self.beta = beta    # Transformer attention regularization weight\n",
    "        \n",
    "    def forward(self, logits, targets, attention_dict):\n",
    "        # Classification loss\n",
    "        ce = self.ce_loss(logits, targets)\n",
    "        \n",
    "        # Channel attention regularization (encourage diversity)\n",
    "        \n",
    "        # Transformer attention regularization (discourage extreme peakiness)\n",
    "        transformer_attn = attention_dict['transformer_attention'][-1]  # Use last layer (B, T, T)\n",
    "        # Variance is always non-negative (variance >= 0)\n",
    "        attn_variance = torch.var(transformer_attn, dim=-1).mean()\n",
    "        \n",
    "        # Calculate total loss: CE + (alpha * negative_entropy) + (beta * variance)\n",
    "        # Since alpha * negative_entropy is negative, it reduces the loss.\n",
    "        total_loss = ce + self.beta * attn_variance\n",
    "        \n",
    "        # *** CRITICAL FIX: Ensure Total Loss is Non-Negative ***\n",
    "        # If CE is near zero, the negative channel_reg term can cause total_loss < 0.\n",
    "        # Clipping maintains optimization goal while ensuring mathematical stability.\n",
    "        total_loss = torch.max(total_loss, torch.tensor(0.0, device=total_loss.device))\n",
    "        \n",
    "        return total_loss, {\n",
    "            'ce_loss': ce.item(),\n",
    "            'attn_variance': attn_variance.item()\n",
    "        }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f850fe",
   "metadata": {},
   "source": [
    "# test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "484720f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     # Model initialization\n",
    "#     model = EEGClassifier(\n",
    "#         num_samples=1000,\n",
    "#         num_classes=4,\n",
    "#         d_model=64,  # Reduced from 128\n",
    "#         n_heads=4,   # Reduced from 8\n",
    "#         transformer_layers=2,\n",
    "#         dropout=0.3,\n",
    "#         learnable_window=False  # Start with fixed window\n",
    "#     )\n",
    "    \n",
    "#     # Loss function\n",
    "#     criterion = AttentionRegularizedLoss(num_classes=4, alpha=0.01, beta=0.01)\n",
    "    \n",
    "#     # Dummy data\n",
    "#     x = torch.randn(4, 22, 1000)  # (batch, channels, time)\n",
    "#     y = torch.randint(0, 4, (4,))\n",
    "    \n",
    "#     # Forward pass with attention\n",
    "#     logits, attention_dict = model(x, return_attention=True)\n",
    "    \n",
    "#     # Calculate loss\n",
    "#     loss, loss_dict = criterion(logits, y, attention_dict)\n",
    "    \n",
    "#     print(f\"Logits shape: {logits.shape}\")\n",
    "#     print(f\"Channel attention shape: {attention_dict['channel_attention'].shape}\")\n",
    "#     print(f\"Num transformer layers: {len(attention_dict['transformer_attention'])}\")\n",
    "#     print(f\"Transformer attention shape: {attention_dict['transformer_attention'][0].shape}\")\n",
    "#     print(f\"Total loss: {loss.item():.4f}\")\n",
    "#     print(f\"Loss components: {loss_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313f023b",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c483a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 11:04:27.483374: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-29 11:04:27.532755: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-29 11:04:27.532803: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-29 11:04:27.532835: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-29 11:04:27.542505: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-29 11:04:28.745245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import json\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "class EEGTrainer:\n",
    "    def __init__(self, model, train_loader, val_loader, test_loader=None, config=None):\n",
    "\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        \n",
    "        # Set device\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "        # Default configuration\n",
    "        self.config = {\n",
    "            'lr': 1e-3,\n",
    "            'weight_decay': 1e-4,\n",
    "            'patience': 10,\n",
    "            'min_lr': 1e-6,\n",
    "            'epochs': 100,\n",
    "            'save_dir': 'experiments',\n",
    "            'experiment_name': f'exp_{time.strftime(\"%Y%m%d-%H%M%S\")}',\n",
    "            'save_attention_maps': True,\n",
    "            'attention_map_freq': 5\n",
    "        }\n",
    "        \n",
    "        # Update with user config if provided\n",
    "        if config:\n",
    "            self.config.update(config)\n",
    "            \n",
    "        # Create experiment directory\n",
    "        self.exp_dir = os.path.join(self.config['save_dir'], self.config['experiment_name'])\n",
    "        os.makedirs(self.exp_dir, exist_ok=True)\n",
    "        \n",
    "        # Initialize components\n",
    "        self._init_components()\n",
    "        \n",
    "        # Save config\n",
    "        self._save_config()\n",
    "        \n",
    "    def _init_components(self):\n",
    "        \"\"\"Initialize training components\"\"\"\n",
    "        # Loss function (CrossEntropy + KLDiv for attention regularization)\n",
    "        self.criterion = AttentionRegularizedLoss(num_classes=4, alpha=0.01, beta=0.01)#nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=self.config['lr'],\n",
    "            weight_decay=self.config['weight_decay']\n",
    "        )\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        self.scheduler = ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='max',\n",
    "            factor=0.5,\n",
    "            patience=self.config['patience']//2,\n",
    "            min_lr=self.config['min_lr'],\n",
    "            #verbose=True\n",
    "        )\n",
    "        \n",
    "        self.best_val_acc = 0.0\n",
    "        self.early_stop_counter = 0\n",
    "        \n",
    "        # Tensorboard writer\n",
    "        self.writer = SummaryWriter(log_dir=self.exp_dir)\n",
    "        \n",
    "        # Attention maps directory\n",
    "        if self.config['save_attention_maps']:\n",
    "            self.attention_dir = os.path.join(self.exp_dir, 'attention_maps')\n",
    "            os.makedirs(self.attention_dir, exist_ok=True)\n",
    "    \n",
    "    def _save_config(self):\n",
    "        config_path = os.path.join(self.exp_dir, 'config.json')\n",
    "        with open(config_path, 'w') as f:\n",
    "            json.dump(self.config, f, indent=4)\n",
    "    \n",
    "    def _compute_metrics(self, outputs, labels):\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        accuracy = correct / labels.size(0)\n",
    "        return accuracy\n",
    "    \n",
    "    def _log_metrics(self, phase, metrics, epoch):\n",
    "        loss = metrics['loss']\n",
    "        acc = metrics['accuracy']\n",
    "        pre = metrics['precision']\n",
    "        rec = metrics['recall']\n",
    "        f1 = metrics['f1']\n",
    "        \n",
    "        # Console logging\n",
    "        print(f\"{phase.capitalize()} - Epoch: {epoch+1} | \"\n",
    "              f\"Loss: {loss:.4f} | Acc: {acc:.2%} | Precision: {pre:.2%} | recall: {rec:.2%} | f1: {f1:.2%}\")\n",
    "        \n",
    "        # Tensorboard logging\n",
    "        self.writer.add_scalar(f'Loss/{phase}', loss, epoch)\n",
    "        self.writer.add_scalar(f'Accuracy/{phase}', acc, epoch)\n",
    "        \n",
    "        \n",
    "        # Log learning rate\n",
    "        if phase == 'train':\n",
    "            lr = self.optimizer.param_groups[0]['lr']\n",
    "            self.writer.add_scalar('LR', lr, epoch)\n",
    "    \n",
    "    def _save_checkpoint(self, epoch, is_best=False):\n",
    "        \"\"\"Save model checkpoint\"\"\"\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'state_dict': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "            'scheduler': self.scheduler.state_dict(),\n",
    "            'best_val_acc': self.best_val_acc\n",
    "        }\n",
    "        \n",
    "        # Save regular checkpoint\n",
    "        checkpoint_path = os.path.join(self.exp_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "        torch.save(state, checkpoint_path)\n",
    "        \n",
    "        # Save best model\n",
    "        if is_best:\n",
    "            best_path = os.path.join(self.exp_dir, 'best_model.pth')\n",
    "            torch.save(state, best_path)\n",
    "    \n",
    "\n",
    "    \n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Store all predictions and labels for epoch-wise metrics\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for inputs, labels in self.train_loader:\n",
    "            inputs = inputs.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "\n",
    "            # Zero gradients\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs, attention_dict = self.model(inputs, return_attention=True)\n",
    "            loss ,_ = self.criterion(outputs, labels,attention_dict)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # ----- accumulate loss -----\n",
    "            batch_size = inputs.size(0)\n",
    "            running_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "            # ----- accumulate preds + labels for metrics -----\n",
    "            preds = torch.argmax(outputs, dim=1)          # [B]\n",
    "            all_preds.append(preds.detach().cpu())\n",
    "            all_labels.append(labels.detach().cpu())\n",
    "\n",
    "        # ---- end of epoch: stack everything and compute metrics ----\n",
    "        all_preds = torch.cat(all_preds).numpy()\n",
    "        all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "        epoch_loss = running_loss / total_samples\n",
    "\n",
    "        # accuracy\n",
    "        epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "        # precision, recall, f1\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_labels,\n",
    "            all_preds,\n",
    "            average='weighted',      # change to 'macro' / 'binary' if needed\n",
    "            zero_division=0          # avoid NaN if a class is missing in preds\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'loss': epoch_loss,\n",
    "            'accuracy': epoch_acc,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "        }\n",
    "\n",
    "\n",
    "    \n",
    "    def validate_epoch(self, epoch):\n",
    "        \"\"\"Validate for one epoch\"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.val_loader:\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "     \n",
    "                # Forward pass\n",
    "                #outputs = self.model(inputs)\n",
    "                outputs, attention_dict = self.model(inputs, return_attention=True)\n",
    "                loss, _ = self.criterion(outputs, labels, attention_dict)\n",
    "                #loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                batch_size = inputs.size(0)\n",
    "                running_loss += loss.item() * batch_size\n",
    "                total_samples += batch_size\n",
    "\n",
    "                # ----- accumulate preds + labels for metrics -----\n",
    "                preds = torch.argmax(outputs, dim=1)          # [B]\n",
    "                all_preds.append(preds.detach().cpu())\n",
    "                all_labels.append(labels.detach().cpu())\n",
    "\n",
    "            # ---- end of epoch: stack everything and compute metrics ----\n",
    "            all_preds = torch.cat(all_preds).numpy()\n",
    "            all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "            epoch_loss = running_loss / total_samples\n",
    "\n",
    "            # accuracy\n",
    "            epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "            # precision, recall, f1\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                all_labels,\n",
    "                all_preds,\n",
    "                average='weighted',      # change to 'macro' / 'binary' if needed\n",
    "                zero_division=0          # avoid NaN if a class is missing in preds\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                'loss': epoch_loss,\n",
    "                'accuracy': epoch_acc,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1,\n",
    "            }\n",
    "    def train(self):\n",
    "        \"\"\"Main training loop\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(self.config['epochs']):\n",
    "            # Train and validate\n",
    "            train_metrics = self.train_epoch(epoch)\n",
    "            val_metrics = self.validate_epoch(epoch)\n",
    "            \n",
    "            # Log metrics\n",
    "            self._log_metrics('train', train_metrics, epoch)\n",
    "            self._log_metrics('val', val_metrics, epoch)\n",
    "            \n",
    "            # Save attention maps periodically\n",
    "            \n",
    "            # Step scheduler\n",
    "            self.scheduler.step(val_metrics['accuracy'])\n",
    "            \n",
    "            # Check for best model\n",
    "            if val_metrics['accuracy'] > self.best_val_acc:\n",
    "                self.best_val_acc = val_metrics['accuracy']\n",
    "                self._save_checkpoint(epoch, is_best=True)\n",
    "                self.early_stop_counter = 0\n",
    "            else:\n",
    "                self.early_stop_counter += 1\n",
    "            \n",
    "            # Save checkpoint periodically\n",
    "            if epoch % 10 == 0:\n",
    "                self._save_checkpoint(epoch)\n",
    "            \n",
    "            # Early stopping\n",
    "            # if self.early_stop_counter >= self.config['patience']:\n",
    "            #     print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            #     break\n",
    "        \n",
    "        # Training complete\n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"Training completed in {training_time//60:.0f}m {training_time%60:.0f}s\")\n",
    "        print(f\"Best validation accuracy: {self.best_val_acc:.2%}\")\n",
    "        \n",
    "        # Test if test loader provided\n",
    "        if self.test_loader:\n",
    "            test_acc = self.test()\n",
    "            print(f\"Test accuracy: {test_acc:.2%}\")\n",
    "        \n",
    "        # Close tensorboard writer\n",
    "        self.writer.close()\n",
    "        \n",
    "        return self.best_val_acc\n",
    "    \n",
    "    def test(self):\n",
    "        \"\"\"Evaluate on test set\"\"\"\n",
    "        self.model.eval()\n",
    "        running_acc = 0.0\n",
    "        total_samples = 0\n",
    "        \n",
    "        # Load best model\n",
    "        best_path = os.path.join(self.exp_dir, 'best_model.pth')\n",
    "        if os.path.exists(best_path):\n",
    "            checkpoint = torch.load(best_path)\n",
    "            self.model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n",
    "        \n",
    "        all_preds=[]\n",
    "        all_labels=[]\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.test_loader:\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                batch_size = inputs.size(0)\n",
    "                total_samples += batch_size\n",
    "\n",
    "                # ----- accumulate preds + labels for metrics -----\n",
    "                preds = torch.argmax(outputs, dim=1)          # [B]\n",
    "                all_preds.append(preds.detach().cpu())\n",
    "                all_labels.append(labels.detach().cpu())\n",
    "\n",
    "            # ---- end of epoch: stack everything and compute metrics ----\n",
    "            all_preds = torch.cat(all_preds).numpy()\n",
    "            all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "            epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "            # precision, recall, f1\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                all_labels,\n",
    "                all_preds,\n",
    "                average='weighted',      # change to 'macro' / 'binary' if needed\n",
    "                zero_division=0          # avoid NaN if a class is missing in preds\n",
    "            )\n",
    "        \n",
    "        test_acc = epoch_acc\n",
    "        self.writer.add_scalar('Accuracy/test', test_acc)\n",
    "        print(\"acc: \",test_acc)\n",
    "        print(\"precision:\", precision)\n",
    "        print(\"recall:\", recall)\n",
    "        print(\"F1 :\", f1)\n",
    "        return epoch_acc\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef686541",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf259697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train+Val dataset size: 4592\n",
      "Test dataset size: 1148\n",
      "Train batches: 115\n",
      "Val batches: 29\n",
      "Test batches: 36\n",
      "Single Trial Shape: (22, 1501)\n",
      "Train - Epoch: 1 | Loss: 1.4065 | Acc: 23.88% | Precision: 23.81% | recall: 23.88% | f1: 23.79%\n",
      "Val - Epoch: 1 | Loss: 1.3900 | Acc: 24.81% | Precision: 6.16% | recall: 24.81% | f1: 9.86%\n",
      "Train - Epoch: 2 | Loss: 1.3942 | Acc: 25.65% | Precision: 25.70% | recall: 25.65% | f1: 25.56%\n",
      "Val - Epoch: 2 | Loss: 1.3904 | Acc: 25.14% | Precision: 6.32% | recall: 25.14% | f1: 10.10%\n",
      "Train - Epoch: 3 | Loss: 1.3894 | Acc: 25.92% | Precision: 26.00% | recall: 25.92% | f1: 25.86%\n",
      "Val - Epoch: 3 | Loss: 1.3862 | Acc: 25.14% | Precision: 6.32% | recall: 25.14% | f1: 10.10%\n",
      "Train - Epoch: 4 | Loss: 1.3874 | Acc: 26.87% | Precision: 26.78% | recall: 26.87% | f1: 26.04%\n",
      "Val - Epoch: 4 | Loss: 1.3844 | Acc: 26.88% | Precision: 23.07% | recall: 26.88% | f1: 17.20%\n",
      "Train - Epoch: 5 | Loss: 1.3840 | Acc: 27.74% | Precision: 27.04% | recall: 27.74% | f1: 26.45%\n",
      "Val - Epoch: 5 | Loss: 1.3880 | Acc: 26.44% | Precision: 22.03% | recall: 26.44% | f1: 18.15%\n",
      "Train - Epoch: 6 | Loss: 1.3779 | Acc: 28.12% | Precision: 27.72% | recall: 28.12% | f1: 27.37%\n",
      "Val - Epoch: 6 | Loss: 1.3745 | Acc: 29.27% | Precision: 30.41% | recall: 29.27% | f1: 24.04%\n",
      "Train - Epoch: 7 | Loss: 1.3781 | Acc: 29.29% | Precision: 28.88% | recall: 29.29% | f1: 28.20%\n",
      "Val - Epoch: 7 | Loss: 1.3752 | Acc: 29.05% | Precision: 22.96% | recall: 29.05% | f1: 20.44%\n",
      "Train - Epoch: 8 | Loss: 1.3658 | Acc: 30.19% | Precision: 29.11% | recall: 30.19% | f1: 28.28%\n",
      "Val - Epoch: 8 | Loss: 1.3605 | Acc: 29.92% | Precision: 30.63% | recall: 29.92% | f1: 29.71%\n",
      "Train - Epoch: 9 | Loss: 1.3571 | Acc: 31.15% | Precision: 31.06% | recall: 31.15% | f1: 30.02%\n",
      "Val - Epoch: 9 | Loss: 1.3657 | Acc: 29.60% | Precision: 22.08% | recall: 29.60% | f1: 22.88%\n",
      "Train - Epoch: 10 | Loss: 1.3530 | Acc: 31.80% | Precision: 31.49% | recall: 31.80% | f1: 31.52%\n",
      "Val - Epoch: 10 | Loss: 1.3531 | Acc: 30.47% | Precision: 31.94% | recall: 30.47% | f1: 19.93%\n",
      "Train - Epoch: 11 | Loss: 1.3355 | Acc: 32.86% | Precision: 32.76% | recall: 32.86% | f1: 32.36%\n",
      "Val - Epoch: 11 | Loss: 1.3279 | Acc: 33.30% | Precision: 26.12% | recall: 33.30% | f1: 25.62%\n",
      "Train - Epoch: 12 | Loss: 1.3145 | Acc: 35.01% | Precision: 35.47% | recall: 35.01% | f1: 34.35%\n",
      "Val - Epoch: 12 | Loss: 1.3235 | Acc: 36.13% | Precision: 35.61% | recall: 36.13% | f1: 33.56%\n",
      "Train - Epoch: 13 | Loss: 1.3025 | Acc: 36.24% | Precision: 36.85% | recall: 36.24% | f1: 35.54%\n",
      "Val - Epoch: 13 | Loss: 1.3341 | Acc: 33.19% | Precision: 45.99% | recall: 33.19% | f1: 27.92%\n",
      "Train - Epoch: 14 | Loss: 1.2868 | Acc: 37.82% | Precision: 38.62% | recall: 37.82% | f1: 37.55%\n",
      "Val - Epoch: 14 | Loss: 1.3412 | Acc: 38.19% | Precision: 39.77% | recall: 38.19% | f1: 35.13%\n",
      "Train - Epoch: 15 | Loss: 1.2524 | Acc: 39.99% | Precision: 41.39% | recall: 39.99% | f1: 39.62%\n",
      "Val - Epoch: 15 | Loss: 1.2681 | Acc: 41.78% | Precision: 46.79% | recall: 41.78% | f1: 40.95%\n",
      "Train - Epoch: 16 | Loss: 1.2204 | Acc: 43.78% | Precision: 45.25% | recall: 43.78% | f1: 43.89%\n",
      "Val - Epoch: 16 | Loss: 1.2431 | Acc: 40.70% | Precision: 48.13% | recall: 40.70% | f1: 38.90%\n",
      "Train - Epoch: 17 | Loss: 1.1947 | Acc: 43.70% | Precision: 45.57% | recall: 43.70% | f1: 44.08%\n",
      "Val - Epoch: 17 | Loss: 1.2321 | Acc: 42.00% | Precision: 43.95% | recall: 42.00% | f1: 41.55%\n",
      "Train - Epoch: 18 | Loss: 1.1596 | Acc: 47.15% | Precision: 48.87% | recall: 47.15% | f1: 47.41%\n",
      "Val - Epoch: 18 | Loss: 1.2269 | Acc: 42.87% | Precision: 50.72% | recall: 42.87% | f1: 40.28%\n",
      "Train - Epoch: 19 | Loss: 1.1127 | Acc: 50.37% | Precision: 52.43% | recall: 50.37% | f1: 50.78%\n",
      "Val - Epoch: 19 | Loss: 1.2095 | Acc: 45.70% | Precision: 52.83% | recall: 45.70% | f1: 44.41%\n",
      "Train - Epoch: 20 | Loss: 1.0998 | Acc: 51.70% | Precision: 53.53% | recall: 51.70% | f1: 52.16%\n",
      "Val - Epoch: 20 | Loss: 1.1550 | Acc: 48.10% | Precision: 50.93% | recall: 48.10% | f1: 47.43%\n",
      "Train - Epoch: 21 | Loss: 1.0401 | Acc: 55.16% | Precision: 56.62% | recall: 55.16% | f1: 55.44%\n",
      "Val - Epoch: 21 | Loss: 1.1707 | Acc: 46.68% | Precision: 51.35% | recall: 46.68% | f1: 47.16%\n",
      "Train - Epoch: 22 | Loss: 0.9901 | Acc: 58.18% | Precision: 59.62% | recall: 58.18% | f1: 58.46%\n",
      "Val - Epoch: 22 | Loss: 1.0801 | Acc: 52.67% | Precision: 54.04% | recall: 52.67% | f1: 52.27%\n",
      "Train - Epoch: 23 | Loss: 0.9279 | Acc: 61.34% | Precision: 62.29% | recall: 61.34% | f1: 61.57%\n",
      "Val - Epoch: 23 | Loss: 1.0928 | Acc: 52.23% | Precision: 55.75% | recall: 52.23% | f1: 51.19%\n",
      "Train - Epoch: 24 | Loss: 0.8726 | Acc: 64.52% | Precision: 65.76% | recall: 64.52% | f1: 64.81%\n",
      "Val - Epoch: 24 | Loss: 1.0787 | Acc: 54.41% | Precision: 58.77% | recall: 54.41% | f1: 54.81%\n",
      "Train - Epoch: 25 | Loss: 0.8204 | Acc: 66.51% | Precision: 67.26% | recall: 66.51% | f1: 66.70%\n",
      "Val - Epoch: 25 | Loss: 1.0294 | Acc: 57.02% | Precision: 62.72% | recall: 57.02% | f1: 56.91%\n",
      "Train - Epoch: 26 | Loss: 0.7726 | Acc: 69.81% | Precision: 70.58% | recall: 69.81% | f1: 69.92%\n",
      "Val - Epoch: 26 | Loss: 1.0985 | Acc: 55.39% | Precision: 57.94% | recall: 55.39% | f1: 55.45%\n",
      "Train - Epoch: 27 | Loss: 0.7315 | Acc: 71.74% | Precision: 71.93% | recall: 71.74% | f1: 71.73%\n",
      "Val - Epoch: 27 | Loss: 0.9389 | Acc: 61.92% | Precision: 62.36% | recall: 61.92% | f1: 60.98%\n",
      "Train - Epoch: 28 | Loss: 0.6451 | Acc: 75.03% | Precision: 75.23% | recall: 75.03% | f1: 75.05%\n",
      "Val - Epoch: 28 | Loss: 0.9949 | Acc: 60.50% | Precision: 63.24% | recall: 60.50% | f1: 59.13%\n",
      "Train - Epoch: 29 | Loss: 0.6024 | Acc: 77.43% | Precision: 77.59% | recall: 77.43% | f1: 77.46%\n",
      "Val - Epoch: 29 | Loss: 0.9070 | Acc: 63.87% | Precision: 63.61% | recall: 63.87% | f1: 63.56%\n",
      "Train - Epoch: 30 | Loss: 0.5585 | Acc: 79.58% | Precision: 79.69% | recall: 79.58% | f1: 79.60%\n",
      "Val - Epoch: 30 | Loss: 0.8694 | Acc: 69.42% | Precision: 69.72% | recall: 69.42% | f1: 69.51%\n",
      "Train - Epoch: 31 | Loss: 0.5125 | Acc: 81.30% | Precision: 81.32% | recall: 81.30% | f1: 81.29%\n",
      "Val - Epoch: 31 | Loss: 0.7982 | Acc: 72.47% | Precision: 73.17% | recall: 72.47% | f1: 72.65%\n",
      "Train - Epoch: 32 | Loss: 0.4481 | Acc: 83.72% | Precision: 83.76% | recall: 83.72% | f1: 83.73%\n",
      "Val - Epoch: 32 | Loss: 0.8603 | Acc: 71.38% | Precision: 71.58% | recall: 71.38% | f1: 71.26%\n",
      "Train - Epoch: 33 | Loss: 0.4249 | Acc: 84.89% | Precision: 84.96% | recall: 84.89% | f1: 84.90%\n",
      "Val - Epoch: 33 | Loss: 0.8214 | Acc: 73.23% | Precision: 74.69% | recall: 73.23% | f1: 72.88%\n",
      "Train - Epoch: 34 | Loss: 0.4084 | Acc: 85.38% | Precision: 85.42% | recall: 85.38% | f1: 85.39%\n",
      "Val - Epoch: 34 | Loss: 0.7789 | Acc: 75.73% | Precision: 76.45% | recall: 75.73% | f1: 75.87%\n",
      "Train - Epoch: 35 | Loss: 0.3630 | Acc: 87.10% | Precision: 87.13% | recall: 87.10% | f1: 87.10%\n",
      "Val - Epoch: 35 | Loss: 0.7169 | Acc: 77.80% | Precision: 78.95% | recall: 77.80% | f1: 77.81%\n",
      "Train - Epoch: 36 | Loss: 0.3226 | Acc: 88.95% | Precision: 88.96% | recall: 88.95% | f1: 88.95%\n",
      "Val - Epoch: 36 | Loss: 0.7172 | Acc: 78.78% | Precision: 79.51% | recall: 78.78% | f1: 78.86%\n",
      "Train - Epoch: 37 | Loss: 0.2804 | Acc: 90.42% | Precision: 90.44% | recall: 90.42% | f1: 90.42%\n",
      "Val - Epoch: 37 | Loss: 0.7326 | Acc: 77.91% | Precision: 79.72% | recall: 77.91% | f1: 77.92%\n",
      "Train - Epoch: 38 | Loss: 0.2616 | Acc: 91.53% | Precision: 91.54% | recall: 91.53% | f1: 91.53%\n",
      "Val - Epoch: 38 | Loss: 0.6676 | Acc: 82.15% | Precision: 82.46% | recall: 82.15% | f1: 82.19%\n",
      "Train - Epoch: 39 | Loss: 0.2534 | Acc: 91.37% | Precision: 91.37% | recall: 91.37% | f1: 91.37%\n",
      "Val - Epoch: 39 | Loss: 0.6562 | Acc: 81.50% | Precision: 81.84% | recall: 81.50% | f1: 81.36%\n",
      "Train - Epoch: 40 | Loss: 0.2319 | Acc: 91.94% | Precision: 91.96% | recall: 91.94% | f1: 91.94%\n",
      "Val - Epoch: 40 | Loss: 0.7509 | Acc: 79.76% | Precision: 80.09% | recall: 79.76% | f1: 79.83%\n",
      "Train - Epoch: 41 | Loss: 0.2266 | Acc: 92.57% | Precision: 92.57% | recall: 92.57% | f1: 92.57%\n",
      "Val - Epoch: 41 | Loss: 0.6477 | Acc: 82.81% | Precision: 83.41% | recall: 82.81% | f1: 82.84%\n",
      "Train - Epoch: 42 | Loss: 0.1937 | Acc: 93.63% | Precision: 93.64% | recall: 93.63% | f1: 93.63%\n",
      "Val - Epoch: 42 | Loss: 0.6467 | Acc: 83.46% | Precision: 83.68% | recall: 83.46% | f1: 83.50%\n",
      "Train - Epoch: 43 | Loss: 0.1889 | Acc: 93.44% | Precision: 93.44% | recall: 93.44% | f1: 93.44%\n",
      "Val - Epoch: 43 | Loss: 0.7005 | Acc: 80.85% | Precision: 81.29% | recall: 80.85% | f1: 80.90%\n",
      "Train - Epoch: 44 | Loss: 0.1975 | Acc: 93.77% | Precision: 93.77% | recall: 93.77% | f1: 93.77%\n",
      "Val - Epoch: 44 | Loss: 0.6407 | Acc: 83.90% | Precision: 84.64% | recall: 83.90% | f1: 83.89%\n",
      "Train - Epoch: 45 | Loss: 0.1762 | Acc: 94.15% | Precision: 94.15% | recall: 94.15% | f1: 94.15%\n",
      "Val - Epoch: 45 | Loss: 0.6118 | Acc: 83.90% | Precision: 84.01% | recall: 83.90% | f1: 83.88%\n",
      "Train - Epoch: 46 | Loss: 0.1601 | Acc: 94.99% | Precision: 94.99% | recall: 94.99% | f1: 94.99%\n",
      "Val - Epoch: 46 | Loss: 0.6065 | Acc: 85.31% | Precision: 85.62% | recall: 85.31% | f1: 85.30%\n",
      "Train - Epoch: 47 | Loss: 0.1400 | Acc: 95.24% | Precision: 95.24% | recall: 95.24% | f1: 95.23%\n",
      "Val - Epoch: 47 | Loss: 0.6382 | Acc: 84.22% | Precision: 84.41% | recall: 84.22% | f1: 84.22%\n",
      "Train - Epoch: 48 | Loss: 0.1871 | Acc: 94.12% | Precision: 94.12% | recall: 94.12% | f1: 94.12%\n",
      "Val - Epoch: 48 | Loss: 0.6037 | Acc: 83.90% | Precision: 84.14% | recall: 83.90% | f1: 83.85%\n",
      "Train - Epoch: 49 | Loss: 0.1421 | Acc: 95.53% | Precision: 95.54% | recall: 95.53% | f1: 95.54%\n",
      "Val - Epoch: 49 | Loss: 0.6246 | Acc: 85.20% | Precision: 85.59% | recall: 85.20% | f1: 85.18%\n",
      "Train - Epoch: 50 | Loss: 0.1351 | Acc: 95.83% | Precision: 95.84% | recall: 95.83% | f1: 95.83%\n",
      "Val - Epoch: 50 | Loss: 0.6795 | Acc: 83.46% | Precision: 84.28% | recall: 83.46% | f1: 83.41%\n",
      "Train - Epoch: 51 | Loss: 0.1381 | Acc: 95.67% | Precision: 95.68% | recall: 95.67% | f1: 95.67%\n",
      "Val - Epoch: 51 | Loss: 0.6238 | Acc: 84.98% | Precision: 85.99% | recall: 84.98% | f1: 84.90%\n",
      "Train - Epoch: 52 | Loss: 0.1432 | Acc: 95.37% | Precision: 95.37% | recall: 95.37% | f1: 95.37%\n",
      "Val - Epoch: 52 | Loss: 0.6234 | Acc: 84.98% | Precision: 85.27% | recall: 84.98% | f1: 84.98%\n",
      "Train - Epoch: 53 | Loss: 0.1261 | Acc: 95.62% | Precision: 95.62% | recall: 95.62% | f1: 95.62%\n",
      "Val - Epoch: 53 | Loss: 0.5795 | Acc: 86.29% | Precision: 86.46% | recall: 86.29% | f1: 86.28%\n",
      "Train - Epoch: 54 | Loss: 0.1194 | Acc: 96.19% | Precision: 96.19% | recall: 96.19% | f1: 96.19%\n",
      "Val - Epoch: 54 | Loss: 0.6071 | Acc: 87.05% | Precision: 87.28% | recall: 87.05% | f1: 87.07%\n",
      "Train - Epoch: 55 | Loss: 0.1140 | Acc: 96.38% | Precision: 96.38% | recall: 96.38% | f1: 96.38%\n",
      "Val - Epoch: 55 | Loss: 0.6319 | Acc: 85.20% | Precision: 85.31% | recall: 85.20% | f1: 85.13%\n",
      "Train - Epoch: 56 | Loss: 0.1126 | Acc: 96.38% | Precision: 96.38% | recall: 96.38% | f1: 96.38%\n",
      "Val - Epoch: 56 | Loss: 0.6274 | Acc: 85.31% | Precision: 85.83% | recall: 85.31% | f1: 85.29%\n",
      "Train - Epoch: 57 | Loss: 0.1122 | Acc: 96.60% | Precision: 96.60% | recall: 96.60% | f1: 96.60%\n",
      "Val - Epoch: 57 | Loss: 0.6130 | Acc: 85.96% | Precision: 86.30% | recall: 85.96% | f1: 86.01%\n",
      "Train - Epoch: 58 | Loss: 0.1114 | Acc: 96.41% | Precision: 96.41% | recall: 96.41% | f1: 96.41%\n",
      "Val - Epoch: 58 | Loss: 0.6057 | Acc: 86.62% | Precision: 86.70% | recall: 86.62% | f1: 86.61%\n",
      "Train - Epoch: 59 | Loss: 0.1014 | Acc: 96.81% | Precision: 96.81% | recall: 96.81% | f1: 96.81%\n",
      "Val - Epoch: 59 | Loss: 0.6793 | Acc: 85.20% | Precision: 85.53% | recall: 85.20% | f1: 85.23%\n",
      "Train - Epoch: 60 | Loss: 0.1009 | Acc: 96.95% | Precision: 96.95% | recall: 96.95% | f1: 96.95%\n",
      "Val - Epoch: 60 | Loss: 0.6429 | Acc: 85.64% | Precision: 85.96% | recall: 85.64% | f1: 85.64%\n",
      "Train - Epoch: 61 | Loss: 0.1085 | Acc: 96.52% | Precision: 96.52% | recall: 96.52% | f1: 96.52%\n",
      "Val - Epoch: 61 | Loss: 0.5951 | Acc: 86.83% | Precision: 86.96% | recall: 86.83% | f1: 86.86%\n",
      "Train - Epoch: 62 | Loss: 0.0869 | Acc: 97.11% | Precision: 97.11% | recall: 97.11% | f1: 97.11%\n",
      "Val - Epoch: 62 | Loss: 0.6032 | Acc: 86.51% | Precision: 86.66% | recall: 86.51% | f1: 86.51%\n",
      "Train - Epoch: 63 | Loss: 0.0692 | Acc: 97.63% | Precision: 97.63% | recall: 97.63% | f1: 97.63%\n",
      "Val - Epoch: 63 | Loss: 0.6042 | Acc: 88.14% | Precision: 88.32% | recall: 88.14% | f1: 88.13%\n",
      "Train - Epoch: 64 | Loss: 0.0631 | Acc: 98.18% | Precision: 98.18% | recall: 98.18% | f1: 98.18%\n",
      "Val - Epoch: 64 | Loss: 0.5855 | Acc: 88.14% | Precision: 88.13% | recall: 88.14% | f1: 88.13%\n",
      "Train - Epoch: 65 | Loss: 0.0593 | Acc: 98.07% | Precision: 98.07% | recall: 98.07% | f1: 98.07%\n",
      "Val - Epoch: 65 | Loss: 0.5748 | Acc: 89.12% | Precision: 89.13% | recall: 89.12% | f1: 89.11%\n",
      "Train - Epoch: 66 | Loss: 0.0402 | Acc: 98.91% | Precision: 98.91% | recall: 98.91% | f1: 98.91%\n",
      "Val - Epoch: 66 | Loss: 0.6367 | Acc: 88.57% | Precision: 88.83% | recall: 88.57% | f1: 88.53%\n",
      "Train - Epoch: 67 | Loss: 0.0515 | Acc: 98.37% | Precision: 98.37% | recall: 98.37% | f1: 98.37%\n",
      "Val - Epoch: 67 | Loss: 0.5961 | Acc: 89.12% | Precision: 89.14% | recall: 89.12% | f1: 89.12%\n",
      "Train - Epoch: 68 | Loss: 0.0418 | Acc: 98.61% | Precision: 98.61% | recall: 98.61% | f1: 98.61%\n",
      "Val - Epoch: 68 | Loss: 0.6060 | Acc: 88.68% | Precision: 88.72% | recall: 88.68% | f1: 88.66%\n",
      "Train - Epoch: 69 | Loss: 0.0436 | Acc: 98.48% | Precision: 98.48% | recall: 98.48% | f1: 98.48%\n",
      "Val - Epoch: 69 | Loss: 0.6016 | Acc: 88.79% | Precision: 88.83% | recall: 88.79% | f1: 88.76%\n",
      "Train - Epoch: 70 | Loss: 0.0468 | Acc: 98.80% | Precision: 98.80% | recall: 98.80% | f1: 98.80%\n",
      "Val - Epoch: 70 | Loss: 0.6139 | Acc: 88.68% | Precision: 88.77% | recall: 88.68% | f1: 88.66%\n",
      "Train - Epoch: 71 | Loss: 0.0402 | Acc: 98.86% | Precision: 98.86% | recall: 98.86% | f1: 98.86%\n",
      "Val - Epoch: 71 | Loss: 0.6251 | Acc: 88.79% | Precision: 88.82% | recall: 88.79% | f1: 88.79%\n",
      "Train - Epoch: 72 | Loss: 0.0356 | Acc: 99.02% | Precision: 99.02% | recall: 99.02% | f1: 99.02%\n",
      "Val - Epoch: 72 | Loss: 0.6330 | Acc: 88.90% | Precision: 88.90% | recall: 88.90% | f1: 88.88%\n",
      "Train - Epoch: 73 | Loss: 0.0376 | Acc: 98.75% | Precision: 98.75% | recall: 98.75% | f1: 98.75%\n",
      "Val - Epoch: 73 | Loss: 0.6293 | Acc: 88.47% | Precision: 88.46% | recall: 88.47% | f1: 88.45%\n",
      "Train - Epoch: 74 | Loss: 0.0307 | Acc: 99.16% | Precision: 99.16% | recall: 99.16% | f1: 99.16%\n",
      "Val - Epoch: 74 | Loss: 0.6511 | Acc: 88.47% | Precision: 88.48% | recall: 88.47% | f1: 88.46%\n",
      "Train - Epoch: 75 | Loss: 0.0210 | Acc: 99.37% | Precision: 99.37% | recall: 99.37% | f1: 99.37%\n",
      "Val - Epoch: 75 | Loss: 0.6553 | Acc: 88.79% | Precision: 88.80% | recall: 88.79% | f1: 88.78%\n",
      "Train - Epoch: 76 | Loss: 0.0248 | Acc: 99.40% | Precision: 99.40% | recall: 99.40% | f1: 99.40%\n",
      "Val - Epoch: 76 | Loss: 0.6668 | Acc: 88.57% | Precision: 88.56% | recall: 88.57% | f1: 88.56%\n",
      "Train - Epoch: 77 | Loss: 0.0275 | Acc: 99.07% | Precision: 99.07% | recall: 99.07% | f1: 99.07%\n",
      "Val - Epoch: 77 | Loss: 0.6555 | Acc: 87.92% | Precision: 87.90% | recall: 87.92% | f1: 87.90%\n",
      "Train - Epoch: 78 | Loss: 0.0267 | Acc: 99.35% | Precision: 99.35% | recall: 99.35% | f1: 99.35%\n",
      "Val - Epoch: 78 | Loss: 0.6723 | Acc: 88.25% | Precision: 88.32% | recall: 88.25% | f1: 88.22%\n",
      "Train - Epoch: 79 | Loss: 0.0256 | Acc: 99.24% | Precision: 99.24% | recall: 99.24% | f1: 99.24%\n",
      "Val - Epoch: 79 | Loss: 0.6786 | Acc: 88.03% | Precision: 88.06% | recall: 88.03% | f1: 88.01%\n",
      "Train - Epoch: 80 | Loss: 0.0248 | Acc: 99.37% | Precision: 99.37% | recall: 99.37% | f1: 99.37%\n",
      "Val - Epoch: 80 | Loss: 0.6729 | Acc: 88.14% | Precision: 88.19% | recall: 88.14% | f1: 88.12%\n",
      "Train - Epoch: 81 | Loss: 0.0231 | Acc: 99.35% | Precision: 99.35% | recall: 99.35% | f1: 99.35%\n",
      "Val - Epoch: 81 | Loss: 0.6806 | Acc: 87.81% | Precision: 87.85% | recall: 87.81% | f1: 87.80%\n",
      "Train - Epoch: 82 | Loss: 0.0269 | Acc: 99.29% | Precision: 99.29% | recall: 99.29% | f1: 99.29%\n",
      "Val - Epoch: 82 | Loss: 0.6801 | Acc: 88.57% | Precision: 88.58% | recall: 88.57% | f1: 88.55%\n",
      "Train - Epoch: 83 | Loss: 0.0182 | Acc: 99.62% | Precision: 99.62% | recall: 99.62% | f1: 99.62%\n",
      "Val - Epoch: 83 | Loss: 0.6855 | Acc: 88.03% | Precision: 88.05% | recall: 88.03% | f1: 88.01%\n",
      "Train - Epoch: 84 | Loss: 0.0259 | Acc: 99.26% | Precision: 99.27% | recall: 99.26% | f1: 99.26%\n",
      "Val - Epoch: 84 | Loss: 0.6807 | Acc: 88.03% | Precision: 88.03% | recall: 88.03% | f1: 88.01%\n",
      "Train - Epoch: 85 | Loss: 0.0183 | Acc: 99.32% | Precision: 99.32% | recall: 99.32% | f1: 99.32%\n",
      "Val - Epoch: 85 | Loss: 0.6745 | Acc: 88.57% | Precision: 88.62% | recall: 88.57% | f1: 88.56%\n",
      "Train - Epoch: 86 | Loss: 0.0199 | Acc: 99.43% | Precision: 99.43% | recall: 99.43% | f1: 99.43%\n",
      "Val - Epoch: 86 | Loss: 0.6819 | Acc: 88.36% | Precision: 88.35% | recall: 88.36% | f1: 88.34%\n",
      "Train - Epoch: 87 | Loss: 0.0188 | Acc: 99.32% | Precision: 99.32% | recall: 99.32% | f1: 99.32%\n",
      "Val - Epoch: 87 | Loss: 0.7117 | Acc: 87.49% | Precision: 87.54% | recall: 87.49% | f1: 87.47%\n",
      "Train - Epoch: 88 | Loss: 0.0288 | Acc: 99.02% | Precision: 99.02% | recall: 99.02% | f1: 99.02%\n",
      "Val - Epoch: 88 | Loss: 0.6828 | Acc: 88.14% | Precision: 88.15% | recall: 88.14% | f1: 88.14%\n",
      "Train - Epoch: 89 | Loss: 0.0182 | Acc: 99.46% | Precision: 99.46% | recall: 99.46% | f1: 99.46%\n",
      "Val - Epoch: 89 | Loss: 0.6955 | Acc: 87.81% | Precision: 87.84% | recall: 87.81% | f1: 87.81%\n",
      "Train - Epoch: 90 | Loss: 0.0133 | Acc: 99.73% | Precision: 99.73% | recall: 99.73% | f1: 99.73%\n",
      "Val - Epoch: 90 | Loss: 0.6967 | Acc: 88.36% | Precision: 88.35% | recall: 88.36% | f1: 88.35%\n",
      "Train - Epoch: 91 | Loss: 0.0180 | Acc: 99.46% | Precision: 99.46% | recall: 99.46% | f1: 99.46%\n",
      "Val - Epoch: 91 | Loss: 0.6858 | Acc: 88.14% | Precision: 88.15% | recall: 88.14% | f1: 88.13%\n",
      "Train - Epoch: 92 | Loss: 0.0127 | Acc: 99.67% | Precision: 99.67% | recall: 99.67% | f1: 99.67%\n",
      "Val - Epoch: 92 | Loss: 0.7063 | Acc: 88.03% | Precision: 88.04% | recall: 88.03% | f1: 88.02%\n",
      "Train - Epoch: 93 | Loss: 0.0134 | Acc: 99.65% | Precision: 99.65% | recall: 99.65% | f1: 99.65%\n",
      "Val - Epoch: 93 | Loss: 0.6883 | Acc: 88.14% | Precision: 88.14% | recall: 88.14% | f1: 88.14%\n",
      "Train - Epoch: 94 | Loss: 0.0154 | Acc: 99.56% | Precision: 99.56% | recall: 99.56% | f1: 99.56%\n",
      "Val - Epoch: 94 | Loss: 0.6839 | Acc: 87.81% | Precision: 87.84% | recall: 87.81% | f1: 87.81%\n",
      "Train - Epoch: 95 | Loss: 0.0184 | Acc: 99.59% | Precision: 99.59% | recall: 99.59% | f1: 99.59%\n",
      "Val - Epoch: 95 | Loss: 0.7003 | Acc: 88.14% | Precision: 88.13% | recall: 88.14% | f1: 88.12%\n",
      "Train - Epoch: 96 | Loss: 0.0178 | Acc: 99.62% | Precision: 99.62% | recall: 99.62% | f1: 99.62%\n",
      "Val - Epoch: 96 | Loss: 0.6992 | Acc: 88.25% | Precision: 88.26% | recall: 88.25% | f1: 88.25%\n",
      "Train - Epoch: 97 | Loss: 0.0160 | Acc: 99.59% | Precision: 99.59% | recall: 99.59% | f1: 99.59%\n",
      "Val - Epoch: 97 | Loss: 0.6857 | Acc: 88.47% | Precision: 88.46% | recall: 88.47% | f1: 88.45%\n",
      "Train - Epoch: 98 | Loss: 0.0203 | Acc: 99.46% | Precision: 99.46% | recall: 99.46% | f1: 99.46%\n",
      "Val - Epoch: 98 | Loss: 0.6874 | Acc: 88.14% | Precision: 88.15% | recall: 88.14% | f1: 88.12%\n",
      "Train - Epoch: 99 | Loss: 0.0161 | Acc: 99.62% | Precision: 99.62% | recall: 99.62% | f1: 99.62%\n",
      "Val - Epoch: 99 | Loss: 0.6837 | Acc: 88.25% | Precision: 88.24% | recall: 88.25% | f1: 88.24%\n",
      "Train - Epoch: 100 | Loss: 0.0164 | Acc: 99.46% | Precision: 99.46% | recall: 99.46% | f1: 99.46%\n",
      "Val - Epoch: 100 | Loss: 0.6804 | Acc: 88.36% | Precision: 88.35% | recall: 88.36% | f1: 88.34%\n",
      "Training completed in 3m 18s\n",
      "Best validation accuracy: 89.12%\n",
      "Loaded best model from epoch 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_325546/1946701902.py:306: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(best_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.9764808362369338\n",
      "precision: 0.9765026059243082\n",
      "recall: 0.9764808362369338\n",
      "F1 : 0.9764741347306604\n",
      "Test accuracy: 97.65%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example configuration\n",
    "    config = {\n",
    "        'lr': 3e-4,\n",
    "        'weight_decay': 1e-5,\n",
    "        'patience': 15,\n",
    "        'epochs': 100,\n",
    "        'experiment_name': 'eeg_attention_experiment',\n",
    "        'save_attention_maps': True\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_loader, val_loader, test_loader, trail_shape = get_data_loaders(data_dir=\"/teamspace/studios/this_studio/EEG_REC\", all_subjects = [1,2,3,5,6,7,8,9])\n",
    "    model = EEGClassifier(num_samples = trail_shape[-1], num_classes=4)\n",
    "    # Create trainer\n",
    "    trainer = EEGTrainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    # Start training\n",
    "    best_val_acc = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1488ba3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
