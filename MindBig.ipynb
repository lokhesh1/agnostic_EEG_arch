{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b03eea36",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f557f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.signal import firwin, filtfilt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import warnings\n",
    "import torch\n",
    "import random\n",
    "from scipy.io import loadmat\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"mne\")\n",
    "# Completely silence MNE-Python output\n",
    "mne.set_log_level('WARNING')  # or 'ERROR' for even less output\n",
    "logging.getLogger('mne').setLevel(logging.WARNING)\n",
    "#mne.set_log_level('debug')\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fbae4a",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "055eea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(file_path, clas):\n",
    "\n",
    "    try:\n",
    "        raw = mne.io.read_raw_edf(file_path, preload=True)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR during file loading: {e}\")\n",
    "        return\n",
    "\n",
    "    epochs = mne.make_fixed_length_epochs(\n",
    "        raw, \n",
    "        duration=10.0, \n",
    "        overlap=1.0, \n",
    "    )\n",
    "\n",
    "    epochs.load_data() \n",
    "    label = epochs.get_data().shape[0]\n",
    "    labels=None\n",
    "    if clas == 'H':\n",
    "        labels = [0]*label\n",
    "    else:\n",
    "        labels = [1] * label\n",
    "\n",
    "    return {\"epochs\":epochs, \"labels\":labels}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c3a9d1",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe018fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.io as sio\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def gauss_smooth(inputs, device, smooth_kernel_std=2, smooth_kernel_size=100,  padding='same'):\n",
    "\n",
    "    #print(inputs.shape)\n",
    "    inputs = inputs.transpose(0, 2, 1)\n",
    "    # Get Gaussian kernel\n",
    "    inp = np.zeros(smooth_kernel_size, dtype=np.float32)\n",
    "    inp[smooth_kernel_size // 2] = 1\n",
    "    gaussKernel = gaussian_filter1d(inp, smooth_kernel_std)\n",
    "    validIdx = np.argwhere(gaussKernel > 0.01)\n",
    "    gaussKernel = gaussKernel[validIdx]\n",
    "    gaussKernel = np.squeeze(gaussKernel / np.sum(gaussKernel))\n",
    "\n",
    "    # Convert to tensor\n",
    "    gaussKernel = torch.tensor(gaussKernel, dtype=torch.float32, device=device)\n",
    "    gaussKernel = gaussKernel.view(1, 1, -1)  # [1, 1, kernel_size]\n",
    "\n",
    "    # Prepare convolution\n",
    "    B, T, C = inputs.shape\n",
    "    inputs = inputs.transpose(0, 2, 1)  # [B, C, T]\n",
    "    inputs = torch.tensor(inputs, dtype=torch.float32, device=device)\n",
    "    \n",
    "    gaussKernel = gaussKernel.repeat(C, 1, 1)  # [C, 1, kernel_size]\n",
    "\n",
    "    # Perform convolution\n",
    "    smoothed = F.conv1d(inputs, gaussKernel, padding=padding, groups=C)\n",
    "    return smoothed.detach().cpu().numpy()  # [B, T, C]\n",
    "\n",
    "from scipy.signal import filtfilt, butter\n",
    "\n",
    "def bandpass(data, low=1, high=40, fs=256, order=4):\n",
    "    nyq = fs / 2\n",
    "    b, a = butter(order, [low/nyq, high/nyq], btype='band')\n",
    "    \n",
    "    # Apply on axis=2 (time axis)\n",
    "    return filtfilt(b, a, data, axis=2)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "class BCI4_2a_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, transform=None, target_transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.data, self.labels = self._load_data()\n",
    "\n",
    "        self.labels = self.labels \n",
    "        # In your dataset __init__:\n",
    "        print(f\"Class distribution: {np.bincount(self.labels)}\")\n",
    "        print(f\"Class ratio: {np.bincount(self.labels)[1] / len(self.labels):.2%}\")\n",
    "\n",
    "\n",
    "    def _load_data(self):\n",
    "\n",
    "        df = pd.read_csv(self.data_dir, header=None)\n",
    "        df = df[df.iloc[:, 2] != -1]\n",
    "        labels = df.iloc[:, 2].values\n",
    "        all_data = []\n",
    "\n",
    "        for i, row in df.iterrows():\n",
    "            data = row.iloc[788:].astype(float).values.reshape(64, 400)\n",
    "            all_data.append(data)\n",
    "            exp_data = np.expand_dims(data, axis=0)\n",
    "            aug1 = gauss_smooth(exp_data, device='cpu', smooth_kernel_std=0.7, smooth_kernel_size=20)\n",
    "            aug2 = gauss_smooth(exp_data, device='cpu', smooth_kernel_std=2.0, smooth_kernel_size=50)\n",
    "            aug3 = gauss_smooth(exp_data, device='cpu', smooth_kernel_std=2, smooth_kernel_size=50)\n",
    "            all_data.append(np.squeeze(aug1, axis=0))\n",
    "            all_data.append(np.squeeze(aug2, axis=0))\n",
    "            all_data.append(np.squeeze(aug3, axis=0))\n",
    "        \n",
    "        # Convert list â†’ NumPy array\n",
    "        all_data = np.stack(all_data)\n",
    " \n",
    "        labels = np.repeat(labels, 3)\n",
    "\n",
    "        return all_data, labels\n",
    "    \n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.labels[idx]\n",
    "        \n",
    "        x = torch.from_numpy(x).float()  # shape: (1, timepoints, channels)\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        if self.target_transform:\n",
    "            y = self.target_transform(y)\n",
    "            \n",
    "        return x, y\n",
    "\n",
    "def get_data_loaders(data_dir, batch_size=32, test_split= 0.2, val_split=0.2, random_state=42):\n",
    "    # Get all subjects except the test subject for training/validation\n",
    "    \n",
    "    #train_val_subjects = [s for s in all_subjects if s not in test_subject]\n",
    "    \n",
    "    # Create datasets\n",
    "    train_val_dataset = BCI4_2a_Dataset(data_dir)\n",
    "    single_trial_shape = train_val_dataset.data[0].shape\n",
    "    # labels = np.array(train_val_dataset.labels)\n",
    "    # class_weights = compute_class_weight(class_weight='balanced',\n",
    "    #                                  classes=np.unique(labels),\n",
    "    #                                  y=labels)\n",
    "\n",
    "    # class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "    print(f\"Train+Val dataset size: {len(train_val_dataset)}\")\n",
    "    \n",
    "    train_idx, val_idx = train_test_split(\n",
    "        range(len(train_val_dataset)),\n",
    "        test_size=test_split,          # e.g., 0.2\n",
    "        random_state=random_state,\n",
    "        stratify=train_val_dataset.labels\n",
    "    )\n",
    "  \n",
    "\n",
    "    \n",
    "    train_dataset = torch.utils.data.Subset(train_val_dataset, train_idx)\n",
    "    val_dataset = torch.utils.data.Subset(train_val_dataset, val_idx)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    print(f\"Train batches: {len(train_loader)}\")\n",
    "    print(f\"Val batches: {len(val_loader)}\")\n",
    "    print(f\"Single Trial Shape: {single_trial_shape}\")\n",
    "    return train_loader, val_loader, single_trial_shape,None# class_weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449a4378",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "135ecd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, num_channels, reduction_ratio=4, dropout=0.1):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(num_channels, num_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),  # Added dropout\n",
    "            nn.Linear(num_channels // reduction_ratio, num_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        channel_avg = torch.mean(x, dim=2, keepdim=True)  \n",
    "        channel_max, _ = torch.max(x, dim=2, keepdim=True) \n",
    "        combined = channel_avg + channel_max  \n",
    "        combined = combined.squeeze(2)\n",
    "        attention = self.mlp(combined)\n",
    "        attention = torch.sigmoid(attention).unsqueeze(2)\n",
    "        attended_x = x * attention\n",
    "        return attended_x, attention.squeeze(2)  # Return proper attention scores\n",
    "\n",
    "\n",
    "class LearnableSTFT(nn.Module):\n",
    "    def __init__(self, window_size, hop_size, learnable_window=True, dropout=0.05):\n",
    "        super(LearnableSTFT, self).__init__()\n",
    "        \n",
    "        self.window_size = window_size\n",
    "        self.hop_size = hop_size\n",
    "        self.dft_size = window_size\n",
    "        self.learnable_window = learnable_window\n",
    "        \n",
    "        # Initialize with Hamming window\n",
    "        initial_window = 0.54 - 0.46 * torch.cos(\n",
    "            2 * math.pi * torch.arange(window_size, dtype=torch.float32) / (window_size - 1)\n",
    "        )\n",
    "        \n",
    "        if learnable_window:\n",
    "            self.window = nn.Parameter(initial_window)\n",
    "        else:\n",
    "            # Fixed window reduces overfitting\n",
    "            self.register_buffer('window', initial_window)\n",
    "        \n",
    "        # Batch normalization after STFT\n",
    "        self.batch_norm = nn.BatchNorm2d(1)\n",
    "        self.dropout = nn.Dropout2d(dropout)\n",
    "        \n",
    "        dft_matrix = self._create_dft_matrix(self.dft_size, self.window_size)\n",
    "        self.register_buffer('dft_matrix', dft_matrix)\n",
    "\n",
    "    def _create_dft_matrix(self, dft_size, window_size):\n",
    "        k = torch.arange(dft_size).unsqueeze(1)\n",
    "        n = torch.arange(window_size)\n",
    "        angle = -2 * math.pi * k * n / dft_size\n",
    "        dft_matrix = torch.complex(torch.cos(angle), torch.sin(angle))\n",
    "        return dft_matrix\n",
    "\n",
    "    def forward(self, signal):\n",
    "        if signal.dim() == 1:\n",
    "            signal = signal.unsqueeze(0).unsqueeze(0)\n",
    "        elif signal.dim() == 2:\n",
    "            signal = signal.unsqueeze(1)\n",
    "            \n",
    "        batch_size, num_channels, num_samples = signal.shape\n",
    "        signal_reshaped = signal.reshape(batch_size * num_channels, num_samples)\n",
    "        \n",
    "        frames = signal_reshaped.unfold(dimension=1, size=self.window_size, step=self.hop_size)\n",
    "        num_frames_unfolded = frames.shape[1]\n",
    "        expected_num_frames = int(math.ceil((num_samples - self.window_size) / self.hop_size)) + 1\n",
    "        \n",
    "        if num_frames_unfolded < expected_num_frames:\n",
    "            padding_amount = (expected_num_frames - 1) * self.hop_size + self.window_size - num_samples\n",
    "            padded_signal = torch.nn.functional.pad(signal_reshaped, (0, padding_amount))\n",
    "            frames = padded_signal.unfold(1, self.window_size, self.hop_size)\n",
    "        \n",
    "        windowed_frames = frames * self.window\n",
    "        BC, F, W = windowed_frames.shape\n",
    "        windowed_frames_reshaped = windowed_frames.reshape(BC * F, W)\n",
    "        \n",
    "        windowed_frames_complex = windowed_frames_reshaped.to(self.dft_matrix.dtype)\n",
    "        stft_result_reshaped = self.dft_matrix @ windowed_frames_complex.T\n",
    "        stft_result = stft_result_reshaped.T.reshape(batch_size, num_channels, F, self.dft_size)\n",
    "        \n",
    "        # Apply magnitude and normalization\n",
    "        stft_magnitude = torch.abs(stft_result)\n",
    "        \n",
    "        # Reshape for batch norm: (B*C, 1, F, freq_bins)\n",
    "        stft_normalized = stft_magnitude.reshape(batch_size * num_channels, 1, F, self.dft_size)\n",
    "        stft_normalized = self.batch_norm(stft_normalized)\n",
    "        stft_normalized = self.dropout(stft_normalized)\n",
    "        stft_normalized = stft_normalized.reshape(batch_size, num_channels, F, self.dft_size)\n",
    "        \n",
    "        return stft_normalized\n",
    "\n",
    "\n",
    "class Attention4D(nn.Module):\n",
    "    def __init__(self, in_channels, time_frames, freq_bins, d_model=128, n_heads=4, \n",
    "                 d_ff=256, dropout=0.2, num_layers=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.time_frames = time_frames\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        in_features = in_channels * freq_bins\n",
    "        \n",
    "        # Project input to d_model with layer norm\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(in_features, d_model),\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # Learnable positional encoding with smaller init\n",
    "        self.positional_encoding = nn.Parameter(\n",
    "            torch.randn(1, time_frames, d_model) * 0.02\n",
    "        )\n",
    "        \n",
    "        # Stack multiple transformer layers for better representation\n",
    "        self.transformer_layers = nn.ModuleList([\n",
    "            TransformerBlock(d_model, n_heads, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.final_norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Reshape: (B, C, T, F) -> (B, T, C*F)\n",
    "        x = x.permute(0, 2, 1, 3)\n",
    "        x = x.reshape(batch_size, self.time_frames, -1)\n",
    "        \n",
    "        # Project and add positional encoding\n",
    "        x = self.projection(x)\n",
    "        x = x + self.positional_encoding\n",
    "        \n",
    "        # Store attention weights from all layers\n",
    "        all_attention_weights = []\n",
    "        \n",
    "        # Pass through transformer layers\n",
    "        for layer in self.transformer_layers:\n",
    "            x, attn_weights = layer(x)\n",
    "            all_attention_weights.append(attn_weights)\n",
    "        \n",
    "        x = self.final_norm(x)\n",
    "        \n",
    "        return x, all_attention_weights\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=d_model, \n",
    "            num_heads=n_heads, \n",
    "            dropout=dropout, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.GELU(),  # GELU often works better than ReLU\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Pre-norm architecture (more stable)\n",
    "        x_norm = self.layernorm1(x)\n",
    "        attn_output, attn_weights = self.attention(x_norm, x_norm, x_norm, \n",
    "                                                    need_weights=True, \n",
    "                                                    average_attn_weights=True)\n",
    "        x = x + self.dropout1(attn_output)\n",
    "        \n",
    "        x_norm = self.layernorm2(x)\n",
    "        ff_output = self.feed_forward(x_norm)\n",
    "        x = x + self.dropout2(ff_output)\n",
    "        \n",
    "        return x, attn_weights\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_features, num_classes, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # Add intermediate layer for better capacity\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features // 2),\n",
    "            nn.LayerNorm(in_features // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_features // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # (B, d_model, T)\n",
    "        x = self.pooling(x).squeeze(2)  # (B, d_model)\n",
    "        output = self.classifier(x)  # (B, num_classes)\n",
    "        return output\n",
    "\n",
    "\n",
    "class EEGClassifier(nn.Module):\n",
    "    def __init__(self, num_samples, num_classes=4, window_percent=0.25, \n",
    "                 overlap_percent=0.10, d_model=128, n_heads=8, \n",
    "                 transformer_layers=1, dropout=0.2, learnable_window=True):\n",
    "\n",
    "        super(EEGClassifier, self).__init__()\n",
    "        \n",
    "        window_size = int(num_samples * window_percent)\n",
    "        hop_size = int(num_samples * overlap_percent)\n",
    "        \n",
    "        self.window_size = max(window_size, 40)\n",
    "        self.hop_size = max(hop_size, 20)\n",
    "        \n",
    "        self.channel_attn = ChannelAttention(num_channels=64, dropout=dropout)\n",
    "        \n",
    "        self.learnable_stft = LearnableSTFT(\n",
    "            window_size=self.window_size,\n",
    "            hop_size=self.hop_size,\n",
    "            learnable_window=learnable_window,\n",
    "            dropout=dropout * 0.5\n",
    "        )\n",
    "        \n",
    "        time_frames = int(math.ceil((num_samples - self.window_size) / self.hop_size)) + 1\n",
    "        \n",
    "        self.attention_module = Attention4D(\n",
    "            in_channels=64,\n",
    "            time_frames=time_frames,\n",
    "            freq_bins=self.window_size,\n",
    "            d_model=d_model,\n",
    "            n_heads=n_heads,\n",
    "            num_layers=transformer_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.classifier = Classifier(\n",
    "            in_features=d_model, \n",
    "            num_classes=num_classes,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, x, return_attention=False):\n",
    "\n",
    "        # Channel attention\n",
    "        x, channel_attn_scores = self.channel_attn(x)\n",
    "        \n",
    "        # STFT\n",
    "        x = self.learnable_stft(x)\n",
    "        \n",
    "        # Transformer attention\n",
    "        x, transformer_attn_weights = self.attention_module(x)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(x)\n",
    "        \n",
    "        if return_attention:\n",
    "            attention_dict = {\n",
    "                'channel_attention': channel_attn_scores,  # (B, 22)\n",
    "                'transformer_attention': transformer_attn_weights,  # List of (B, T, T) for each layer\n",
    "            }\n",
    "            return logits, attention_dict\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "class AttentionRegularizedLoss(nn.Module):\n",
    "    def __init__(self, num_classes, alpha=0.01, beta=0.01):\n",
    "        super().__init__()\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.alpha = alpha  # Channel attention regularization weight\n",
    "        self.beta = beta    # Transformer attention regularization weight\n",
    "        \n",
    "    def forward(self, logits, targets, attention_dict):\n",
    "        ce = self.ce_loss(logits, targets)\n",
    "        channel_attn = attention_dict['channel_attention']  # (B, C)\n",
    "        channel_attn_norm = channel_attn + 1e-8\n",
    "        channel_attn_norm = channel_attn_norm / channel_attn_norm.sum(dim=1, keepdim=True)\n",
    "        channel_entropy = -(channel_attn_norm * torch.log(channel_attn_norm)).sum(dim=1).mean()\n",
    "        channel_reg = -self.alpha * channel_entropy  # Negative because we want to maximize entropy\n",
    "        transformer_attn = attention_dict['transformer_attention'][-1]  # (B, T, T)\n",
    "        attn_norm = transformer_attn + 1e-8\n",
    "        attn_norm = attn_norm / attn_norm.sum(dim=-1, keepdim=True)\n",
    "        attn_entropy = -(attn_norm * torch.log(attn_norm)).sum(dim=-1).mean()\n",
    "        transformer_reg = -self.beta * attn_entropy  # Maximize entropy\n",
    "\n",
    "        total_loss = ce + channel_reg + transformer_reg\n",
    "        \n",
    "        return total_loss, {\n",
    "            'ce_loss': ce.item(),\n",
    "            'channel_reg': channel_reg.item(),\n",
    "            'transformer_reg': transformer_reg.item(),\n",
    "            'total_loss': total_loss.item()\n",
    "        }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f850fe",
   "metadata": {},
   "source": [
    "# test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "484720f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     # Model initialization\n",
    "#     model = EEGClassifier(\n",
    "#         num_samples=1000,\n",
    "#         num_classes=4,\n",
    "#         d_model=64,  # Reduced from 128\n",
    "#         n_heads=4,   # Reduced from 8\n",
    "#         transformer_layers=2,\n",
    "#         dropout=0.3,\n",
    "#         learnable_window=False  # Start with fixed window\n",
    "#     )\n",
    "    \n",
    "#     # Loss function\n",
    "#     criterion = AttentionRegularizedLoss(num_classes=4, alpha=0.01, beta=0.01)\n",
    "    \n",
    "#     # Dummy data\n",
    "#     x = torch.randn(4, 22, 1000)  # (batch, channels, time)\n",
    "#     y = torch.randint(0, 4, (4,))\n",
    "    \n",
    "#     # Forward pass with attention\n",
    "#     logits, attention_dict = model(x, return_attention=True)\n",
    "    \n",
    "#     # Calculate loss\n",
    "#     loss, loss_dict = criterion(logits, y, attention_dict)\n",
    "    \n",
    "#     print(f\"Logits shape: {logits.shape}\")\n",
    "#     print(f\"Channel attention shape: {attention_dict['channel_attention'].shape}\")\n",
    "#     print(f\"Num transformer layers: {len(attention_dict['transformer_attention'])}\")\n",
    "#     print(f\"Transformer attention shape: {attention_dict['transformer_attention'][0].shape}\")\n",
    "#     print(f\"Total loss: {loss.item():.4f}\")\n",
    "#     print(f\"Loss components: {loss_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313f023b",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c483a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 03:53:07.478214: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-30 03:53:07.792906: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-30 03:53:07.792971: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-30 03:53:07.795076: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-30 03:53:07.993711: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-30 03:53:09.482697: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import json\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "class EEGTrainer:\n",
    "    def __init__(self, model, train_loader, val_loader ,class_weights=None,test_loader=None, config=None):\n",
    "\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        \n",
    "        # Set device\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.class_weights = class_weights\n",
    "        # Default configuration\n",
    "        self.config = {\n",
    "            'lr': 1e-3,\n",
    "            'weight_decay': 1e-4,\n",
    "            'patience': 10,\n",
    "            'min_lr': 1e-6,\n",
    "            'epochs': 100,\n",
    "            'save_dir': 'experiments',\n",
    "            'experiment_name': f'exp_{time.strftime(\"%Y%m%d-%H%M%S\")}',\n",
    "            'save_attention_maps': True,\n",
    "            'attention_map_freq': 5\n",
    "        }\n",
    "        \n",
    "        # Update with user config if provided\n",
    "        if config:\n",
    "            self.config.update(config)\n",
    "            \n",
    "        # Create experiment directory\n",
    "        self.exp_dir = os.path.join(self.config['save_dir'], self.config['experiment_name'])\n",
    "        os.makedirs(self.exp_dir, exist_ok=True)\n",
    "        \n",
    "        # Initialize components\n",
    "        self._init_components()\n",
    "        \n",
    "        # Save config\n",
    "        self._save_config()\n",
    "        \n",
    "    def _init_components(self):\n",
    "        \"\"\"Initialize training components\"\"\"\n",
    "        # Loss function (CrossEntropy + KLDiv for attention regularization)\n",
    "        #self.criterion = nn.CrossEntropyLoss()#weight=self.class_weights)\n",
    "        self.criterion = AttentionRegularizedLoss(num_classes=10)\n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=self.config['lr'],\n",
    "            weight_decay=self.config['weight_decay']\n",
    "        )\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        self.scheduler = ReduceLROnPlateau(\n",
    "            self.optimizer,\n",
    "            mode='max',\n",
    "            factor=0.5,\n",
    "            patience=self.config['patience']//2,\n",
    "            min_lr=self.config['min_lr'],\n",
    "            #verbose=True\n",
    "        )\n",
    "        \n",
    "        self.best_val_acc = 0.0\n",
    "        self.early_stop_counter = 0\n",
    "        \n",
    "        # Tensorboard writer\n",
    "        self.writer = SummaryWriter(log_dir=self.exp_dir)\n",
    "        \n",
    "        # Attention maps directory\n",
    "        if self.config['save_attention_maps']:\n",
    "            self.attention_dir = os.path.join(self.exp_dir, 'attention_maps')\n",
    "            os.makedirs(self.attention_dir, exist_ok=True)\n",
    "    \n",
    "    def _save_config(self):\n",
    "        config_path = os.path.join(self.exp_dir, 'config.json')\n",
    "        with open(config_path, 'w') as f:\n",
    "            json.dump(self.config, f, indent=4)\n",
    "    \n",
    "    def _compute_metrics(self, outputs, labels):\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        accuracy = correct / labels.size(0)\n",
    "        return accuracy\n",
    "    \n",
    "    def _log_metrics(self, phase, metrics, epoch):\n",
    "        loss = metrics['loss']\n",
    "        acc = metrics['accuracy']\n",
    "        pre = metrics['precision']\n",
    "        rec = metrics['recall']\n",
    "        f1 = metrics['f1']\n",
    "        \n",
    "        # Console logging\n",
    "        print(f\"{phase.capitalize()} - Epoch: {epoch+1} | \"\n",
    "              f\"Loss: {loss:.4f} | Acc: {acc:.2%} | Precision: {pre:.2%} | recall: {rec:.2%} | f1: {f1:.2%}\")\n",
    "        \n",
    "        # Tensorboard logging\n",
    "        self.writer.add_scalar(f'Loss/{phase}', loss, epoch)\n",
    "        self.writer.add_scalar(f'Accuracy/{phase}', acc, epoch)\n",
    "        \n",
    "        \n",
    "        # Log learning rate\n",
    "        if phase == 'train':\n",
    "            lr = self.optimizer.param_groups[0]['lr']\n",
    "            self.writer.add_scalar('LR', lr, epoch)\n",
    "    \n",
    "    def _save_checkpoint(self, epoch, is_best=False):\n",
    "        \"\"\"Save model checkpoint\"\"\"\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'state_dict': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "            'scheduler': self.scheduler.state_dict(),\n",
    "            'best_val_acc': self.best_val_acc\n",
    "        }\n",
    "        \n",
    "        # Save regular checkpoint\n",
    "        checkpoint_path = os.path.join(self.exp_dir, f'checkpoint_epoch_{epoch}.pth')\n",
    "        torch.save(state, checkpoint_path)\n",
    "        \n",
    "        # Save best model\n",
    "        if is_best:\n",
    "            best_path = os.path.join(self.exp_dir, 'best_model.pth')\n",
    "            torch.save(state, best_path)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Store all predictions and labels for epoch-wise metrics\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for inputs, labels in self.train_loader:\n",
    "            inputs = inputs.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "\n",
    "            # Zero gradients\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs, attention_dict = self.model(inputs, return_attention=True)\n",
    "            loss ,_ = self.criterion(outputs, labels,attention_dict)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # ----- accumulate loss -----\n",
    "            batch_size = inputs.size(0)\n",
    "            running_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "            # ----- accumulate preds + labels for metrics -----\n",
    "            preds = torch.argmax(outputs, dim=1)          # [B]\n",
    "            all_preds.append(preds.detach().cpu())\n",
    "            all_labels.append(labels.detach().cpu())\n",
    "\n",
    "        # ---- end of epoch: stack everything and compute metrics ----\n",
    "        all_preds = torch.cat(all_preds).numpy()\n",
    "        all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "        epoch_loss = running_loss / total_samples\n",
    "\n",
    "        # accuracy\n",
    "        epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "        # precision, recall, f1\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_labels,\n",
    "            all_preds,\n",
    "            average='weighted',      # change to 'macro' / 'binary' if needed\n",
    "            zero_division=0          # avoid NaN if a class is missing in preds\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'loss': epoch_loss,\n",
    "            'accuracy': epoch_acc,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "        }\n",
    "\n",
    "\n",
    "    \n",
    "    def validate_epoch(self, epoch):\n",
    "        \"\"\"Validate for one epoch\"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.val_loader:\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "     \n",
    "                # Forward pass\n",
    "                #outputs = self.model(inputs)\n",
    "                outputs, attention_dict = self.model(inputs, return_attention=True)\n",
    "                loss, _ = self.criterion(outputs, labels, attention_dict)\n",
    "                #loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                batch_size = inputs.size(0)\n",
    "                running_loss += loss.item() * batch_size\n",
    "                total_samples += batch_size\n",
    "\n",
    "                # ----- accumulate preds + labels for metrics -----\n",
    "                preds = torch.argmax(outputs, dim=1)          # [B]\n",
    "                all_preds.append(preds.detach().cpu())\n",
    "                all_labels.append(labels.detach().cpu())\n",
    "\n",
    "            # ---- end of epoch: stack everything and compute metrics ----\n",
    "            all_preds = torch.cat(all_preds).numpy()\n",
    "            all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "            epoch_loss = running_loss / total_samples\n",
    "\n",
    "            # accuracy\n",
    "            epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "            # precision, recall, f1\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                all_labels,\n",
    "                all_preds,\n",
    "                average='weighted',      # change to 'macro' / 'binary' if needed\n",
    "                zero_division=0          # avoid NaN if a class is missing in preds\n",
    "            )\n",
    "\n",
    "            return {\n",
    "                'loss': epoch_loss,\n",
    "                'accuracy': epoch_acc,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1': f1,\n",
    "            }\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Main training loop\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(self.config['epochs']):\n",
    "            # Train and validate\n",
    "            train_metrics = self.train_epoch(epoch)\n",
    "            val_metrics = self.validate_epoch(epoch)\n",
    "            \n",
    "            # Log metrics\n",
    "            self._log_metrics('train', train_metrics, epoch)\n",
    "            self._log_metrics('val', val_metrics, epoch)\n",
    "            \n",
    "            # Save attention maps periodically\n",
    "            \n",
    "            # Step scheduler\n",
    "            self.scheduler.step(val_metrics['accuracy'])\n",
    "            \n",
    "            # Check for best model\n",
    "            if val_metrics['accuracy'] > self.best_val_acc:\n",
    "                self.best_val_acc = val_metrics['accuracy']\n",
    "                self._save_checkpoint(epoch, is_best=True)\n",
    "                self.early_stop_counter = 0\n",
    "            else:\n",
    "                self.early_stop_counter += 1\n",
    "            \n",
    "            # Save checkpoint periodically\n",
    "            if epoch % 10 == 0:\n",
    "                self._save_checkpoint(epoch)\n",
    "            \n",
    "            # Early stopping\n",
    "            # if self.early_stop_counter >= self.config['patience']:\n",
    "            #     print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            #     break\n",
    "        \n",
    "        # Training complete\n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"Training completed in {training_time//60:.0f}m {training_time%60:.0f}s\")\n",
    "        print(f\"Best validation accuracy: {self.best_val_acc:.2%}\")\n",
    "        \n",
    "        # Test if test loader provided\n",
    "        if self.test_loader:\n",
    "            test_acc = self.test()\n",
    "            print(f\"Test accuracy: {test_acc:.2%}\")\n",
    "        \n",
    "        # Close tensorboard writer\n",
    "        self.writer.close()\n",
    "        \n",
    "        return self.best_val_acc\n",
    "    \n",
    "    def test(self):\n",
    "        \"\"\"Evaluate on test set\"\"\"\n",
    "        self.model.eval()\n",
    "        running_acc = 0.0\n",
    "        total_samples = 0\n",
    "        \n",
    "        # Load best model\n",
    "        best_path = os.path.join(self.exp_dir, 'best_model.pth')\n",
    "        if os.path.exists(best_path):\n",
    "            checkpoint = torch.load(best_path)\n",
    "            self.model.load_state_dict(checkpoint['state_dict'])\n",
    "            print(f\"Loaded best model from epoch {checkpoint['epoch']}\")\n",
    "        \n",
    "        all_preds=[]\n",
    "        all_labels=[]\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.test_loader:\n",
    "                inputs = inputs.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                batch_size = inputs.size(0)\n",
    "                total_samples += batch_size\n",
    "\n",
    "                # ----- accumulate preds + labels for metrics -----\n",
    "                preds = torch.argmax(outputs, dim=1)          # [B]\n",
    "                all_preds.append(preds.detach().cpu())\n",
    "                all_labels.append(labels.detach().cpu())\n",
    "\n",
    "            # ---- end of epoch: stack everything and compute metrics ----\n",
    "            all_preds = torch.cat(all_preds).numpy()\n",
    "            all_labels = torch.cat(all_labels).numpy()\n",
    "\n",
    "            epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "            # precision, recall, f1\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                all_labels,\n",
    "                all_preds,\n",
    "                average='binary',      # change to 'macro' / 'binary' if needed\n",
    "                zero_division=0          # avoid NaN if a class is missing in preds\n",
    "            )\n",
    "        \n",
    "        test_acc = epoch_acc\n",
    "        self.writer.add_scalar('Accuracy/test', test_acc)\n",
    "        print(\"acc: \",test_acc)\n",
    "        print(\"precision:\", precision)\n",
    "        print(\"recall:\", recall)\n",
    "        print(\"F1 :\", f1)\n",
    "        return epoch_acc\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef686541",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf259697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: [342 417 345 333 363 312 321 414 306 345]\n",
      "Class ratio: 11.92%\n",
      "Train+Val dataset size: 3498\n",
      "Train batches: 88\n",
      "Val batches: 22\n",
      "Single Trial Shape: (64, 400)\n",
      "Train - Epoch: 1 | Loss: 2.2678 | Acc: 11.01% | Precision: 10.60% | recall: 11.01% | f1: 8.96%\n",
      "Val - Epoch: 1 | Loss: 2.2404 | Acc: 12.00% | Precision: 4.42% | recall: 12.00% | f1: 3.06%\n",
      "Train - Epoch: 2 | Loss: 2.2447 | Acc: 11.72% | Precision: 10.62% | recall: 11.72% | f1: 9.18%\n",
      "Val - Epoch: 2 | Loss: 2.2345 | Acc: 13.29% | Precision: 4.60% | recall: 13.29% | f1: 6.13%\n",
      "Train - Epoch: 3 | Loss: 2.2405 | Acc: 11.65% | Precision: 9.92% | recall: 11.65% | f1: 8.76%\n",
      "Val - Epoch: 3 | Loss: 2.2334 | Acc: 12.29% | Precision: 3.98% | recall: 12.29% | f1: 5.92%\n",
      "Train - Epoch: 4 | Loss: 2.2409 | Acc: 11.40% | Precision: 11.50% | recall: 11.40% | f1: 9.06%\n",
      "Val - Epoch: 4 | Loss: 2.2353 | Acc: 12.14% | Precision: 3.00% | recall: 12.14% | f1: 3.85%\n",
      "Train - Epoch: 5 | Loss: 2.2438 | Acc: 12.51% | Precision: 11.64% | recall: 12.51% | f1: 8.97%\n",
      "Val - Epoch: 5 | Loss: 2.2324 | Acc: 12.00% | Precision: 6.20% | recall: 12.00% | f1: 2.80%\n",
      "Train - Epoch: 6 | Loss: 2.2380 | Acc: 13.05% | Precision: 11.04% | recall: 13.05% | f1: 9.34%\n",
      "Val - Epoch: 6 | Loss: 2.2284 | Acc: 12.71% | Precision: 13.36% | recall: 12.71% | f1: 5.92%\n",
      "Train - Epoch: 7 | Loss: 2.2293 | Acc: 12.94% | Precision: 13.40% | recall: 12.94% | f1: 11.38%\n",
      "Val - Epoch: 7 | Loss: 2.2264 | Acc: 11.86% | Precision: 12.19% | recall: 11.86% | f1: 4.15%\n",
      "Train - Epoch: 8 | Loss: 2.2329 | Acc: 12.90% | Precision: 12.70% | recall: 12.90% | f1: 9.66%\n",
      "Val - Epoch: 8 | Loss: 2.2243 | Acc: 12.29% | Precision: 13.19% | recall: 12.29% | f1: 3.35%\n",
      "Train - Epoch: 9 | Loss: 2.2278 | Acc: 13.01% | Precision: 12.41% | recall: 13.01% | f1: 10.55%\n",
      "Val - Epoch: 9 | Loss: 2.2240 | Acc: 12.43% | Precision: 7.09% | recall: 12.43% | f1: 5.25%\n",
      "Train - Epoch: 10 | Loss: 2.2189 | Acc: 14.08% | Precision: 13.59% | recall: 14.08% | f1: 11.55%\n",
      "Val - Epoch: 10 | Loss: 2.2143 | Acc: 14.43% | Precision: 25.12% | recall: 14.43% | f1: 7.49%\n",
      "Train - Epoch: 11 | Loss: 2.2153 | Acc: 14.12% | Precision: 13.58% | recall: 14.12% | f1: 12.30%\n",
      "Val - Epoch: 11 | Loss: 2.2120 | Acc: 14.00% | Precision: 19.13% | recall: 14.00% | f1: 8.90%\n",
      "Train - Epoch: 12 | Loss: 2.2009 | Acc: 15.44% | Precision: 15.49% | recall: 15.44% | f1: 14.18%\n",
      "Val - Epoch: 12 | Loss: 2.2048 | Acc: 16.00% | Precision: 23.33% | recall: 16.00% | f1: 10.17%\n",
      "Train - Epoch: 13 | Loss: 2.2058 | Acc: 14.97% | Precision: 15.38% | recall: 14.97% | f1: 13.02%\n",
      "Val - Epoch: 13 | Loss: 2.2036 | Acc: 14.57% | Precision: 10.38% | recall: 14.57% | f1: 8.71%\n",
      "Train - Epoch: 14 | Loss: 2.1903 | Acc: 16.48% | Precision: 16.77% | recall: 16.48% | f1: 15.45%\n",
      "Val - Epoch: 14 | Loss: 2.2035 | Acc: 15.29% | Precision: 11.32% | recall: 15.29% | f1: 8.17%\n",
      "Train - Epoch: 15 | Loss: 2.1936 | Acc: 16.08% | Precision: 16.29% | recall: 16.08% | f1: 14.94%\n",
      "Val - Epoch: 15 | Loss: 2.2089 | Acc: 14.29% | Precision: 8.77% | recall: 14.29% | f1: 9.29%\n",
      "Train - Epoch: 16 | Loss: 2.1741 | Acc: 17.30% | Precision: 17.13% | recall: 17.30% | f1: 16.39%\n",
      "Val - Epoch: 16 | Loss: 2.1931 | Acc: 18.29% | Precision: 19.66% | recall: 18.29% | f1: 14.10%\n",
      "Train - Epoch: 17 | Loss: 2.1700 | Acc: 18.55% | Precision: 18.59% | recall: 18.55% | f1: 17.98%\n",
      "Val - Epoch: 17 | Loss: 2.2032 | Acc: 17.86% | Precision: 22.46% | recall: 17.86% | f1: 11.64%\n",
      "Train - Epoch: 18 | Loss: 2.1589 | Acc: 18.08% | Precision: 18.11% | recall: 18.08% | f1: 17.28%\n",
      "Val - Epoch: 18 | Loss: 2.1768 | Acc: 20.00% | Precision: 21.95% | recall: 20.00% | f1: 18.07%\n",
      "Train - Epoch: 19 | Loss: 2.1410 | Acc: 20.05% | Precision: 20.16% | recall: 20.05% | f1: 19.57%\n",
      "Val - Epoch: 19 | Loss: 2.1585 | Acc: 19.14% | Precision: 22.76% | recall: 19.14% | f1: 15.87%\n",
      "Train - Epoch: 20 | Loss: 2.1362 | Acc: 20.09% | Precision: 20.12% | recall: 20.09% | f1: 19.51%\n",
      "Val - Epoch: 20 | Loss: 2.1586 | Acc: 16.86% | Precision: 22.41% | recall: 16.86% | f1: 15.99%\n",
      "Train - Epoch: 21 | Loss: 2.1346 | Acc: 19.76% | Precision: 19.79% | recall: 19.76% | f1: 18.99%\n",
      "Val - Epoch: 21 | Loss: 2.1445 | Acc: 17.00% | Precision: 22.08% | recall: 17.00% | f1: 15.98%\n",
      "Train - Epoch: 22 | Loss: 2.1126 | Acc: 20.94% | Precision: 20.74% | recall: 20.94% | f1: 19.92%\n",
      "Val - Epoch: 22 | Loss: 2.1510 | Acc: 19.71% | Precision: 22.56% | recall: 19.71% | f1: 17.61%\n",
      "Train - Epoch: 23 | Loss: 2.1038 | Acc: 21.09% | Precision: 21.22% | recall: 21.09% | f1: 20.79%\n",
      "Val - Epoch: 23 | Loss: 2.1466 | Acc: 20.29% | Precision: 21.82% | recall: 20.29% | f1: 17.34%\n",
      "Train - Epoch: 24 | Loss: 2.0872 | Acc: 23.27% | Precision: 23.28% | recall: 23.27% | f1: 22.70%\n",
      "Val - Epoch: 24 | Loss: 2.1489 | Acc: 15.86% | Precision: 23.98% | recall: 15.86% | f1: 12.50%\n",
      "Train - Epoch: 25 | Loss: 2.0807 | Acc: 23.16% | Precision: 22.82% | recall: 23.16% | f1: 22.58%\n",
      "Val - Epoch: 25 | Loss: 2.1433 | Acc: 19.14% | Precision: 23.73% | recall: 19.14% | f1: 15.44%\n",
      "Train - Epoch: 26 | Loss: 2.0582 | Acc: 24.62% | Precision: 25.35% | recall: 24.62% | f1: 24.34%\n",
      "Val - Epoch: 26 | Loss: 2.0859 | Acc: 24.43% | Precision: 27.13% | recall: 24.43% | f1: 23.51%\n",
      "Train - Epoch: 27 | Loss: 2.0467 | Acc: 24.45% | Precision: 24.45% | recall: 24.45% | f1: 24.12%\n",
      "Val - Epoch: 27 | Loss: 2.0817 | Acc: 23.00% | Precision: 28.91% | recall: 23.00% | f1: 21.91%\n",
      "Train - Epoch: 28 | Loss: 2.0332 | Acc: 26.41% | Precision: 26.36% | recall: 26.41% | f1: 25.90%\n",
      "Val - Epoch: 28 | Loss: 2.0625 | Acc: 24.86% | Precision: 24.88% | recall: 24.86% | f1: 23.45%\n",
      "Train - Epoch: 29 | Loss: 2.0175 | Acc: 25.98% | Precision: 26.46% | recall: 25.98% | f1: 25.30%\n",
      "Val - Epoch: 29 | Loss: 2.0558 | Acc: 27.71% | Precision: 32.18% | recall: 27.71% | f1: 25.91%\n",
      "Train - Epoch: 30 | Loss: 2.0101 | Acc: 28.06% | Precision: 28.24% | recall: 28.06% | f1: 27.78%\n",
      "Val - Epoch: 30 | Loss: 2.0637 | Acc: 21.71% | Precision: 33.69% | recall: 21.71% | f1: 19.44%\n",
      "Train - Epoch: 31 | Loss: 1.9916 | Acc: 29.20% | Precision: 29.24% | recall: 29.20% | f1: 28.65%\n",
      "Val - Epoch: 31 | Loss: 2.0585 | Acc: 26.29% | Precision: 33.77% | recall: 26.29% | f1: 22.69%\n",
      "Train - Epoch: 32 | Loss: 1.9628 | Acc: 30.88% | Precision: 31.04% | recall: 30.88% | f1: 30.53%\n",
      "Val - Epoch: 32 | Loss: 2.0062 | Acc: 26.29% | Precision: 31.40% | recall: 26.29% | f1: 24.54%\n",
      "Train - Epoch: 33 | Loss: 1.9424 | Acc: 32.06% | Precision: 32.37% | recall: 32.06% | f1: 31.57%\n",
      "Val - Epoch: 33 | Loss: 1.9982 | Acc: 28.57% | Precision: 31.21% | recall: 28.57% | f1: 27.33%\n",
      "Train - Epoch: 34 | Loss: 1.9462 | Acc: 31.31% | Precision: 31.59% | recall: 31.31% | f1: 30.75%\n",
      "Val - Epoch: 34 | Loss: 2.0164 | Acc: 26.14% | Precision: 28.14% | recall: 26.14% | f1: 23.72%\n",
      "Train - Epoch: 35 | Loss: 1.9268 | Acc: 31.42% | Precision: 31.81% | recall: 31.42% | f1: 30.85%\n",
      "Val - Epoch: 35 | Loss: 2.0074 | Acc: 27.57% | Precision: 39.04% | recall: 27.57% | f1: 24.72%\n",
      "Train - Epoch: 36 | Loss: 1.9135 | Acc: 31.09% | Precision: 31.48% | recall: 31.09% | f1: 30.67%\n",
      "Val - Epoch: 36 | Loss: 1.9880 | Acc: 28.57% | Precision: 42.76% | recall: 28.57% | f1: 25.85%\n",
      "Train - Epoch: 37 | Loss: 1.8974 | Acc: 34.27% | Precision: 34.62% | recall: 34.27% | f1: 33.93%\n",
      "Val - Epoch: 37 | Loss: 1.9646 | Acc: 29.86% | Precision: 32.23% | recall: 29.86% | f1: 27.64%\n",
      "Train - Epoch: 38 | Loss: 1.8630 | Acc: 36.13% | Precision: 36.35% | recall: 36.13% | f1: 35.70%\n",
      "Val - Epoch: 38 | Loss: 1.9347 | Acc: 32.00% | Precision: 35.90% | recall: 32.00% | f1: 30.52%\n",
      "Train - Epoch: 39 | Loss: 1.8514 | Acc: 35.67% | Precision: 35.92% | recall: 35.67% | f1: 35.12%\n",
      "Val - Epoch: 39 | Loss: 1.9213 | Acc: 31.14% | Precision: 36.45% | recall: 31.14% | f1: 29.46%\n",
      "Train - Epoch: 40 | Loss: 1.8356 | Acc: 36.81% | Precision: 37.43% | recall: 36.81% | f1: 36.26%\n",
      "Val - Epoch: 40 | Loss: 1.9150 | Acc: 32.71% | Precision: 39.78% | recall: 32.71% | f1: 31.51%\n",
      "Train - Epoch: 41 | Loss: 1.8267 | Acc: 36.81% | Precision: 37.04% | recall: 36.81% | f1: 36.27%\n",
      "Val - Epoch: 41 | Loss: 1.8808 | Acc: 34.71% | Precision: 35.91% | recall: 34.71% | f1: 33.87%\n",
      "Train - Epoch: 42 | Loss: 1.7849 | Acc: 39.71% | Precision: 39.60% | recall: 39.71% | f1: 39.20%\n",
      "Val - Epoch: 42 | Loss: 1.8464 | Acc: 35.57% | Precision: 36.80% | recall: 35.57% | f1: 34.20%\n",
      "Train - Epoch: 43 | Loss: 1.7735 | Acc: 40.53% | Precision: 40.65% | recall: 40.53% | f1: 40.14%\n",
      "Val - Epoch: 43 | Loss: 1.8732 | Acc: 34.43% | Precision: 39.94% | recall: 34.43% | f1: 32.70%\n",
      "Train - Epoch: 44 | Loss: 1.7674 | Acc: 40.17% | Precision: 40.11% | recall: 40.17% | f1: 39.72%\n",
      "Val - Epoch: 44 | Loss: 1.8868 | Acc: 34.14% | Precision: 38.27% | recall: 34.14% | f1: 32.12%\n",
      "Train - Epoch: 45 | Loss: 1.7505 | Acc: 42.32% | Precision: 42.57% | recall: 42.32% | f1: 41.78%\n",
      "Val - Epoch: 45 | Loss: 1.8330 | Acc: 39.14% | Precision: 41.51% | recall: 39.14% | f1: 38.09%\n",
      "Train - Epoch: 46 | Loss: 1.7142 | Acc: 44.42% | Precision: 44.66% | recall: 44.42% | f1: 43.91%\n",
      "Val - Epoch: 46 | Loss: 1.8530 | Acc: 35.29% | Precision: 40.62% | recall: 35.29% | f1: 33.96%\n",
      "Train - Epoch: 47 | Loss: 1.7141 | Acc: 42.67% | Precision: 42.81% | recall: 42.67% | f1: 42.02%\n",
      "Val - Epoch: 47 | Loss: 1.8136 | Acc: 37.29% | Precision: 42.86% | recall: 37.29% | f1: 35.41%\n",
      "Train - Epoch: 48 | Loss: 1.6880 | Acc: 45.07% | Precision: 45.42% | recall: 45.07% | f1: 44.68%\n",
      "Val - Epoch: 48 | Loss: 1.8368 | Acc: 37.00% | Precision: 45.37% | recall: 37.00% | f1: 34.71%\n",
      "Train - Epoch: 49 | Loss: 1.6776 | Acc: 43.82% | Precision: 44.34% | recall: 43.82% | f1: 43.21%\n",
      "Val - Epoch: 49 | Loss: 1.8619 | Acc: 33.86% | Precision: 44.02% | recall: 33.86% | f1: 31.81%\n",
      "Train - Epoch: 50 | Loss: 1.6749 | Acc: 45.00% | Precision: 45.45% | recall: 45.00% | f1: 44.44%\n",
      "Val - Epoch: 50 | Loss: 1.7799 | Acc: 38.00% | Precision: 42.85% | recall: 38.00% | f1: 36.03%\n",
      "Train - Epoch: 51 | Loss: 1.6548 | Acc: 45.57% | Precision: 45.84% | recall: 45.57% | f1: 45.01%\n",
      "Val - Epoch: 51 | Loss: 1.7376 | Acc: 43.29% | Precision: 44.30% | recall: 43.29% | f1: 42.34%\n",
      "Train - Epoch: 52 | Loss: 1.6328 | Acc: 46.93% | Precision: 47.54% | recall: 46.93% | f1: 46.63%\n",
      "Val - Epoch: 52 | Loss: 1.7424 | Acc: 41.29% | Precision: 44.90% | recall: 41.29% | f1: 39.37%\n",
      "Train - Epoch: 53 | Loss: 1.6156 | Acc: 48.00% | Precision: 48.12% | recall: 48.00% | f1: 47.56%\n",
      "Val - Epoch: 53 | Loss: 1.7146 | Acc: 42.29% | Precision: 45.74% | recall: 42.29% | f1: 40.75%\n",
      "Train - Epoch: 54 | Loss: 1.5850 | Acc: 49.64% | Precision: 50.18% | recall: 49.64% | f1: 49.22%\n",
      "Val - Epoch: 54 | Loss: 1.7171 | Acc: 42.86% | Precision: 46.81% | recall: 42.86% | f1: 41.49%\n",
      "Train - Epoch: 55 | Loss: 1.5890 | Acc: 49.00% | Precision: 49.83% | recall: 49.00% | f1: 48.58%\n",
      "Val - Epoch: 55 | Loss: 1.7355 | Acc: 40.29% | Precision: 46.60% | recall: 40.29% | f1: 38.58%\n",
      "Train - Epoch: 56 | Loss: 1.5469 | Acc: 50.79% | Precision: 51.17% | recall: 50.79% | f1: 50.50%\n",
      "Val - Epoch: 56 | Loss: 1.7250 | Acc: 42.57% | Precision: 48.41% | recall: 42.57% | f1: 41.15%\n",
      "Train - Epoch: 57 | Loss: 1.5480 | Acc: 50.82% | Precision: 50.97% | recall: 50.82% | f1: 50.44%\n",
      "Val - Epoch: 57 | Loss: 1.6979 | Acc: 43.29% | Precision: 46.01% | recall: 43.29% | f1: 42.65%\n",
      "Train - Epoch: 58 | Loss: 1.5286 | Acc: 50.43% | Precision: 50.62% | recall: 50.43% | f1: 50.05%\n",
      "Val - Epoch: 58 | Loss: 1.7183 | Acc: 40.29% | Precision: 48.07% | recall: 40.29% | f1: 39.20%\n",
      "Train - Epoch: 59 | Loss: 1.5157 | Acc: 52.11% | Precision: 52.57% | recall: 52.11% | f1: 51.74%\n",
      "Val - Epoch: 59 | Loss: 1.6520 | Acc: 45.71% | Precision: 48.65% | recall: 45.71% | f1: 44.90%\n",
      "Train - Epoch: 60 | Loss: 1.4764 | Acc: 54.50% | Precision: 54.47% | recall: 54.50% | f1: 54.15%\n",
      "Val - Epoch: 60 | Loss: 1.6843 | Acc: 41.14% | Precision: 50.99% | recall: 41.14% | f1: 40.02%\n",
      "Train - Epoch: 61 | Loss: 1.4843 | Acc: 53.82% | Precision: 53.91% | recall: 53.82% | f1: 53.34%\n",
      "Val - Epoch: 61 | Loss: 1.6527 | Acc: 45.86% | Precision: 51.50% | recall: 45.86% | f1: 44.94%\n",
      "Train - Epoch: 62 | Loss: 1.4786 | Acc: 53.72% | Precision: 54.29% | recall: 53.72% | f1: 53.44%\n",
      "Val - Epoch: 62 | Loss: 1.6334 | Acc: 43.43% | Precision: 48.87% | recall: 43.43% | f1: 42.18%\n",
      "Train - Epoch: 63 | Loss: 1.4396 | Acc: 56.04% | Precision: 56.66% | recall: 56.04% | f1: 55.81%\n",
      "Val - Epoch: 63 | Loss: 1.7120 | Acc: 37.86% | Precision: 52.60% | recall: 37.86% | f1: 36.02%\n",
      "Train - Epoch: 64 | Loss: 1.4307 | Acc: 54.54% | Precision: 54.71% | recall: 54.54% | f1: 54.28%\n",
      "Val - Epoch: 64 | Loss: 1.5793 | Acc: 46.86% | Precision: 49.01% | recall: 46.86% | f1: 46.39%\n",
      "Train - Epoch: 65 | Loss: 1.4146 | Acc: 56.47% | Precision: 56.88% | recall: 56.47% | f1: 56.25%\n",
      "Val - Epoch: 65 | Loss: 1.6053 | Acc: 45.29% | Precision: 52.67% | recall: 45.29% | f1: 45.03%\n",
      "Train - Epoch: 66 | Loss: 1.4282 | Acc: 55.43% | Precision: 55.53% | recall: 55.43% | f1: 55.16%\n",
      "Val - Epoch: 66 | Loss: 1.5614 | Acc: 49.00% | Precision: 53.97% | recall: 49.00% | f1: 48.41%\n",
      "Train - Epoch: 67 | Loss: 1.4049 | Acc: 55.29% | Precision: 55.72% | recall: 55.29% | f1: 55.05%\n",
      "Val - Epoch: 67 | Loss: 1.5564 | Acc: 50.14% | Precision: 56.17% | recall: 50.14% | f1: 49.89%\n",
      "Train - Epoch: 68 | Loss: 1.3818 | Acc: 57.33% | Precision: 57.38% | recall: 57.33% | f1: 57.08%\n",
      "Val - Epoch: 68 | Loss: 1.5307 | Acc: 49.71% | Precision: 53.42% | recall: 49.71% | f1: 48.85%\n",
      "Train - Epoch: 69 | Loss: 1.3508 | Acc: 59.61% | Precision: 59.49% | recall: 59.61% | f1: 59.31%\n",
      "Val - Epoch: 69 | Loss: 1.4952 | Acc: 52.43% | Precision: 56.35% | recall: 52.43% | f1: 52.26%\n",
      "Train - Epoch: 70 | Loss: 1.3320 | Acc: 59.11% | Precision: 59.26% | recall: 59.11% | f1: 58.87%\n",
      "Val - Epoch: 70 | Loss: 1.5312 | Acc: 51.86% | Precision: 55.81% | recall: 51.86% | f1: 51.24%\n",
      "Train - Epoch: 71 | Loss: 1.3137 | Acc: 61.69% | Precision: 61.85% | recall: 61.69% | f1: 61.49%\n",
      "Val - Epoch: 71 | Loss: 1.4945 | Acc: 51.00% | Precision: 56.44% | recall: 51.00% | f1: 51.06%\n",
      "Train - Epoch: 72 | Loss: 1.3077 | Acc: 60.22% | Precision: 60.37% | recall: 60.22% | f1: 59.99%\n",
      "Val - Epoch: 72 | Loss: 1.4732 | Acc: 53.57% | Precision: 59.43% | recall: 53.57% | f1: 53.63%\n",
      "Train - Epoch: 73 | Loss: 1.2863 | Acc: 61.76% | Precision: 62.01% | recall: 61.76% | f1: 61.61%\n",
      "Val - Epoch: 73 | Loss: 1.4394 | Acc: 53.86% | Precision: 56.05% | recall: 53.86% | f1: 53.59%\n",
      "Train - Epoch: 74 | Loss: 1.2654 | Acc: 61.94% | Precision: 62.31% | recall: 61.94% | f1: 61.83%\n",
      "Val - Epoch: 74 | Loss: 1.4723 | Acc: 51.00% | Precision: 56.96% | recall: 51.00% | f1: 50.29%\n",
      "Train - Epoch: 75 | Loss: 1.2367 | Acc: 62.58% | Precision: 62.76% | recall: 62.58% | f1: 62.41%\n",
      "Val - Epoch: 75 | Loss: 1.4102 | Acc: 56.71% | Precision: 59.15% | recall: 56.71% | f1: 56.59%\n",
      "Train - Epoch: 76 | Loss: 1.2195 | Acc: 64.01% | Precision: 64.02% | recall: 64.01% | f1: 63.84%\n",
      "Val - Epoch: 76 | Loss: 1.4520 | Acc: 51.71% | Precision: 58.16% | recall: 51.71% | f1: 52.25%\n",
      "Train - Epoch: 77 | Loss: 1.2124 | Acc: 64.65% | Precision: 64.92% | recall: 64.65% | f1: 64.50%\n",
      "Val - Epoch: 77 | Loss: 1.4222 | Acc: 51.86% | Precision: 59.55% | recall: 51.86% | f1: 52.02%\n",
      "Train - Epoch: 78 | Loss: 1.1862 | Acc: 64.65% | Precision: 64.79% | recall: 64.65% | f1: 64.53%\n",
      "Val - Epoch: 78 | Loss: 1.3697 | Acc: 56.43% | Precision: 60.52% | recall: 56.43% | f1: 56.30%\n",
      "Train - Epoch: 79 | Loss: 1.1625 | Acc: 66.62% | Precision: 66.85% | recall: 66.62% | f1: 66.47%\n",
      "Val - Epoch: 79 | Loss: 1.3703 | Acc: 58.29% | Precision: 62.47% | recall: 58.29% | f1: 58.46%\n",
      "Train - Epoch: 80 | Loss: 1.1977 | Acc: 62.44% | Precision: 62.49% | recall: 62.44% | f1: 62.29%\n",
      "Val - Epoch: 80 | Loss: 1.3743 | Acc: 55.43% | Precision: 59.86% | recall: 55.43% | f1: 55.11%\n",
      "Train - Epoch: 81 | Loss: 1.1522 | Acc: 65.80% | Precision: 65.92% | recall: 65.80% | f1: 65.66%\n",
      "Val - Epoch: 81 | Loss: 1.3200 | Acc: 58.71% | Precision: 61.47% | recall: 58.71% | f1: 58.71%\n",
      "Train - Epoch: 82 | Loss: 1.1428 | Acc: 66.62% | Precision: 66.84% | recall: 66.62% | f1: 66.47%\n",
      "Val - Epoch: 82 | Loss: 1.3004 | Acc: 58.86% | Precision: 63.03% | recall: 58.86% | f1: 59.37%\n",
      "Train - Epoch: 83 | Loss: 1.1048 | Acc: 68.48% | Precision: 68.53% | recall: 68.48% | f1: 68.34%\n",
      "Val - Epoch: 83 | Loss: 1.3138 | Acc: 57.43% | Precision: 63.32% | recall: 57.43% | f1: 57.67%\n",
      "Train - Epoch: 84 | Loss: 1.1021 | Acc: 66.87% | Precision: 66.94% | recall: 66.87% | f1: 66.75%\n",
      "Val - Epoch: 84 | Loss: 1.2430 | Acc: 63.57% | Precision: 65.59% | recall: 63.57% | f1: 63.58%\n",
      "Train - Epoch: 85 | Loss: 1.0909 | Acc: 68.19% | Precision: 68.30% | recall: 68.19% | f1: 67.99%\n",
      "Val - Epoch: 85 | Loss: 1.2655 | Acc: 62.43% | Precision: 65.59% | recall: 62.43% | f1: 62.55%\n",
      "Train - Epoch: 86 | Loss: 1.0909 | Acc: 67.51% | Precision: 67.44% | recall: 67.51% | f1: 67.38%\n",
      "Val - Epoch: 86 | Loss: 1.3081 | Acc: 57.57% | Precision: 63.15% | recall: 57.57% | f1: 57.57%\n",
      "Train - Epoch: 87 | Loss: 1.0459 | Acc: 69.73% | Precision: 69.72% | recall: 69.73% | f1: 69.57%\n",
      "Val - Epoch: 87 | Loss: 1.3186 | Acc: 56.71% | Precision: 64.91% | recall: 56.71% | f1: 57.00%\n",
      "Train - Epoch: 88 | Loss: 1.0587 | Acc: 68.48% | Precision: 68.63% | recall: 68.48% | f1: 68.36%\n",
      "Val - Epoch: 88 | Loss: 1.2710 | Acc: 58.71% | Precision: 65.28% | recall: 58.71% | f1: 59.11%\n",
      "Train - Epoch: 89 | Loss: 1.0192 | Acc: 69.73% | Precision: 69.72% | recall: 69.73% | f1: 69.62%\n",
      "Val - Epoch: 89 | Loss: 1.1925 | Acc: 65.71% | Precision: 68.05% | recall: 65.71% | f1: 65.71%\n",
      "Train - Epoch: 90 | Loss: 1.0104 | Acc: 70.51% | Precision: 70.58% | recall: 70.51% | f1: 70.41%\n",
      "Val - Epoch: 90 | Loss: 1.1660 | Acc: 66.57% | Precision: 69.28% | recall: 66.57% | f1: 66.64%\n",
      "Train - Epoch: 91 | Loss: 0.9760 | Acc: 72.30% | Precision: 72.25% | recall: 72.30% | f1: 72.19%\n",
      "Val - Epoch: 91 | Loss: 1.1630 | Acc: 64.00% | Precision: 67.13% | recall: 64.00% | f1: 63.82%\n",
      "Train - Epoch: 92 | Loss: 0.9587 | Acc: 73.20% | Precision: 73.25% | recall: 73.20% | f1: 73.15%\n",
      "Val - Epoch: 92 | Loss: 1.1756 | Acc: 63.57% | Precision: 68.55% | recall: 63.57% | f1: 63.63%\n",
      "Train - Epoch: 93 | Loss: 0.9747 | Acc: 71.69% | Precision: 71.77% | recall: 71.69% | f1: 71.62%\n",
      "Val - Epoch: 93 | Loss: 1.0954 | Acc: 70.14% | Precision: 72.34% | recall: 70.14% | f1: 70.26%\n",
      "Train - Epoch: 94 | Loss: 0.9647 | Acc: 71.52% | Precision: 71.74% | recall: 71.52% | f1: 71.35%\n",
      "Val - Epoch: 94 | Loss: 1.1272 | Acc: 67.71% | Precision: 70.16% | recall: 67.71% | f1: 67.59%\n",
      "Train - Epoch: 95 | Loss: 0.9291 | Acc: 73.77% | Precision: 73.80% | recall: 73.77% | f1: 73.64%\n",
      "Val - Epoch: 95 | Loss: 1.0714 | Acc: 70.00% | Precision: 71.52% | recall: 70.00% | f1: 70.11%\n",
      "Train - Epoch: 96 | Loss: 0.9234 | Acc: 73.73% | Precision: 73.86% | recall: 73.73% | f1: 73.67%\n",
      "Val - Epoch: 96 | Loss: 1.2239 | Acc: 61.43% | Precision: 69.21% | recall: 61.43% | f1: 61.65%\n",
      "Train - Epoch: 97 | Loss: 0.9226 | Acc: 72.37% | Precision: 72.40% | recall: 72.37% | f1: 72.29%\n",
      "Val - Epoch: 97 | Loss: 1.0556 | Acc: 68.57% | Precision: 70.40% | recall: 68.57% | f1: 68.74%\n",
      "Train - Epoch: 98 | Loss: 0.8970 | Acc: 74.34% | Precision: 74.32% | recall: 74.34% | f1: 74.24%\n",
      "Val - Epoch: 98 | Loss: 1.1240 | Acc: 64.00% | Precision: 69.68% | recall: 64.00% | f1: 63.45%\n",
      "Train - Epoch: 99 | Loss: 0.8615 | Acc: 76.05% | Precision: 76.10% | recall: 76.05% | f1: 75.98%\n",
      "Val - Epoch: 99 | Loss: 1.0340 | Acc: 69.14% | Precision: 72.19% | recall: 69.14% | f1: 69.31%\n",
      "Train - Epoch: 100 | Loss: 0.8576 | Acc: 75.45% | Precision: 75.50% | recall: 75.45% | f1: 75.33%\n",
      "Val - Epoch: 100 | Loss: 1.0347 | Acc: 70.29% | Precision: 72.55% | recall: 70.29% | f1: 70.39%\n",
      "Train - Epoch: 101 | Loss: 0.8398 | Acc: 76.48% | Precision: 76.54% | recall: 76.48% | f1: 76.42%\n",
      "Val - Epoch: 101 | Loss: 0.9976 | Acc: 71.86% | Precision: 74.80% | recall: 71.86% | f1: 72.44%\n",
      "Train - Epoch: 102 | Loss: 0.8067 | Acc: 78.31% | Precision: 78.36% | recall: 78.31% | f1: 78.24%\n",
      "Val - Epoch: 102 | Loss: 1.0051 | Acc: 71.14% | Precision: 73.51% | recall: 71.14% | f1: 71.17%\n",
      "Train - Epoch: 103 | Loss: 0.7913 | Acc: 78.63% | Precision: 78.69% | recall: 78.63% | f1: 78.57%\n",
      "Val - Epoch: 103 | Loss: 0.9304 | Acc: 73.43% | Precision: 74.48% | recall: 73.43% | f1: 73.40%\n",
      "Train - Epoch: 104 | Loss: 0.7703 | Acc: 78.59% | Precision: 78.59% | recall: 78.59% | f1: 78.51%\n",
      "Val - Epoch: 104 | Loss: 0.9180 | Acc: 73.71% | Precision: 75.03% | recall: 73.71% | f1: 73.69%\n",
      "Train - Epoch: 105 | Loss: 0.7491 | Acc: 80.09% | Precision: 80.14% | recall: 80.09% | f1: 80.03%\n",
      "Val - Epoch: 105 | Loss: 0.9405 | Acc: 72.86% | Precision: 76.21% | recall: 72.86% | f1: 73.21%\n",
      "Train - Epoch: 106 | Loss: 0.7768 | Acc: 78.84% | Precision: 78.80% | recall: 78.84% | f1: 78.77%\n",
      "Val - Epoch: 106 | Loss: 0.9900 | Acc: 70.57% | Precision: 74.91% | recall: 70.57% | f1: 70.46%\n",
      "Train - Epoch: 107 | Loss: 0.7276 | Acc: 80.41% | Precision: 80.45% | recall: 80.41% | f1: 80.36%\n",
      "Val - Epoch: 107 | Loss: 0.8435 | Acc: 75.86% | Precision: 77.11% | recall: 75.86% | f1: 75.87%\n",
      "Train - Epoch: 108 | Loss: 0.7152 | Acc: 81.13% | Precision: 81.22% | recall: 81.13% | f1: 81.08%\n",
      "Val - Epoch: 108 | Loss: 0.9211 | Acc: 72.29% | Precision: 76.70% | recall: 72.29% | f1: 72.77%\n",
      "Train - Epoch: 109 | Loss: 0.6992 | Acc: 81.81% | Precision: 81.80% | recall: 81.81% | f1: 81.78%\n",
      "Val - Epoch: 109 | Loss: 0.8367 | Acc: 76.57% | Precision: 78.37% | recall: 76.57% | f1: 76.71%\n",
      "Train - Epoch: 110 | Loss: 0.6684 | Acc: 82.63% | Precision: 82.62% | recall: 82.63% | f1: 82.58%\n",
      "Val - Epoch: 110 | Loss: 0.8006 | Acc: 78.14% | Precision: 79.60% | recall: 78.14% | f1: 78.23%\n",
      "Training completed in 2m 12s\n",
      "Best validation accuracy: 78.14%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example configuration\n",
    "    config = {\n",
    "        'lr': 3e-5,\n",
    "        'weight_decay': 1e-5,\n",
    "        'patience': 15,\n",
    "        'epochs': 110,\n",
    "        'experiment_name': 'eeg_attention_experiment',\n",
    "        'save_attention_maps': True\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_loader, val_loader, trail_shape, class_weights = get_data_loaders(data_dir=\"/teamspace/studios/this_studio/mnist_data/MindBigData64_Mnist2022-EEGv0.016.txt\")\n",
    "    model = EEGClassifier(num_samples = trail_shape[-1], num_classes=10)\n",
    "    # Create trainer\n",
    "    trainer = EEGTrainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        class_weights = class_weights,\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    # Start training\n",
    "    best_val_acc = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca4ca2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# file_path = \"/teamspace/studios/this_studio/mnist_s/MindBigData64_Mnist2022-EEGv0.016.txt\"\n",
    "# df = pd.read_csv(file_path, header=None)\n",
    "# df = df[df.iloc[:, 2] != -1]\n",
    "\n",
    "# df.columns = ['id', 'event', 'device', 'channel', 'code', 'size', 'data']\n",
    "# df['data'] = df['data'].apply(lambda x: np.array(x.split(','), dtype=float))\n",
    "# num_groups = len(df) // 14\n",
    "# grouped = np.zeros((num_groups - 8, 14, 244), dtype=np.float32)\n",
    "# group_idx = 0\n",
    "# temp = None\n",
    "# temp1=[]\n",
    "# labels = []\n",
    "# ind = 0\n",
    "# for row, num in zip(df['data'], df['code']):\n",
    "\n",
    "#     if num != -1:\n",
    "#         if len(row) >= 244:\n",
    "#             temp = df['data'].iloc[ind:ind+14]\n",
    "#             ind+=14\n",
    "#         else:\n",
    "#             continue\n",
    "        \n",
    "#         if not temp.empty:\n",
    "#             if all(len(i)>=244 for i in temp):\n",
    "#                 for row in temp:\n",
    "#                     temp1.append(row[:244])\n",
    "#             else:\n",
    "#                 continue\n",
    "#         else:\n",
    "#             continue\n",
    "\n",
    "\n",
    "#         if len(temp1) == 14:\n",
    "#             grouped[group_idx] = np.stack(temp1)\n",
    "#             labels.append(num)\n",
    "#             temp1=[]\n",
    "#             temp = None\n",
    "#             group_idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4255d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# labels = df.iloc[:, 2].values\n",
    "# all_data = []\n",
    "\n",
    "# for i, row in df.iterrows():\n",
    "#     data = row.iloc[788:].astype(float).values.reshape(64, 400)\n",
    "#     all_data.append(data)\n",
    "\n",
    "# # Convert list â†’ NumPy array\n",
    "# all_data = np.stack(all_data)\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
